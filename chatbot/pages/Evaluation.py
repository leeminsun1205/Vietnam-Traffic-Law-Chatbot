# pages/2_Evaluation.py
import time
import streamlit as st
import pandas as pd
import json
import os
from datetime import datetime
import sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
import config
import utils
import data_loader
from retriever import HybridRetriever
from utils import precision_at_k, recall_at_k, f1_at_k, mrr_at_k, ndcg_at_k, calculate_average_metrics

# Bi·∫øn to√†n c·ª•c ƒë·ªÉ ki·ªÉm tra y√™u c·∫ßu h·ªßy b·ªè (d√πng trong session state)
if 'cancel_eval_requested' not in st.session_state:
    st.session_state.cancel_eval_requested = False

def run_retrieval_evaluation(
    eval_data: list,
    hybrid_retriever: HybridRetriever,
    embedding_model,
    reranking_model,
    gemini_model,
    eval_config: dict
    ):

    results_list = []
    k_values = [3, 5, 10]

    # --- L·∫•y c·∫•u h√¨nh t·ª´ eval_config ---
    retrieval_query_mode = eval_config.get('retrieval_query_mode', 'T·ªïng qu√°t')
    retrieval_method = eval_config.get('retrieval_method', 'hybrid')
    use_reranker = eval_config.get('use_reranker', True)

    progress_bar = st.progress(0)
    status_text = st.empty()

    total_items = len(eval_data)
    queries_per_batch = 15 # Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng query tr∆∞·ªõc khi t·∫°m d·ª´ng
    wait_time_seconds = 60 # Th·ªùi gian t·∫°m d·ª´ng

    # ƒê·∫∑t c·ªù h·ªßy b·ªè v·ªÅ False khi b·∫Øt ƒë·∫ßu ch·∫°y
    st.session_state.cancel_eval_requested = False

    for i, item in enumerate(eval_data):
        # --- KI·ªÇM TRA Y√äU C·∫¶U H·ª¶Y B·ªé ---
        if st.session_state.cancel_eval_requested:
            status_text.warning(f"ƒê√£ h·ªßy b·ªè qu√° tr√¨nh ƒë√°nh gi√° t·∫°i query {i}/{total_items}.")
            break # Tho√°t kh·ªèi v√≤ng l·∫∑p ch√≠nh

        # T·∫°m d·ª´ng sau m·ªói batch
        if i > 0 and i % queries_per_batch == 0:
            pause_msg = f"ƒê√£ x·ª≠ l√Ω {i}/{total_items} queries. T·∫°m d·ª´ng {wait_time_seconds} gi√¢y..."
            status_text.text(pause_msg)
            time.sleep(wait_time_seconds)
            # Ki·ªÉm tra l·∫°i y√™u c·∫ßu h·ªßy b·ªè sau khi t·∫°m d·ª´ng
            if st.session_state.cancel_eval_requested:
                status_text.warning(f"ƒê√£ h·ªßy b·ªè qu√° tr√¨nh ƒë√°nh gi√° t·∫°i query {i}/{total_items}.")
                break # Tho√°t kh·ªèi v√≤ng l·∫∑p ch√≠nh

            status_text.text(f"Ti·∫øp t·ª•c x·ª≠ l√Ω query {i+1}/{total_items}...")


        query_id = item.get("query_id"); original_query = item.get("query")
        relevant_chunk_ids = set(item.get("relevant_chunk_ids", []))

        status_text.text(f"ƒêang x·ª≠ l√Ω query {i+1}/{total_items}: {query_id} (QueryMode: {retrieval_query_mode}, Method: {retrieval_method}, Rerank: {use_reranker})")

        start_time = time.time()
        # --- Kh·ªüi t·∫°o query_metrics v·ªõi c√°c tr∆∞·ªùng c·∫•u h√¨nh ---
        query_metrics = {
            "query_id": query_id, "query": original_query,
            "retrieval_query_mode": retrieval_query_mode,
            "retrieval_method": retrieval_method,
            "use_reranker": use_reranker,
            "status": "error", "retrieved_ids": [], "relevant_ids": list(relevant_chunk_ids),
            "processing_time": 0.0, 'summarizing_query': '',
            'variation_time': 0.0, 'search_time': 0.0, 'rerank_time': 0.0,
            'num_variations_generated': 0, 'num_unique_docs_found': 0, 'num_docs_reranked': 0,
            'num_retrieved_before_rerank': 0, 'num_retrieved_after_rerank': 0
        }
        # V√≤ng l·∫∑p kh·ªüi t·∫°o metrics, t·ª± ƒë·ªông d√πng k_values m·ªõi
        for k in k_values:
            query_metrics[f'precision@{k}'] = 0.0; query_metrics[f'recall@{k}'] = 0.0
            query_metrics[f'f1@{k}'] = 0.0; query_metrics[f'mrr@{k}'] = 0.0; query_metrics[f'ndcg@{k}'] = 0.0

        try:
            # B∆∞·ªõc 1: T·∫°o variations/summarizing query (lu√¥n ch·∫°y)
            variation_start = time.time()
            relevance_status, _, all_queries, summarizing_query = utils.generate_query_variations(
                original_query=original_query, gemini_model=gemini_model,
                chat_history=None,
                num_variations=config.NUM_QUERY_VARIATIONS
            )
            query_metrics["variation_time"] = time.time() - variation_start
            query_metrics["summarizing_query"] = summarizing_query
            query_metrics["num_variations_generated"] = len(all_queries) - 1

            if relevance_status == 'invalid':
                query_metrics["status"] = "skipped_irrelevant"
                query_metrics["processing_time"] = time.time() - start_time
                results_list.append(query_metrics)
                progress_bar.progress((i + 1) / total_items)
                continue

            # --- B∆∞·ªõc 2: X√°c ƒë·ªãnh query(s) ƒë·ªÉ t√¨m ki·∫øm ---
            queries_to_search = []
            if retrieval_query_mode == 'ƒê∆°n gi·∫£n': queries_to_search = [original_query]
            elif retrieval_query_mode == 'T·ªïng qu√°t': queries_to_search = [summarizing_query]
            elif retrieval_query_mode == 'S√¢u': queries_to_search = all_queries

            # --- B∆∞·ªõc 3: Th·ª±c hi·ªán Retrieval ---
            collected_docs_data = {}
            search_start = time.time()
            for q_variant in queries_to_search:
                if not q_variant: continue
                search_results = hybrid_retriever.search(
                    q_variant, embedding_model,
                    method=retrieval_method,
                    k=config.VECTOR_K_PER_QUERY
                )
                for item in search_results:
                    doc_index = item.get('index')
                    # ƒê·∫£m b·∫£o doc_index l√† s·ªë nguy√™n h·ª£p l·ªá tr∆∞·ªõc khi th√™m v√†o dict
                    if isinstance(doc_index, int) and doc_index >= 0 and doc_index not in collected_docs_data:
                        collected_docs_data[doc_index] = item
            query_metrics["search_time"] = time.time() - search_start
            query_metrics["num_unique_docs_found"] = len(collected_docs_data)

            # --- Chu·∫©n b·ªã danh s√°ch k·∫øt qu·∫£ retrieval ---
            retrieved_docs_list = list(collected_docs_data.values())
            sort_reverse = (retrieval_method != 'dense')
            retrieved_docs_list.sort(key=lambda x: x.get('score', 0 if sort_reverse else float('inf')), reverse=sort_reverse)
            query_metrics["num_retrieved_before_rerank"] = len(retrieved_docs_list)


            # --- B∆∞·ªõc 4: Re-ranking (N·∫øu b·∫≠t) ---
            final_docs_for_metrics = []
            rerank_time = 0.0 # Kh·ªüi t·∫°o rerank_time
            rerank_start = time.time()

            if use_reranker and retrieved_docs_list:
                query_for_reranking = summarizing_query if summarizing_query else original_query
                docs_to_rerank = retrieved_docs_list[:config.MAX_DOCS_FOR_RERANK]
                query_metrics["num_docs_reranked"] = len(docs_to_rerank)

                rerank_input = [{'doc': item.get('doc', {}), 'index': item.get('index')} for item in docs_to_rerank if 'doc' in item] # B·ªï sung ki·ªÉm tra 'doc'
                # Ch·ªâ g·ªçi rerank n·∫øu reranking_model t·ªìn t·∫°i v√† c√≥ docs ƒë·ªÉ rerank
                if reranking_model and rerank_input:
                    reranked_results = utils.rerank_documents(
                        query_for_reranking, rerank_input, reranking_model
                    )
                    final_docs_for_metrics = reranked_results[:config.FINAL_NUM_RESULTS_AFTER_RERANK]
                    rerank_time = time.time() - rerank_start
                else:
                    # N·∫øu kh√¥ng c√≥ reranker model ho·∫∑c kh√¥ng c√≥ docs ƒë·ªÉ rerank, b·ªè qua rerank
                    final_docs_for_metrics = docs_to_rerank[:config.FINAL_NUM_RESULTS_AFTER_RERANK] # L·∫•y top K tr·ª±c ti·∫øp
                    rerank_time = 0.0
                    query_metrics["num_docs_reranked"] = 0


            elif retrieved_docs_list:
                final_docs_for_metrics = retrieved_docs_list[:config.FINAL_NUM_RESULTS_AFTER_RERANK]
                rerank_time = 0.0
                query_metrics["num_docs_reranked"] = 0
            else:
                 rerank_time = 0.0
                 query_metrics["num_docs_reranked"] = 0

            query_metrics["rerank_time"] = rerank_time # L∆∞u th·ªùi gian rerank ƒë√£ t√≠nh

            query_metrics["num_retrieved_after_rerank"] = len(final_docs_for_metrics)

            # --- B∆∞·ªõc 5: L·∫•y IDs v√† T√≠nh Metrics ---
            retrieved_ids = []
            for res in final_docs_for_metrics:
                doc = res.get('doc', {}); original_index = res.get('original_index', res.get('index')) # L·∫•y original_index t·ª´ k·∫øt qu·∫£ rerank n·∫øu c√≥, fallback v·ªÅ index ban ƒë·∫ßu
                chunk_id = None

                if isinstance(doc, dict):
                     # ∆Øu ti√™n l·∫•y t·ª´ metadata tr∆∞·ªõc
                    metadata = doc.get('metadata', {})
                    if isinstance(metadata, dict):
                        chunk_id = metadata.get('chunk_id') or metadata.get('id')
                     # N·∫øu kh√¥ng c√≥ trong metadata, th·ª≠ l·∫•y tr·ª±c ti·∫øp t·ª´ doc
                    if not chunk_id:
                        chunk_id = doc.get('id')

                # Fallback l·∫•y t·ª´ original_index n·∫øu chunk_id kh√¥ng t√¨m th·∫•y (√≠t ch√≠nh x√°c h∆°n)
                if not chunk_id and isinstance(original_index, (int, np.integer)):
                    # C·ªë g·∫Øng l·∫•y th√¥ng tin t·ª´ self.documents trong retriever instance n·∫øu index h·ª£p l·ªá
                    if hybrid_retriever and hasattr(hybrid_retriever, 'documents') and isinstance(hybrid_retriever.documents, list) and 0 <= original_index < len(hybrid_retriever.documents):
                        doc_from_retriever = hybrid_retriever.documents[original_index]
                        if isinstance(doc_from_retriever, dict):
                            metadata_from_retriever = doc_from_retriever.get('metadata', {})
                            if isinstance(metadata_from_retriever, dict):
                                chunk_id = metadata_from_retriever.get('chunk_id') or metadata_from_retriever.get('id')
                            if not chunk_id:
                                chunk_id = doc_from_retriever.get('id')


                if chunk_id is not None: # Ki·ªÉm tra None thay v√¨ ch·ªâ True/False
                    retrieved_ids.append(str(chunk_id)) # ƒê·∫£m b·∫£o l√† string


            query_metrics["retrieved_ids"] = retrieved_ids

            query_metrics["status"] = "evaluated"
            # V√≤ng l·∫∑p t√≠nh metrics, t·ª± ƒë·ªông d√πng k_values m·ªõi
            for k in k_values:
                query_metrics[f'precision@{k}'] = precision_at_k(retrieved_ids, relevant_chunk_ids, k)
                query_metrics[f'recall@{k}'] = recall_at_k(retrieved_ids, relevant_chunk_ids, k)
                query_metrics[f'f1@{k}'] = f1_at_k(retrieved_ids, relevant_chunk_ids, k)
                query_metrics[f'mrr@{k}'] = mrr_at_k(retrieved_ids, relevant_chunk_ids, k)
                query_metrics[f'ndcg@{k}'] = ndcg_at_k(retrieved_ids, relevant_chunk_ids, k)


        except Exception as e:
            query_metrics["status"] = "error_runtime"
            query_metrics["error_message"] = str(e)
        finally:
            query_metrics["processing_time"] = time.time() - start_time
            results_list.append(query_metrics)
            progress_bar.progress((i + 1) / total_items)

    # C·∫≠p nh·∫≠t thanh ti·∫øn tr√¨nh v√† tr·∫°ng th√°i sau khi ho√†n th√†nh ho·∫∑c h·ªßy b·ªè
    if st.session_state.cancel_eval_requested:
         progress_bar.progress((i + 1) / total_items) # Hi·ªÉn th·ªã ti·∫øn ƒë·ªô t·∫°i th·ªùi ƒëi·ªÉm h·ªßy
         # Tr·∫°ng th√°i h·ªßy b·ªè ƒë√£ ƒë∆∞·ª£c hi·ªÉn th·ªã b√™n trong v√≤ng l·∫∑p
    else:
        status_text.text(f"Ho√†n th√†nh ƒë√°nh gi√° {total_items} queries!")


    return pd.DataFrame(results_list)

# --- Giao di·ªán Streamlit ---
st.set_page_config(page_title="ƒê√°nh gi√° Retrieval", layout="wide")
st.title("üìä ƒê√°nh gi√° H·ªá th·ªëng Retrieval")

st.markdown("""
Trang n√†y cho ph√©p b·∫°n ch·∫°y ƒë√°nh gi√° hi·ªáu su·∫•t c·ªßa h·ªá th·ªëng retrieval v√† reranking
d·ª±a tr√™n m·ªôt t·∫≠p d·ªØ li·ªáu c√¢u h·ªèi v√† c√°c chunk t√†i li·ªáu li√™n quan (ground truth).
S·ª≠ d·ª•ng c·∫•u h√¨nh **hi·ªán t·∫°i ƒë∆∞·ª£c ch·ªçn tr√™n sidebar c·ªßa trang n√†y**.
""")

# --- sidebar ---
with st.sidebar:
    st.title("T√πy ch·ªçn ƒê√°nh gi√°")

    DEFAULT_EVAL_CONFIG_STATE = {
        "selected_gemini_model": st.session_state.get("selected_gemini_model", config.DEFAULT_GEMINI_MODEL),
        "retrieval_query_mode": st.session_state.get("retrieval_query_mode", 'T·ªïng qu√°t'),
        "retrieval_method": st.session_state.get("retrieval_method", 'hybrid'),
        "use_reranker": st.session_state.get("use_reranker", True),
        "eval_uploaded_filename": "", # ƒê·∫£m b·∫£o c√≥ trong state
        "eval_run_completed": False, # ƒê·∫£m b·∫£o c√≥ trong state
        "eval_data": None, # ƒê·∫£m b·∫£o c√≥ trong state
        "eval_results_df": None, # ƒê·∫£m b·∫£o c√≥ trong state
        "last_eval_config": {}, # ƒê·∫£m b·∫£o c√≥ trong state
        "cancel_eval_requested": False, # Th√™m bi·∫øn tr·∫°ng th√°i h·ªßy
    }

    for key, default_value in DEFAULT_EVAL_CONFIG_STATE.items():
        if key not in st.session_state:
            st.session_state[key] = default_value

    st.header("M√¥ h√¨nh")
    st.selectbox(
        "Ch·ªçn m√¥ h√¨nh Gemini (ƒë·ªÉ t·∫°o query variations):",
        options=config.AVAILABLE_GEMINI_MODELS,
        index=config.AVAILABLE_GEMINI_MODELS.index(st.session_state.get('selected_gemini_model', config.DEFAULT_GEMINI_MODEL)), # ƒê·ªçc t·ª´ state
        key="selected_gemini_model", # Ghi v√†o state khi thay ƒë·ªïi
        help="Ch·ªçn m√¥ h√¨nh ng√¥n ng·ªØ l·ªõn ƒë·ªÉ ph√¢n t√≠ch v√† t·∫°o bi·∫øn th·ªÉ c√¢u h·ªèi cho Retrieval."
    )

    st.header("C·∫•u h√¨nh Retrieval")

    st.radio(
        "Ngu·ªìn c√¢u h·ªèi cho Retrieval:",
        options=['ƒê∆°n gi·∫£n', 'T·ªïng qu√°t', 'S√¢u'],
        index=['ƒê∆°n gi·∫£n', 'T·ªïng qu√°t', 'S√¢u'].index(st.session_state.get('retrieval_query_mode', 'T·ªïng qu√°t')), # ƒê·ªçc t·ª´ state
        key="retrieval_query_mode", # Ghi v√†o state khi thay ƒë·ªïi
        horizontal=True,
        help=(
            "**ƒê∆°n gi·∫£n:** Ch·ªâ d√πng c√¢u h·ªèi g·ªëc.\n"
            "**T·ªïng qu√°t:** Ch·ªâ d√πng c√¢u h·ªèi t√≥m t·∫Øt (do AI t·∫°o).\n"
            "**S√¢u:** D√πng c·∫£ c√¢u h·ªèi g·ªëc v√† c√°c bi·∫øn th·ªÉ (do AI t·∫°o)."
        )
    )

    st.radio(
        "Ph∆∞∆°ng th·ª©c Retrieval:",
        options=['dense', 'sparse', 'hybrid'],
        index=['dense', 'sparse', 'hybrid'].index(st.session_state.get('retrieval_method', 'hybrid')), # ƒê·ªçc t·ª´ state
        key="retrieval_method", # Ghi v√†o state khi thay ƒë·ªïi
        horizontal=True,
        help=(
            "**dense:** T√¨m ki·∫øm d·ª±a tr√™n vector ng·ªØ nghƒ©a.\n"
            "**sparse:** T√¨m ki·∫øm d·ª±a tr√™n t·ª´ kh√≥a (BM25).\n"
            "**hybrid:** K·∫øt h·ª£p c·∫£ dense v√† sparse."
        )
    )

    # Widget ƒë·ªçc v√† ghi v√†o st.session_state['use_reranker']
    st.toggle(
        "S·ª≠ d·ª•ng Reranker",
        value=st.session_state.get('use_reranker', True), # ƒê·ªçc t·ª´ state
        key="use_reranker", # Ghi v√†o state khi thay ƒë·ªïi
        help="B·∫≠t ƒë·ªÉ s·ª≠ d·ª•ng m√¥ h√¨nh CrossEncoder x·∫øp h·∫°ng l·∫°i k·∫øt qu·∫£ t√¨m ki·∫øm."
    )

    # ƒê√£ b·ªè c√†i ƒë·∫∑t cho History LLM1 ·ªü sidebar

# --- Kh·ªüi t·∫°o ho·∫∑c ki·ªÉm tra Session State (Ti·∫øp t·ª•c) ---
# Ph·∫ßn kh·ªüi t·∫°o state ri√™ng c·ªßa Evaluation (gi·ªØ nguy√™n)
# if 'eval_data' not in st.session_state: st.session_state.eval_data = None
# if 'eval_results_df' not in st.session_state: st.session_state.eval_results_df = None
# if 'eval_run_completed' not in st.session_state: st.session_state.eval_run_completed = False
# if 'eval_uploaded_filename' not in st.session_state: st.session_state.eval_uploaded_filename = ""
# # last_eval_config kh√¥ng c·∫ßn kh·ªüi t·∫°o ·ªü ƒë√¢y v√¨ n√≥ ch·ªâ ƒë∆∞·ª£c set khi b·∫Øt ƒë·∫ßu ƒë√°nh gi√°
# if 'cancel_eval_requested' not in st.session_state: # Th√™m kh·ªüi t·∫°o cho bi·∫øn h·ªßy
#     st.session_state.cancel_eval_requested = False


st.subheader("Tr·∫°ng th√°i H·ªá th·ªëng C∆° b·∫£n")
init_ok = False
retriever_instance = None
g_embedding_model = None
g_reranking_model_loaded = None

with st.spinner("Ki·ªÉm tra v√† kh·ªüi t·∫°o t√†i nguy√™n c·ªët l√µi..."):
    try:
        # Ch·ªâ t·∫£i reranker model n·∫øu c·∫•u h√¨nh sidebar b·∫≠t
        use_reranker_current = st.session_state.get('use_reranker', True)

        g_embedding_model = utils.load_embedding_model(config.embedding_model_name)
        if use_reranker_current: # Ch·ªâ t·∫£i n·∫øu b·∫≠t trong c·∫•u h√¨nh sidebar
            g_reranking_model_loaded = utils.load_reranker_model(config.reranking_model_name)
        else:
             g_reranking_model_loaded = None # ƒê·∫£m b·∫£o None n·∫øu t·∫Øt

        _, retriever_instance = data_loader.load_or_create_rag_components(g_embedding_model)

        if retriever_instance and g_embedding_model:
            init_ok = True

        else:
            missing = [comp for comp, loaded in [("Retriever/VectorDB", retriever_instance), ("Embedding Model", g_embedding_model)] if not loaded]
            st.error(f"‚ö†Ô∏è L·ªói kh·ªüi t·∫°o: {', '.join(missing)}.")

    except Exception as e:
        st.error(f"‚ö†Ô∏è L·ªói nghi√™m tr·ªçng khi kh·ªüi t·∫°o h·ªá th·ªëng: {e}")

if init_ok:
    # --- Hi·ªÉn th·ªã C·∫•u h√¨nh ƒê√°nh gi√° s·∫Ω s·ª≠ d·ª•ng (ƒë·ªçc t·ª´ session state, gi·ªù do sidebar qu·∫£n l√Ω) ---
    st.caption(f"M√¥ h√¨nh: `{st.session_state.get('selected_gemini_model', 'N/A')}` | Ngu·ªìn Query: `{st.session_state.get('retrieval_query_mode', 'N/A')}` | Retrieval: `{st.session_state.get('retrieval_method', 'N/A')}` | Reranker: `{'B·∫≠t' if st.session_state.get('use_reranker', False) else 'T·∫Øt'}`")

    # T·∫°o dict c·∫•u h√¨nh cho h√†m ƒë√°nh gi√° - ƒê·ªçc tr·ª±c ti·∫øp t·ª´ st.session_state
    # C√°c gi√° tr·ªã n√†y gi·ªù ƒë∆∞·ª£c ƒë·∫£m b·∫£o t·ªìn t·∫°i do sidebar ho·∫∑c kh·ªüi t·∫°o s·ªõm
    eval_config_dict = {
        'retrieval_query_mode': st.session_state.get('retrieval_query_mode', 'T·ªïng qu√°t'),
        'retrieval_method': st.session_state.get('retrieval_method', 'hybrid'),
        'use_reranker': st.session_state.get('use_reranker', True),
        'gemini_model_name': st.session_state.get('selected_gemini_model', config.DEFAULT_GEMINI_MODEL),
        'embedding_model_name': config.embedding_model_name,
        # C·∫≠p nh·∫≠t t√™n reranker model d·ª±a tr√™n tr·∫°ng th√°i t·∫£i v√† c·∫•u h√¨nh
        'reranker_model_name': config.reranking_model_name if st.session_state.get('use_reranker', True) and g_reranking_model_loaded else ("DISABLED_BY_CONFIG" if st.session_state.get('use_reranker', True) else "DISABLED_BY_CONFIG"),
    }
    # Ki·ªÉm tra cu·ªëi c√πng cho reranker model ƒë·ªÉ truy·ªÅn v√†o h√†m run_retrieval_evaluation
    reranker_model_for_run = g_reranking_model_loaded if st.session_state.get('use_reranker', True) and g_reranking_model_loaded else None


    st.subheader("T·∫£i L√™n File ƒê√°nh gi√°")
    uploaded_file = st.file_uploader(
        "Ch·ªçn file JSON d·ªØ li·ªáu ƒë√°nh gi√°...", type=["json"], key="eval_file_uploader" # Th√™m key ƒë·ªÉ d·ªÖ reset
    )

    if uploaded_file is not None:
        # Ki·ªÉm tra n·∫øu file m·ªõi ƒë∆∞·ª£c t·∫£i l√™n HO·∫∂C n·∫øu uploader key ƒë√£ b·ªã reset tr∆∞·ªõc ƒë√≥ (ƒë·ªÉ tr√°nh x·ª≠ l√Ω l·∫°i file c≈©)
        if uploaded_file.name != st.session_state.eval_uploaded_filename or st.session_state.eval_data is None:
             try:
                # Reset tr·∫°ng th√°i tr∆∞·ªõc khi t·∫£i file m·ªõi
                st.session_state.eval_data = None
                st.session_state.eval_uploaded_filename = uploaded_file.name # C·∫≠p nh·∫≠t t√™n file ngay
                st.session_state.eval_run_completed = False
                st.session_state.eval_results_df = None
                st.session_state.last_eval_config = {}
                st.session_state.cancel_eval_requested = False # Reset c·ªù h·ªßy

                eval_data_list = json.loads(uploaded_file.getvalue().decode('utf-8'))
                st.session_state.eval_data = eval_data_list

                st.success(f"ƒê√£ t·∫£i file '{uploaded_file.name}' ({len(eval_data_list)} c√¢u h·ªèi).")
             except Exception as e:
                st.error(f"L·ªói x·ª≠ l√Ω file JSON: {e}")
                st.session_state.eval_data = None; st.session_state.eval_uploaded_filename = ""
                st.session_state.eval_run_completed = False
                st.session_state.eval_results_df = None
                st.session_state.last_eval_config = {}
                st.session_state.cancel_eval_requested = False # Reset c·ªù h·ªßy


    if st.session_state.eval_data is not None:
        st.info(f"S·∫µn s√†ng ƒë√°nh gi√° v·ªõi d·ªØ li·ªáu t·ª´: **{st.session_state.eval_uploaded_filename}**.")

        if st.checkbox("Hi·ªÉn th·ªã d·ªØ li·ªáu m·∫´u (5 d√≤ng)", key="show_eval_data_preview"):
            st.dataframe(pd.DataFrame(st.session_state.eval_data).head())

        # N√∫t b·∫Øt ƒë·∫ßu v√† h·ªßy ƒë√°nh gi√°
        col_eval_btn, col_cancel_btn = st.columns(2)

        with col_eval_btn:
            # Disable n√∫t B·∫Øt ƒë·∫ßu n·∫øu ƒëang ch·∫°y
            is_running = 'ƒêang ch·∫°y ƒë√°nh gi√°...' in st.session_state.get('status_message', '') # Gi·∫£ ƒë·ªãnh c√≥ bi·∫øn status_message
            if st.button("üöÄ B·∫Øt ƒë·∫ßu ƒê√°nh gi√°", key="start_eval_button", disabled=is_running):
                 # L∆∞u c·∫•u h√¨nh hi·ªán t·∫°i t·ª´ st.session_state v√†o last_eval_config tr∆∞·ªõc khi ch·∫°y
                 # ƒê√¢y l√† c·∫•u h√¨nh m√† ng∆∞·ªùi d√πng ƒë√£ ch·ªçn tr√™n sidebar c·ªßa trang Evaluation
                 current_config_for_save = {
                    'retrieval_query_mode': st.session_state.get('retrieval_query_mode', 'T·ªïng qu√°t'),
                    'retrieval_method': st.session_state.get('retrieval_method', 'hybrid'),
                    'use_reranker': st.session_state.get('use_reranker', True),
                    'gemini_model_name': st.session_state.get('selected_gemini_model', config.DEFAULT_GEMINI_MODEL),
                    'embedding_model_name': config.embedding_model_name,
                    'reranker_model_name': config.reranking_model_name if st.session_state.get('use_reranker', True) and g_reranking_model_loaded else ("DISABLED_BY_CONFIG" if st.session_state.get('use_reranker', True) else "DISABLED_BY_CONFIG"),
                 }
                 st.session_state.last_eval_config = current_config_for_save.copy() # L∆∞u b·∫£n sao
                 st.session_state.eval_run_completed = False # ƒê·∫∑t l·∫°i c·ªù ho√†n th√†nh

                 # Reset c·ªù h·ªßy khi b·∫Øt ƒë·∫ßu ch·∫°y m·ªõi
                 st.session_state.cancel_eval_requested = False


                 with st.spinner(f"ƒêang t·∫£i model Gemini: {st.session_state.get('selected_gemini_model', config.DEFAULT_GEMINI_MODEL)}..."):
                     # T·∫£i Gemini model d·ª±a tr√™n l·ª±a ch·ªçn m·ªõi nh·∫•t t·ª´ sidebar (ƒë√£ c√≥ trong session state)
                     g_gemini_model_eval = utils.load_gemini_model(st.session_state.get('selected_gemini_model', config.DEFAULT_GEMINI_MODEL))


                 if g_gemini_model_eval:
                    st.info(f"Model Gemini '{st.session_state.get('selected_gemini_model', config.DEFAULT_GEMINI_MODEL)}' ƒë√£ s·∫µn s√†ng.")
                    st.session_state.status_message = "ƒêang ch·∫°y ƒë√°nh gi√°..." # C·∫≠p nh·∫≠t status
                    with st.spinner(st.session_state.status_message):
                        start_eval_time = time.time()
                        results_df = run_retrieval_evaluation(
                            eval_data=st.session_state.eval_data,
                            hybrid_retriever=retriever_instance,
                            embedding_model=g_embedding_model,
                            reranking_model=reranker_model_for_run, # Truy·ªÅn model (ho·∫∑c None)
                            gemini_model=g_gemini_model_eval, # Truy·ªÅn Gemini model ƒë√£ t·∫£i
                            eval_config=st.session_state.last_eval_config # Truy·ªÅn dict config ƒë√£ l∆∞u (ƒë·∫£m b·∫£o nh·∫•t)
                        )
                        total_eval_time = time.time() - start_eval_time

                        st.session_state.status_message = "Ho√†n th√†nh ƒë√°nh gi√°." # C·∫≠p nh·∫≠t status

                        if st.session_state.cancel_eval_requested:
                             st.warning(f"ƒê√°nh gi√° ƒë√£ b·ªã h·ªßy b·ªè sau {total_eval_time:.2f} gi√¢y.")
                        else:
                             st.success(f"Ho√†n th√†nh ƒë√°nh gi√° sau {total_eval_time:.2f} gi√¢y.")


                        st.session_state.eval_results_df = results_df
                        # Ch·ªâ set complete n·∫øu kh√¥ng b·ªã h·ªßy b·ªè
                        if not st.session_state.cancel_eval_requested:
                            st.session_state.eval_run_completed = True

                        st.session_state.cancel_eval_requested = False # Reset c·ªù h·ªßy sau khi k·∫øt th√∫c ch·∫°y
                        st.rerun() # Rerun ƒë·ªÉ hi·ªÉn th·ªã k·∫øt qu·∫£

        with col_cancel_btn:
            # Ch·ªâ hi·ªÉn th·ªã n√∫t H·ªßy n·∫øu qu√° tr√¨nh ƒë√°nh gi√° ƒëang ch·∫°y (c√≥ eval_data v√† ch∆∞a ho√†n th√†nh)
            if st.session_state.eval_data is not None and not st.session_state.eval_run_completed and not st.session_state.cancel_eval_requested:
                 if st.button("‚ùå H·ªßy ƒê√°nh gi√°", key="cancel_eval_button"):
                    st.session_state.cancel_eval_requested = True # ƒê·∫∑t c·ªù y√™u c·∫ßu h·ªßy
                    st.info("ƒêang y√™u c·∫ßu h·ªßy b·ªè qu√° tr√¨nh ƒë√°nh gi√°...")
                    time.sleep(0.1) # ƒê·ª£i m·ªôt ch√∫t ƒë·ªÉ state ƒë∆∞·ª£c c·∫≠p nh·∫≠t
                    st.rerun() # K√≠ch ho·∫°t rerun ƒë·ªÉ v√≤ng l·∫∑p ki·ªÉm tra c·ªù


    # --- Hi·ªÉn th·ªã K·∫øt qu·∫£ ---
    # Ch·ªâ hi·ªÉn th·ªã k·∫øt qu·∫£ n·∫øu ƒë√£ ho√†n th√†nh V√Ä kh√¥ng c√≥ y√™u c·∫ßu h·ªßy b·ªè ƒëang ch·ªù x·ª≠ l√Ω
    if st.session_state.eval_run_completed and st.session_state.eval_results_df is not None and not st.session_state.cancel_eval_requested:
        st.subheader("K·∫øt qu·∫£ ƒê√°nh gi√°")
        detailed_results_df = st.session_state.eval_results_df
        last_config = st.session_state.last_eval_config # ƒê·ªçc config ƒë√£ ch·∫°y

        # --- Hi·ªÉn th·ªã l·∫°i c·∫•u h√¨nh ƒë√£ ch·∫°y ---
        st.markdown("**C·∫•u h√¨nh ƒë√£ s·ª≠ d·ª•ng cho l·∫ßn ch·∫°y cu·ªëi:**")
        cfg_col1, cfg_col2, cfg_col3, cfg_col4 = st.columns(4)
        cfg_col1.metric("Ngu·ªìn Query", last_config.get('retrieval_query_mode', 'N/A'))
        cfg_col2.metric("Ret. Method", last_config.get('retrieval_method', 'N/A'))
        cfg_col3.metric("Reranker", "B·∫≠t" if last_config.get('use_reranker', False) else "T·∫Øt")
        st.caption(f"Gemini: `{last_config.get('gemini_model_name', 'N/A')}`, Embedding: `{last_config.get('embedding_model_name', 'N/A')}`, Reranker: `{last_config.get('reranker_model_name', 'N/A')}`")


        avg_metrics, num_eval, num_skipped_error = calculate_average_metrics(detailed_results_df)

        st.metric("T·ªïng s·ªë Queries", len(detailed_results_df))
        col_res1, col_res2 = st.columns(2)
        col_res1.metric("Queries ƒê√°nh gi√° H·ª£p l·ªá", num_eval)
        col_res2.metric("Queries B·ªè qua / L·ªói", num_skipped_error)

        if avg_metrics:
            st.markdown("#### Metrics Trung b√¨nh @K (tr√™n c√°c queries h·ª£p l·ªá)")
            # ƒê√£ b·ªè K=1
            k_values_display = [3, 5, 10]
            cols_k = st.columns(len(k_values_display))
            for idx, k in enumerate(k_values_display):
                with cols_k[idx]:
                    st.markdown(f"**K = {k}**")
                    st.text(f"Precision: {avg_metrics.get(f'avg_precision@{k}', 0.0):.4f}")
                    st.text(f"Recall:    {avg_metrics.get(f'avg_recall@{k}', 0.0):.4f}")
                    st.text(f"F1:        {avg_metrics.get(f'avg_f1@{k}', 0.0):.4f}")
                    st.text(f"MRR:       {avg_metrics.get(f'avg_mrr@{k}', 0.0):.4f}")
                    st.text(f"NDCG:      {avg_metrics.get(f'avg_ndcg@{k}', 0.0):.4f}")

            st.markdown("#### Th√¥ng tin Hi·ªáu nƒÉng & S·ªë l∆∞·ª£ng Trung b√¨nh")
            col_perf1, col_perf2, col_perf3, col_perf4 = st.columns(4)
            col_perf1.metric("Avg Total Time (s)", f"{avg_metrics.get('avg_processing_time', 0.0):.3f}")
            col_perf2.metric("Avg Variation Time (s)", f"{avg_metrics.get('avg_variation_time', 0.0):.3f}")
            col_perf3.metric("Avg Search Time (s)", f"{avg_metrics.get('avg_search_time', 0.0):.3f}")
            col_perf4.metric("Avg Rerank Time (s)", f"{avg_metrics.get('avg_rerank_time', 0.0):.3f}")

            col_count1, col_count2, col_count3, col_count4 = st.columns(4)
            col_count1.metric("Avg Variations Gen", f"{avg_metrics.get('avg_num_variations_generated', 0.0):.1f}")
            col_count2.metric("Avg Docs Found", f"{avg_metrics.get('avg_num_unique_docs_found', 0.0):.1f}")
            col_count3.metric("Avg Docs Reranked", f"{avg_metrics.get('avg_num_docs_reranked', 0.0):.1f}")
            col_count4.metric("Avg Final Docs", f"{avg_metrics.get('avg_num_retrieved_after_rerank', 0.0):.1f}")


        else:
            st.warning("Kh√¥ng th·ªÉ t√≠nh metrics trung b√¨nh (kh√¥ng c√≥ query h·ª£p l·ªá).")


        with st.expander("Xem K·∫øt qu·∫£ Chi ti·∫øt cho t·ª´ng Query"):
            display_columns = [
                'query_id', 'query', 'status',
                'retrieval_query_mode','retrieval_method', 'use_reranker',
                'precision@3', 'recall@3', 'f1@3', 'mrr@3', 'ndcg@3', # Ch·ªâ gi·ªØ K=3, 5, 10
                'precision@5', 'recall@5', 'f1@5', 'mrr@5', 'ndcg@5',
                'precision@10', 'recall@10', 'f1@10', 'mrr@10', 'ndcg@10',
                'processing_time', 'variation_time', 'search_time', 'rerank_time',
                'num_variations_generated','num_unique_docs_found', 'num_retrieved_before_rerank','num_docs_reranked', 'num_retrieved_after_rerank',
                'retrieved_ids', 'relevant_ids', 'summarizing_query', 'error_message'
            ]
            # L·ªçc l·∫°i c√°c c·ªôt hi·ªÉn th·ªã ƒë·ªÉ ch·ªâ gi·ªØ l·∫°i c√°c c·ªôt th·ª±c s·ª± c√≥ trong DataFrame
            # ƒêi·ªÅu n√†y quan tr·ªçng v√¨ c√°c metrics @1 kh√¥ng c√≤n ƒë∆∞·ª£c t√≠nh
            existing_display_columns = [col for col in display_columns if col in detailed_results_df.columns]
            st.dataframe(detailed_results_df[existing_display_columns])


        st.subheader("L∆∞u K·∫øt qu·∫£ Chi ti·∫øt")
        try:
            results_json = detailed_results_df.to_json(orient='records', indent=2, force_ascii=False)
            results_csv = detailed_results_df.to_csv(index=False).encode('utf-8')

            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            # S·ª≠ d·ª•ng config ƒë√£ ch·∫°y ƒë·ªÉ t·∫°o t√™n file
            qmode_suffix = last_config.get('retrieval_query_mode', 'na').lower()[:3]
            method_suffix = last_config.get('retrieval_method', 'na').lower()
            rerank_suffix = "rr" if last_config.get('use_reranker', False) else "norr"
            model_suffix = last_config.get('gemini_model_name', 'gemini').split('/')[-1].replace('.','-')[:15]

            base_filename = f"eval_{qmode_suffix}_{method_suffix}_{rerank_suffix}_{model_suffix}_{timestamp}"
            fname_json = f"{base_filename}.json"
            fname_csv = f"{base_filename}.csv"

            col_dl1, col_dl2 = st.columns(2)
            with col_dl1:
                st.download_button("üíæ T·∫£i v·ªÅ JSON", results_json, fname_json, "application/json", key="dl_json")
            with col_dl2:
                st.download_button("üíæ T·∫£i v·ªÅ CSV", results_csv, fname_csv, "text/csv", key="dl_csv")
        except Exception as e:
            st.error(f"L·ªói khi chu·∫©n b·ªã file k·∫øt qu·∫£: {e}")

    # --- Qu·∫£n l√Ω Tr·∫°ng th√°i ƒê√°nh gi√° ---
    st.markdown("---")
    st.subheader("Qu·∫£n l√Ω Tr·∫°ng th√°i ƒê√°nh gi√°")
    # N√∫t x√≥a: reset to√†n b·ªô tr·∫°ng th√°i li√™n quan ƒë·∫øn ƒë√°nh gi√° v√† uploader
    if st.button("X√≥a File ƒê√£ T·∫£i v√† K·∫øt Qu·∫£", key="clear_eval_state"):
        st.session_state.eval_data = None
        st.session_state.eval_uploaded_filename = ""
        st.session_state.eval_run_completed = False
        st.session_state.eval_results_df = None
        st.session_state.last_eval_config = {}
        st.session_state.cancel_eval_requested = False # Reset c·ªù h·ªßy

        # Reset tr·∫°ng th√°i c·ªßa st.file_uploader b·∫±ng c√°ch c·∫≠p nh·∫≠t key
        # Streamlit s·∫Ω t·∫°o l·∫°i widget v·ªõi tr·∫°ng th√°i r·ªóng
        st.session_state["eval_file_uploader"] = None 

        st.success("ƒê√£ x√≥a tr·∫°ng th√°i ƒë√°nh gi√°.")
        # time.sleep(1) # C√≥ th·ªÉ kh√¥ng c·∫ßn thi·∫øt v·ªõi rerun
        st.rerun()

else:
    st.warning("‚ö†Ô∏è H·ªá th·ªëng c∆° b·∫£n ch∆∞a s·∫µn s√†ng. Vui l√≤ng ki·ªÉm tra l·ªói v√† kh·ªüi ƒë·ªông l·∫°i.")