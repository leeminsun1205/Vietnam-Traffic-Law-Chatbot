# pages/Evaluation.py
import time
import streamlit as st
import pandas as pd
import json
import os
from datetime import datetime
import sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))) # Th√™m th∆∞ m·ª•c g·ªëc v√†o sys.path
import config
from model_loader import load_embedding_model, load_reranker_model, load_gemini_model
from data_loader import load_or_create_rag_components # Import t·ª´ th∆∞ m·ª•c g·ªëc
from reranker import rerank_documents
from utils import (
    generate_query_variations,
    precision_at_k, recall_at_k, f1_at_k, mrr_at_k, ndcg_at_k,
    calculate_average_metrics
)

# @st.cache_resource # Kh√¥ng cache to√†n b·ªô h√†m run_retrieval_evaluation v√¨ n√≥ c√≥ st.progress, st.empty
def run_retrieval_evaluation(
    eval_data: list,
    # Th√¥ng tin v·ªÅ retriever ch√≠nh
    primary_hybrid_retriever, # ƒê·ªïi t√™n ƒë·ªÉ r√µ r√†ng ƒë√¢y l√† retriever ch√≠nh
    primary_embedding_model_object, # Model object cho VDB ch√≠nh c·ªßa retriever
    # Th√¥ng tin v·ªÅ c√°c ngu·ªìn dense ph·ª• (n·∫øu c√≥)
    additional_dense_sources_for_eval: list, # List of (emb_obj, vdb_obj)
    # C√°c model kh√°c
    reranking_model_selected_obj, # ƒê·ªïi t√™n ƒë·ªÉ r√µ l√† object
    gemini_model_obj, # ƒê·ªïi t√™n ƒë·ªÉ r√µ l√† object
    eval_config: dict # Ch·ª©a c√°c t√™n model v√† c·∫•u h√¨nh kh√°c
    ):
    results_list = []
    k_values_metrics = [3, 5, 10] # ƒê·ªïi t√™n bi·∫øn ƒë·ªÉ tr√°nh tr√πng

    # L·∫•y c·∫•u h√¨nh t·ª´ eval_config
    retrieval_query_mode_eval = eval_config.get('retrieval_query_mode', 'T·ªïng qu√°t')
    retrieval_method_eval = eval_config.get('retrieval_method', 'hybrid')
    selected_reranker_name_for_eval_run = eval_config.get('selected_reranker_model', 'Kh√¥ng s·ª≠ d·ª•ng') # T√™n model reranker
    
    use_reranker_for_eval_run_flag = reranking_model_selected_obj is not None and selected_reranker_name_for_eval_run != 'Kh√¥ng s·ª≠ d·ª•ng'

    progress_bar = st.progress(0)
    status_text_area = st.empty() # S·ª≠ d·ª•ng st.text_area ƒë·ªÉ c√≥ th·ªÉ hi·ªÉn th·ªã nhi·ªÅu d√≤ng h∆°n n·∫øu c·∫ßn
    total_items = len(eval_data)
    # Gi·∫£m batch size v√† tƒÉng wait time n·∫øu API Gemini c√≥ rate limit ch·∫∑t
    queries_per_batch_limit = 15 
    wait_time_seconds_between_batches = 60 

    for i, item_data in enumerate(eval_data):
        # X·ª≠ l√Ω batching v√† t·∫°m d·ª´ng
        if i > 0 and i % queries_per_batch_limit == 0:
            pause_msg = f"ƒê√£ x·ª≠ l√Ω {i}/{total_items} queries. T·∫°m d·ª´ng {wait_time_seconds_between_batches} gi√¢y ƒë·ªÉ tr√°nh rate limit..."
            status_text_area.text(pause_msg)
            time.sleep(wait_time_seconds_between_batches)
        
        query_id_val = item_data.get("query_id", f"query_{i+1}")
        original_query_text = item_data.get("query")
        relevant_chunk_ids_set = set(map(str, item_data.get("relevant_chunk_ids", []))) # ƒê·∫£m b·∫£o l√† set c·ªßa string

        # Hi·ªÉn th·ªã th√¥ng tin x·ª≠ l√Ω
        reranker_display_name_eval = selected_reranker_name_for_eval_run.split('/')[-1] if selected_reranker_name_for_eval_run != 'Kh√¥ng s·ª≠ d·ª•ng' else "T·∫Øt"
        primary_emb_name_display = eval_config.get('embedding_model_name', 'N/A').split('/')[-1]
        
        additional_emb_names_display_list = []
        if retrieval_method_eval == 'hybrid' and eval_config.get('additional_embedding_model_names_eval'):
            for name in eval_config.get('additional_embedding_model_names_eval', []):
                 additional_emb_names_display_list.append(name.split('/')[-1])
        additional_embs_str = f", Ph·ª•: {', '.join(additional_emb_names_display_list)}" if additional_emb_names_display_list else ""
        
        status_text_area.text(
            f"ƒêang x·ª≠ l√Ω query {i+1}/{total_items}: {query_id_val}\n"
            f"Embedding Ch√≠nh: {primary_emb_name_display}{additional_embs_str}\n"
            f"QueryMode: {retrieval_query_mode_eval}, Method: {retrieval_method_eval}, Reranker: {reranker_display_name_eval}"
        )

        # Kh·ªüi t·∫°o dict l∆∞u tr·ªØ metrics cho query hi·ªán t·∫°i
        current_query_metrics = {
            "query_id": query_id_val, "query": original_query_text,
            "embedding_model_name": eval_config.get('embedding_model_name', 'N/A'),
            "additional_embedding_models_used": eval_config.get('additional_embedding_model_names_eval', []), # L∆∞u danh s√°ch t√™n model ph·ª•
            "retrieval_query_mode": retrieval_query_mode_eval,
            "retrieval_method": retrieval_method_eval,
            "selected_reranker_model": selected_reranker_name_for_eval_run,
            "status": "error_undefined", "retrieved_ids": [], "relevant_ids": list(relevant_chunk_ids_set),
            "processing_time": 0.0, 'summarizing_query': '',
            'variation_time': 0.0, 'search_time': 0.0, 'rerank_time': 0.0,
            'num_variations_generated': 0, 'num_unique_docs_found': 0, 
            'num_docs_reranked': 0, 'num_retrieved_before_rerank': 0, 'num_retrieved_after_rerank': 0,
            'error_message': ''
        }
        for k_m in k_values_metrics:
            current_query_metrics[f'precision@{k_m}'] = 0.0; current_query_metrics[f'recall@{k_m}'] = 0.0
            current_query_metrics[f'f1@{k_m}'] = 0.0; current_query_metrics[f'mrr@{k_m}'] = 0.0; current_query_metrics[f'ndcg@{k_m}'] = 0.0

        try:
            eval_query_start_time = time.time()
            # T·∫°o variations
            variation_start_t = time.time()
            relevance_status_eval, _, all_queries_eval, summarizing_q_eval = generate_query_variations(
                original_query=original_query_text, gemini_model=gemini_model_obj, chat_history=None,
                num_variations=config.NUM_QUERY_VARIATIONS
            )
            current_query_metrics["variation_time"] = time.time() - variation_start_t
            current_query_metrics["summarizing_query"] = summarizing_q_eval
            current_query_metrics["num_variations_generated"] = len(all_queries_eval) -1 if isinstance(all_queries_eval, list) and len(all_queries_eval) > 0 else 0
            
            if relevance_status_eval == 'invalid':
                current_query_metrics["status"] = "skipped_irrelevant_by_llm"
                current_query_metrics["processing_time"] = time.time() - eval_query_start_time
                results_list.append(current_query_metrics)
                progress_bar.progress((i + 1) / total_items); continue

            # Ch·ªçn queries ƒë·ªÉ t√¨m ki·∫øm
            queries_to_search_eval = []
            if retrieval_query_mode_eval == 'ƒê∆°n gi·∫£n': queries_to_search_eval = [original_query_text]
            elif retrieval_query_mode_eval == 'T·ªïng qu√°t': queries_to_search_eval = [summarizing_q_eval] if summarizing_q_eval else [original_query_text]
            elif retrieval_query_mode_eval == 'S√¢u': queries_to_search_eval = all_queries_eval if all_queries_eval else [original_query_text]

            # Th·ª±c hi·ªán Retrieval
            collected_docs_data_eval = {}
            search_start_t = time.time()
            for q_variant_eval in queries_to_search_eval:
                if not q_variant_eval: continue
                
                # G·ªçi search c·ªßa retriever ch√≠nh, truy·ªÅn c√°c ngu·ªìn ph·ª• v√†o ƒë√¢y
                search_results_variant_eval = primary_hybrid_retriever.search(
                    q_variant_eval, 
                    primary_embedding_model_object, # Model object cho VDB ch√≠nh
                    method=retrieval_method_eval,
                    k=config.VECTOR_K_PER_QUERY, # L·∫•y nhi·ªÅu h∆°n ƒë·ªÉ rerank/fusion
                    additional_dense_sources=additional_dense_sources_for_eval # Danh s√°ch c√°c (emb_obj, vdb_obj) ph·ª•
                )
                for res_item_eval in search_results_variant_eval:
                    doc_idx_eval = res_item_eval.get('index')
                    if isinstance(doc_idx_eval, int) and doc_idx_eval >= 0:
                        if doc_idx_eval not in collected_docs_data_eval:
                            collected_docs_data_eval[doc_idx_eval] = res_item_eval
                        else: # C·∫≠p nh·∫≠t score n·∫øu t·ªët h∆°n
                            # Score RRF/BM25: cao h∆°n t·ªët h∆°n. Score L2 distance (dense thu·∫ßn t√∫y): th·∫•p h∆°n t·ªët h∆°n.
                            current_score = collected_docs_data_eval[doc_idx_eval]['score']
                            new_score = res_item_eval['score']
                            if (retrieval_method_eval == 'hybrid' or retrieval_method_eval == 'sparse') and new_score > current_score:
                                collected_docs_data_eval[doc_idx_eval] = res_item_eval
                            elif retrieval_method_eval == 'dense' and new_score < current_score:
                                collected_docs_data_eval[doc_idx_eval] = res_item_eval


            current_query_metrics["search_time"] = time.time() - search_start_t
            current_query_metrics["num_unique_docs_found"] = len(collected_docs_data_eval)
            
            retrieved_docs_list_eval = list(collected_docs_data_eval.values())
            # S·∫Øp x·∫øp d·ª±a tr√™n ph∆∞∆°ng th·ª©c retrieval cu·ªëi c√πng
            sort_reverse_final_eval = (retrieval_method_eval == 'hybrid' or retrieval_method_eval == 'sparse')
            retrieved_docs_list_eval.sort(key=lambda x: x.get('score', 0 if sort_reverse_final_eval else float('inf')), reverse=sort_reverse_final_eval)
            current_query_metrics["num_retrieved_before_rerank"] = len(retrieved_docs_list_eval)

            # Rerank (N·∫øu ƒë∆∞·ª£c b·∫≠t)
            final_docs_for_metrics_calc = []
            rerank_start_time_eval_step = time.time()
            if use_reranker_for_eval_run_flag and retrieved_docs_list_eval:
                query_for_reranking_eval = summarizing_q_eval if summarizing_q_eval else original_query_text
                docs_to_rerank_eval_input = retrieved_docs_list_eval[:config.MAX_DOCS_FOR_RERANK]
                current_query_metrics["num_docs_reranked"] = len(docs_to_rerank_eval_input)
                
                rerank_input_formatted_eval = [{'doc': item_doc_rr['doc'], 'index': item_doc_rr['index']} for item_doc_rr in docs_to_rerank_eval_input]
                
                reranked_results_eval = rerank_documents(
                    query_for_reranking_eval, rerank_input_formatted_eval, reranking_model_selected_obj
                )
                final_docs_for_metrics_calc = reranked_results_eval[:config.FINAL_NUM_RESULTS_AFTER_RERANK]
                current_query_metrics["rerank_time"] = time.time() - rerank_start_time_eval_step
            elif retrieved_docs_list_eval: # Kh√¥ng d√πng reranker nh∆∞ng c√≥ k·∫øt qu·∫£ retrieval
                final_docs_for_metrics_calc = retrieved_docs_list_eval[:config.FINAL_NUM_RESULTS_AFTER_RERANK]
                current_query_metrics["rerank_time"] = 0.0; current_query_metrics["num_docs_reranked"] = 0
            else: # Kh√¥ng c√≥ k·∫øt qu·∫£ retrieval
                 current_query_metrics["rerank_time"] = 0.0; current_query_metrics["num_docs_reranked"] = 0
            
            current_query_metrics["num_retrieved_after_rerank"] = len(final_docs_for_metrics_calc)
            
            # Tr√≠ch xu·∫•t ID t·ª´ k·∫øt qu·∫£ cu·ªëi c√πng ƒë·ªÉ t√≠nh metrics
            retrieved_ids_for_metrics = []
            for res_final_item in final_docs_for_metrics_calc:
                doc_data_item = res_final_item.get('doc', {})
                chunk_id_val = None
                if isinstance(doc_data_item, dict): # ƒê·∫£m b·∫£o doc_data_item l√† dict
                    chunk_id_val = doc_data_item.get('id') # ∆Øu ti√™n tr∆∞·ªùng 'id'
                    if not chunk_id_val: # N·∫øu kh√¥ng c√≥, th·ª≠ t√¨m trong metadata
                        metadata = doc_data_item.get('metadata', {})
                        if isinstance(metadata, dict): # ƒê·∫£m b·∫£o metadata l√† dict
                            chunk_id_val = metadata.get('id') or metadata.get('chunk_id') # Th·ª≠ c·∫£ 'id' v√† 'chunk_id' trong metadata
                if chunk_id_val is not None: # Ch·ªâ th√™m n·∫øu chunk_id_val c√≥ gi√° tr·ªã (kh√¥ng ph·∫£i None)
                    retrieved_ids_for_metrics.append(str(chunk_id_val)) # Chuy·ªÉn sang string ƒë·ªÉ so s√°nh

            current_query_metrics["retrieved_ids"] = retrieved_ids_for_metrics
            current_query_metrics["status"] = "evaluated"
            
            # T√≠nh to√°n metrics
            for k_metric_val in k_values_metrics:
                current_query_metrics[f'precision@{k_metric_val}'] = precision_at_k(retrieved_ids_for_metrics, relevant_chunk_ids_set, k_metric_val)
                current_query_metrics[f'recall@{k_metric_val}'] = recall_at_k(retrieved_ids_for_metrics, relevant_chunk_ids_set, k_metric_val)
                current_query_metrics[f'f1@{k_metric_val}'] = f1_at_k(retrieved_ids_for_metrics, relevant_chunk_ids_set, k_metric_val)
                current_query_metrics[f'mrr@{k_metric_val}'] = mrr_at_k(retrieved_ids_for_metrics, relevant_chunk_ids_set, k_metric_val)
                current_query_metrics[f'ndcg@{k_metric_val}'] = ndcg_at_k(retrieved_ids_for_metrics, relevant_chunk_ids_set, k_metric_val)

        except Exception as e_eval:
            current_query_metrics["status"] = "error_runtime_eval"
            current_query_metrics["error_message"] = f"{type(e_eval).__name__}: {str(e_eval)}"
        finally:
            current_query_metrics["processing_time"] = time.time() - eval_query_start_time
            results_list.append(current_query_metrics)
            progress_bar.progress((i + 1) / total_items)

    status_text_area.text(f"Ho√†n th√†nh ƒë√°nh gi√° {total_items} queries!")
    return pd.DataFrame(results_list)

# --- UI STREAMLIT ---
st.set_page_config(page_title="ƒê√°nh gi√° Retrieval", layout="wide")
st.title("üìä ƒê√°nh gi√° H·ªá th·ªëng Retrieval")
st.markdown("Trang n√†y cho ph√©p b·∫°n ch·∫°y ƒë√°nh gi√° hi·ªáu su·∫•t c·ªßa h·ªá th·ªëng retrieval (bao g·ªìm c·∫£ hybrid ƒëa ngu·ªìn) v√† reranking d·ª±a tr√™n m·ªôt t·∫≠p d·ªØ li·ªáu c√≥ g√°n nh√£n.")

# --- Sidebar C·∫•u h√¨nh ƒê√°nh gi√° ---
with st.sidebar:
    st.title("T√πy ch·ªçn ƒê√°nh gi√°")
    
    # Kh·ªüi t·∫°o session state cho trang ƒë√°nh gi√° n·∫øu ch∆∞a c√≥
    DEFAULT_EVAL_CONFIG_STATE_PAGE = {
        "eval_selected_embedding_model": st.session_state.get("eval_selected_embedding_model", config.DEFAULT_EMBEDDING_MODEL),
        "eval_additional_hybrid_models": st.session_state.get("eval_additional_hybrid_models", []), # Cho model ph·ª•
        "eval_selected_gemini_model": st.session_state.get("eval_selected_gemini_model", config.DEFAULT_GEMINI_MODEL),
        "eval_retrieval_query_mode": st.session_state.get("eval_retrieval_query_mode", 'T·ªïng qu√°t'), # 'ƒê∆°n gi·∫£n', 'T·ªïng qu√°t', 'S√¢u'
        "eval_retrieval_method": st.session_state.get("eval_retrieval_method", 'hybrid'), # 'dense', 'sparse', 'hybrid'
        "eval_selected_reranker_model": st.session_state.get("eval_selected_reranker_model", config.DEFAULT_RERANKER_MODEL),
    }
    for key_eval_ss, default_val_eval_ss in DEFAULT_EVAL_CONFIG_STATE_PAGE.items():
        if key_eval_ss not in st.session_state:
            st.session_state[key_eval_ss] = default_val_eval_ss

    st.header("M√¥ h√¨nh")
    # Ch·ªçn Embedding Model ch√≠nh cho ƒë√°nh gi√°
    st.selectbox(
        "Ch·ªçn m√¥ h√¨nh Embedding ch√≠nh:",
        options=config.AVAILABLE_EMBEDDING_MODELS,
        index=config.AVAILABLE_EMBEDDING_MODELS.index(st.session_state.eval_selected_embedding_model),
        key="eval_selected_embedding_model",
        help="Ch·ªçn m√¥ h√¨nh embedding ch√≠nh ƒë·ªÉ ƒë√°nh gi√°."
    )
    # Ch·ªçn Embedding Model ph·ª• cho ƒë√°nh gi√° (ch·ªâ khi hybrid)
    if st.session_state.eval_retrieval_method == 'hybrid':
        available_for_additional_eval = [
            m_eval for m_eval in config.AVAILABLE_EMBEDDING_MODELS 
            if m_eval != st.session_state.eval_selected_embedding_model
        ]
        current_additional_selection_eval = st.session_state.get("eval_additional_hybrid_models", [])
        if not isinstance(current_additional_selection_eval, list): current_additional_selection_eval = []
        valid_current_additional_eval = [m for m in current_additional_selection_eval if m in available_for_additional_eval]

        if available_for_additional_eval:
            selected_additional_eval = st.multiselect(
                "Ch·ªçn th√™m m√¥ h√¨nh Embedding ph·ª• cho Hybrid (t·ªëi ƒëa 2):",
                options=available_for_additional_eval,
                default=valid_current_additional_eval,
                key="eval_additional_hybrid_models_multiselect", # Key ri√™ng cho widget n√†y
                help="Ch·ªçn t·ªëi ƒëa 2 m√¥ h√¨nh embedding ph·ª• ƒë·ªÉ k·∫øt h·ª£p trong ƒë√°nh gi√° hybrid."
            )
            if len(selected_additional_eval) > 2:
                st.warning("T·ªëi ƒëa 2 m√¥ h√¨nh ph·ª•. S·∫Ω l·∫•y 2 l·ª±a ch·ªçn ƒë·∫ßu.")
                st.session_state.eval_additional_hybrid_models = selected_additional_eval[:2]
            else:
                st.session_state.eval_additional_hybrid_models = selected_additional_eval
        else:
            st.markdown("<p style='font-size:0.9em; font-style:italic;'>Kh√¥ng c√≥ m√¥ h√¨nh ph·ª• n√†o kh√°c ƒë·ªÉ ch·ªçn.</p>", unsafe_allow_html=True)
            st.session_state.eval_additional_hybrid_models = []
    else:
        st.session_state.eval_additional_hybrid_models = []


    st.selectbox("Ch·ªçn m√¥ h√¨nh Gemini (t·∫°o query variations):", options=config.AVAILABLE_GEMINI_MODELS,
        index=config.AVAILABLE_GEMINI_MODELS.index(st.session_state.eval_selected_gemini_model),
        key="eval_selected_gemini_model", help="M√¥ h√¨nh LLM ƒë·ªÉ t·∫°o bi·∫øn th·ªÉ c√¢u h·ªèi."
    )
    st.selectbox("Ch·ªçn m√¥ h√¨nh Reranker:", options=config.AVAILABLE_RERANKER_MODELS,
        index=config.AVAILABLE_RERANKER_MODELS.index(st.session_state.eval_selected_reranker_model),
        key="eval_selected_reranker_model", help="M√¥ h√¨nh Reranker ƒë·ªÉ ƒë√°nh gi√° (ho·∫∑c 'Kh√¥ng s·ª≠ d·ª•ng')."
    )
    
    st.header("C·∫•u h√¨nh Retrieval")
    # Index cho radio eval_retrieval_query_mode
    query_mode_options_eval = ['ƒê∆°n gi·∫£n', 'T·ªïng qu√°t', 'S√¢u']
    current_query_mode_idx_eval = query_mode_options_eval.index(st.session_state.eval_retrieval_query_mode) \
        if st.session_state.eval_retrieval_query_mode in query_mode_options_eval else 1 # Default 'T·ªïng qu√°t'
    st.radio("Ngu·ªìn c√¢u h·ªèi cho Retrieval:", options=query_mode_options_eval, index=current_query_mode_idx_eval,
        key="eval_retrieval_query_mode", horizontal=True, help="C√°ch t·∫°o c√¢u h·ªèi ƒë·∫ßu v√†o cho h·ªá th·ªëng retrieval."
    )
    # Index cho radio eval_retrieval_method
    method_options_eval = ['dense', 'sparse', 'hybrid']
    current_method_idx_eval = method_options_eval.index(st.session_state.eval_retrieval_method) \
        if st.session_state.eval_retrieval_method in method_options_eval else 2 # Default 'hybrid'
    st.radio("Ph∆∞∆°ng th·ª©c Retrieval:", options=method_options_eval, index=current_method_idx_eval,
        key="eval_retrieval_method", horizontal=True, help="Ph∆∞∆°ng th·ª©c t√¨m ki·∫øm."
    )

# --- Kh·ªüi t·∫°o c√°c bi·∫øn session state cho trang ƒë√°nh gi√° ---
if 'eval_data' not in st.session_state: st.session_state.eval_data = None
if 'eval_results_df' not in st.session_state: st.session_state.eval_results_df = None
if 'eval_run_completed' not in st.session_state: st.session_state.eval_run_completed = False
if 'eval_uploaded_filename' not in st.session_state: st.session_state.eval_uploaded_filename = None
if "upload_counter_eval" not in st.session_state: st.session_state.upload_counter_eval = 0 # ƒê·ªïi t√™n key
if 'last_eval_config_run' not in st.session_state: st.session_state.last_eval_config_run = {} # ƒê·ªïi t√™n key

# --- Kh·ªüi t·∫°o t√†i nguy√™n c·ªët l√µi cho ƒë√°nh gi√° ---
st.subheader("Tr·∫°ng th√°i H·ªá th·ªëng C∆° b·∫£n cho ƒê√°nh gi√°")
init_ok_eval_page = False
# Primary components
g_primary_embedding_model_eval_obj = None
g_primary_retriever_instance_eval = None
# Reranker
g_reranking_model_eval_obj_loaded = None

with st.spinner("Ki·ªÉm tra v√† kh·ªüi t·∫°o t√†i nguy√™n cho ƒë√°nh gi√°..."):
    try:
        # 1. T·∫£i Embedding Model ch√≠nh
        g_primary_embedding_model_eval_obj = load_embedding_model(st.session_state.eval_selected_embedding_model)
        
        # 2. T·∫£i Retriever ch√≠nh (d·ª±a tr√™n model embedding ch√≠nh)
        if g_primary_embedding_model_eval_obj:
            current_eval_rag_prefix_main = config.get_rag_data_prefix(st.session_state.eval_selected_embedding_model)
            # load_or_create_rag_components tr·∫£ v·ªÅ (vector_db, retriever)
            # Ch√∫ng ta c·∫ßn retriever ch√≠nh ·ªü ƒë√¢y. VectorDB ch√≠nh ƒë√£ n·∫±m trong retriever n√†y.
            _, g_primary_retriever_instance_eval = load_or_create_rag_components(
                g_primary_embedding_model_eval_obj, current_eval_rag_prefix_main
            )
        
        # 3. T·∫£i Reranker Model (n·∫øu ƒë∆∞·ª£c ch·ªçn)
        if st.session_state.eval_selected_reranker_model != 'Kh√¥ng s·ª≠ d·ª•ng':
            g_reranking_model_eval_obj_loaded = load_reranker_model(st.session_state.eval_selected_reranker_model)
        
        # Ki·ªÉm tra ƒëi·ªÅu ki·ªán kh·ªüi t·∫°o th√†nh c√¥ng
        if g_primary_embedding_model_eval_obj and g_primary_retriever_instance_eval:
            init_ok_eval_page = True
            st.success(f"Embedding model ch√≠nh '{st.session_state.eval_selected_embedding_model.split('/')[-1]}' v√† Retriever ch√≠nh s·∫µn s√†ng.")
            
            # Ki·ªÉm tra c√°c model ph·ª• (ch·ªâ th√¥ng b√°o, kh√¥ng l√†m init th·∫•t b·∫°i)
            if st.session_state.eval_retrieval_method == 'hybrid' and st.session_state.eval_additional_hybrid_models:
                st.markdown("---")
                st.write("Ki·ªÉm tra c√°c Embedding Model ph·ª•:")
                for model_name_add_eval_init in st.session_state.eval_additional_hybrid_models:
                    emb_obj_add_eval_init = load_embedding_model(model_name_add_eval_init) # Cache gre normalen
                    if emb_obj_add_eval_init:
                        prefix_add_eval_init = config.get_rag_data_prefix(model_name_add_eval_init)
                        vdb_add_eval_init, _ = load_or_create_rag_components(emb_obj_add_eval_init, prefix_add_eval_init) # Cache gre normalen
                        if vdb_add_eval_init:
                             st.caption(f"- Model ph·ª• '{model_name_add_eval_init.split('/')[-1]}' v√† VDB: S·∫µn s√†ng.")
                        else: st.caption(f"- Model ph·ª• '{model_name_add_eval_init.split('/')[-1]}': L·ªói t·∫£i VDB.")
                    else: st.caption(f"- Model ph·ª• '{model_name_add_eval_init.split('/')[-1]}': L·ªói t·∫£i Embedding Model.")
                st.markdown("---")

            if st.session_state.eval_selected_reranker_model != 'Kh√¥ng s·ª≠ d·ª•ng':
                if g_reranking_model_eval_obj_loaded:
                    st.success(f"Reranker model '{st.session_state.eval_selected_reranker_model.split('/')[-1]}' s·∫µn s√†ng.")
                else:
                    st.warning(f"‚ö†Ô∏è Kh√¥ng t·∫£i ƒë∆∞·ª£c Reranker Model ({st.session_state.eval_selected_reranker_model}).")
            else: st.info("Reranker kh√¥ng ƒë∆∞·ª£c ch·ªçn s·ª≠ d·ª•ng cho ƒë√°nh gi√°.")
        else:
            missing_components = []
            if not g_primary_embedding_model_eval_obj: missing_components.append(f"Embedding Model ch√≠nh ({st.session_state.eval_selected_embedding_model})")
            if not g_primary_retriever_instance_eval: missing_components.append("Retriever/VectorDB ch√≠nh")
            st.error(f"‚ö†Ô∏è L·ªói kh·ªüi t·∫°o cho ƒë√°nh gi√°: {', '.join(missing_components)} kh√¥ng s·∫µn s√†ng.")
            
    except Exception as e_init_eval:
        st.error(f"‚ö†Ô∏è L·ªói nghi√™m tr·ªçng khi kh·ªüi t·∫°o h·ªá th·ªëng cho ƒë√°nh gi√°: {str(e_init_eval)}")

# --- Giao di·ªán ch√≠nh c·ªßa trang ƒë√°nh gi√° ---
if init_ok_eval_page:
    # Hi·ªÉn th·ªã c·∫•u h√¨nh hi·ªán t·∫°i cho ƒë√°nh gi√°
    reranker_display_eval_caption_page = st.session_state.eval_selected_reranker_model.split('/')[-1] \
        if st.session_state.eval_selected_reranker_model != 'Kh√¥ng s·ª≠ d·ª•ng' else "T·∫Øt"
    
    additional_embs_caption_list = []
    if st.session_state.eval_retrieval_method == 'hybrid' and st.session_state.eval_additional_hybrid_models:
        additional_embs_caption_list = [name.split('/')[-1] for name in st.session_state.eval_additional_hybrid_models]
    additional_embs_caption_str = f", Ph·ª•: {', '.join(additional_embs_caption_list)}" if additional_embs_caption_list else ""

    st.caption(
        f"Emb. Ch√≠nh: `{st.session_state.eval_selected_embedding_model.split('/')[-1]}`{additional_embs_caption_str} | "
        f"LLM: `{st.session_state.eval_selected_gemini_model}` | Query: `{st.session_state.eval_retrieval_query_mode}` | "
        f"Retrieval: `{st.session_state.eval_retrieval_method}` | Reranker: `{reranker_display_eval_caption_page}`"
    )

    # T·∫£i file ƒë√°nh gi√°
    uploader_key_eval = f"eval_file_uploader_{st.session_state.upload_counter_eval}"
    st.subheader("1. T·∫£i L√™n File D·ªØ li·ªáu ƒê√°nh gi√°")
    uploaded_file_eval = st.file_uploader("Ch·ªçn file JSON ch·ª©a c√°c c·∫∑p (query, relevant_chunk_ids)...", type=["json"], key=uploader_key_eval)

    if uploaded_file_eval is not None:
        # X·ª≠ l√Ω file m·ªõi t·∫£i l√™n
        if uploaded_file_eval.name != st.session_state.eval_uploaded_filename:
            try:
                eval_data_list_from_file = json.loads(uploaded_file_eval.getvalue().decode('utf-8'))
                # Ki·ªÉm tra c·∫•u tr√∫c c∆° b·∫£n c·ªßa file
                if isinstance(eval_data_list_from_file, list) and \
                   all(isinstance(item, dict) and "query" in item and "relevant_chunk_ids" in item for item in eval_data_list_from_file):
                    st.session_state.eval_data = eval_data_list_from_file
                    st.session_state.eval_uploaded_filename = uploaded_file_eval.name
                    st.session_state.eval_run_completed = False # Reset tr·∫°ng th√°i ch·∫°y
                    st.session_state.last_eval_config_run = {} # Reset c·∫•u h√¨nh ch·∫°y tr∆∞·ªõc
                    st.success(f"ƒê√£ t·∫£i v√† x√°c th·ª±c file '{uploaded_file_eval.name}' ({len(eval_data_list_from_file)} c√¢u h·ªèi).")
                else:
                    st.error("File JSON kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng. M·ªói item ph·∫£i l√† dict c√≥ key 'query' v√† 'relevant_chunk_ids'.")
                    st.session_state.eval_data = None; st.session_state.eval_uploaded_filename = None
            except json.JSONDecodeError:
                st.error("L·ªói gi·∫£i m√£ JSON. Vui l√≤ng ki·ªÉm tra l·∫°i ƒë·ªãnh d·∫°ng file.")
                st.session_state.eval_data = None; st.session_state.eval_uploaded_filename = None
            except Exception as e_file:
                st.error(f"L·ªói x·ª≠ l√Ω file: {str(e_file)}")
                st.session_state.eval_data = None; st.session_state.eval_uploaded_filename = None
    
    # N·∫øu c√≥ d·ªØ li·ªáu ƒë√°nh gi√° ƒë√£ t·∫£i
    if st.session_state.eval_data is not None:
        st.info(f"S·∫µn s√†ng ƒë√°nh gi√° v·ªõi d·ªØ li·ªáu t·ª´: **{st.session_state.eval_uploaded_filename}** ({len(st.session_state.eval_data)} c√¢u h·ªèi).")
        if st.checkbox("Hi·ªÉn th·ªã 5 d√≤ng d·ªØ li·ªáu m·∫´u", key="show_eval_data_preview_checkbox"):
            st.dataframe(pd.DataFrame(st.session_state.eval_data).head())

        st.subheader("2. Ch·∫°y ƒê√°nh gi√°")
        if st.button("üöÄ B·∫Øt ƒë·∫ßu ƒê√°nh gi√° ngay!", key="start_eval_button_main"):
            # --- Chu·∫©n b·ªã c√°c ƒë·ªëi t∆∞·ª£ng model v√† c·∫•u h√¨nh cho l·∫ßn ch·∫°y ƒë√°nh gi√° ---
            current_run_config = {
                'embedding_model_name': st.session_state.eval_selected_embedding_model, # T√™n model ch√≠nh
                'additional_embedding_model_names_eval': list(st.session_state.eval_additional_hybrid_models), # List t√™n model ph·ª•
                'retrieval_query_mode': st.session_state.eval_retrieval_query_mode,
                'retrieval_method': st.session_state.eval_retrieval_method,
                'selected_reranker_model': st.session_state.eval_selected_reranker_model, # T√™n model reranker
                'gemini_model_name': st.session_state.eval_selected_gemini_model, # T√™n model Gemini
                # T√™n model reranker th·ª±c s·ª± ƒë∆∞·ª£c s·ª≠ d·ª•ng (n·∫øu c√≥)
                'reranker_model_name_actually_used': st.session_state.eval_selected_reranker_model \
                    if g_reranking_model_eval_obj_loaded and st.session_state.eval_selected_reranker_model != 'Kh√¥ng s·ª≠ d·ª•ng' \
                    else "Kh√¥ng s·ª≠ d·ª•ng"
            }
            st.session_state.last_eval_config_run = current_run_config.copy()

            # T·∫£i LLM (Gemini) cho vi·ªác t·∫°o query variations
            with st.spinner(f"ƒêang t·∫£i model Gemini cho ƒë√°nh gi√°: {st.session_state.eval_selected_gemini_model}..."):
                 g_gemini_model_for_eval_run_obj = load_gemini_model(st.session_state.eval_selected_gemini_model) # Cache gre normalen

            if not g_gemini_model_for_eval_run_obj:
                st.error(f"Kh√¥ng th·ªÉ t·∫£i model Gemini '{st.session_state.eval_selected_gemini_model}' cho ƒë√°nh gi√°. Vui l√≤ng th·ª≠ l·∫°i."); st.stop()

            # Chu·∫©n b·ªã c√°c ngu·ªìn dense ph·ª• (embedding model objects v√† VDB objects)
            additional_dense_sources_for_current_eval_run = []
            if current_run_config['retrieval_method'] == 'hybrid' and current_run_config['additional_embedding_model_names_eval']:
                with st.spinner("ƒêang chu·∫©n b·ªã c√°c ngu·ªìn embedding ph·ª• cho ƒë√°nh gi√°..."):
                    for model_name_add_eval in current_run_config['additional_embedding_model_names_eval']:
                        emb_obj_add_eval = load_embedding_model(model_name_add_eval) # Cache gre normalen
                        if emb_obj_add_eval:
                            prefix_add_eval = config.get_rag_data_prefix(model_name_add_eval)
                            vdb_add_eval, _ = load_or_create_rag_components(emb_obj_add_eval, prefix_add_eval) # Cache gre normalen
                            if vdb_add_eval:
                                additional_dense_sources_for_current_eval_run.append((emb_obj_add_eval, vdb_add_eval))
                            else: st.warning(f"Kh√¥ng t·∫£i ƒë∆∞·ª£c VDB cho model ph·ª• '{model_name_add_eval}' trong ƒë√°nh gi√°. B·ªè qua.")
                        else: st.warning(f"Kh√¥ng t·∫£i ƒë∆∞·ª£c Embedding Model ph·ª• '{model_name_add_eval}' trong ƒë√°nh gi√°. B·ªè qua.")
            
            st.info(f"Model Gemini '{st.session_state.eval_selected_gemini_model}' v√† c√°c t√†i nguy√™n kh√°c ƒë√£ s·∫µn s√†ng.")
            with st.spinner("‚è≥ ƒêang ch·∫°y ƒë√°nh gi√° to√†n b·ªô t·∫≠p d·ªØ li·ªáu... Qu√° tr√¨nh n√†y c√≥ th·ªÉ m·∫•t v√†i ph√∫t ƒë·∫øn v√†i ch·ª•c ph√∫t t√πy thu·ªôc v√†o s·ªë l∆∞·ª£ng c√¢u h·ªèi v√† c·∫•u h√¨nh."):
                eval_run_start_time = time.time()
                
                # G·ªçi h√†m ch·∫°y ƒë√°nh gi√°
                results_df_output = run_retrieval_evaluation(
                    eval_data=st.session_state.eval_data,
                    primary_hybrid_retriever=g_primary_retriever_instance_eval, # Retriever ch√≠nh
                    primary_embedding_model_object=g_primary_embedding_model_eval_obj, # Model object ch√≠nh
                    additional_dense_sources_for_eval=additional_dense_sources_for_current_eval_run, # List (emb_obj, vdb_obj) ph·ª•
                    reranking_model_selected_obj=g_reranking_model_eval_obj_loaded, # Reranker object (ho·∫∑c None)
                    gemini_model_obj=g_gemini_model_for_eval_run_obj, # Gemini object
                    eval_config=st.session_state.last_eval_config_run # Dict c·∫•u h√¨nh
                )
                total_eval_run_time = time.time() - eval_run_start_time
                st.success(f"üéâ Ho√†n th√†nh ƒë√°nh gi√° to√†n b·ªô d·ªØ li·ªáu sau {total_eval_run_time:.2f} gi√¢y.")
                st.session_state.eval_results_df = results_df_output
                st.session_state.eval_run_completed = True
                st.rerun() # Ch·∫°y l·∫°i ƒë·ªÉ hi·ªÉn th·ªã k·∫øt qu·∫£

    # --- Hi·ªÉn th·ªã k·∫øt qu·∫£ ƒë√°nh gi√° ---
    if st.session_state.eval_run_completed and st.session_state.eval_results_df is not None:
        st.subheader("3. K·∫øt qu·∫£ ƒê√°nh gi√°")
        detailed_results_df_display = st.session_state.eval_results_df
        last_run_config_display = st.session_state.last_eval_config_run

        st.markdown("**C·∫•u h√¨nh ƒë√£ s·ª≠ d·ª•ng cho l·∫ßn ch·∫°y cu·ªëi:**")
        # S·ª≠ d·ª•ng c·ªôt ƒë·ªÉ hi·ªÉn th·ªã g·ªçn g√†ng h∆°n
        cfg_col_main, cfg_col_add, cfg_col_ret, cfg_col_rerank = st.columns(4)
        
        primary_emb_name_res = last_run_config_display.get('embedding_model_name', 'N/A').split('/')[-1]
        cfg_col_main.metric("Embedding Ch√≠nh", primary_emb_name_res)

        add_emb_names_res_list = []
        if last_run_config_display.get('additional_embedding_model_names_eval'):
            add_emb_names_res_list = [name.split('/')[-1] for name in last_run_config_display.get('additional_embedding_model_names_eval')]
        cfg_col_add.metric("Embeddings Ph·ª•", ", ".join(add_emb_names_res_list) if add_emb_names_res_list else "Kh√¥ng")
        
        cfg_col_ret.metric("Retrieval Method", last_run_config_display.get('retrieval_method', 'N/A'))
        
        reranker_name_res = last_run_config_display.get('selected_reranker_model', 'N/A') # T√™n model reranker t·ª´ config
        reranker_name_disp_res = reranker_name_res.split('/')[-1] if reranker_name_res != 'Kh√¥ng s·ª≠ d·ª•ng' else "T·∫Øt"
        cfg_col_rerank.metric("Reranker Config", reranker_name_disp_res)

        st.caption(
            f"LLM (Variations): `{last_run_config_display.get('gemini_model_name', 'N/A')}` | "
            f"Ngu·ªìn Query: `{last_run_config_display.get('retrieval_query_mode', 'N/A')}` | "
            f"Reranker th·ª±c t·∫ø d√πng: `{last_run_config_display.get('reranker_model_name_actually_used', 'N/A').split('/')[-1] if last_run_config_display.get('reranker_model_name_actually_used') != 'Kh√¥ng s·ª≠ d·ª•ng' else 'T·∫Øt'}`"
        )
        
        # T√≠nh to√°n metrics trung b√¨nh
        avg_metrics_results, num_evaluated_queries, num_skipped_or_error_queries = calculate_average_metrics(detailed_results_df_display)

        st.metric("T·ªïng s·ªë Queries trong File", len(detailed_results_df_display))
        col_res_count1, col_res_count2 = st.columns(2)
        col_res_count1.metric("Queries ƒê√°nh gi√° H·ª£p l·ªá (status='evaluated')", num_evaluated_queries)
        col_res_count2.metric("Queries B·ªè qua / L·ªói", num_skipped_or_error_queries)

        if avg_metrics_results:
            st.markdown("#### Metrics Trung b√¨nh @K (tr√™n c√°c queries h·ª£p l·ªá)")
            k_values_for_display = [3, 5, 10] # C√°c gi√° tr·ªã K mu·ªën hi·ªÉn th·ªã
            cols_k_metrics = st.columns(len(k_values_for_display))
            for idx_k_disp, k_val_disp in enumerate(k_values_for_display):
                with cols_k_metrics[idx_k_disp]:
                    st.markdown(f"**K = {k_val_disp}**")
                    st.text(f"Precision: {avg_metrics_results.get(f'avg_precision@{k_val_disp}', 0.0):.4f}")
                    st.text(f"Recall:    {avg_metrics_results.get(f'avg_recall@{k_val_disp}', 0.0):.4f}")
                    st.text(f"F1 Score:  {avg_metrics_results.get(f'avg_f1@{k_val_disp}', 0.0):.4f}")
                    st.text(f"MRR:       {avg_metrics_results.get(f'avg_mrr@{k_val_disp}', 0.0):.4f}")
                    st.text(f"NDCG:      {avg_metrics_results.get(f'avg_ndcg@{k_val_disp}', 0.0):.4f}")
            
            st.markdown("#### Th√¥ng tin Hi·ªáu nƒÉng & S·ªë l∆∞·ª£ng Trung b√¨nh (tr√™n c√°c queries h·ª£p l·ªá)")
            perf_col1, perf_col2, perf_col3 = st.columns(3)
            perf_col1.metric("Avg Process Time (s)", f"{avg_metrics_results.get('avg_processing_time', 0.0):.2f}s")
            perf_col1.metric("Avg Variation Time (s)", f"{avg_metrics_results.get('avg_variation_time', 0.0):.2f}s")
            perf_col2.metric("Avg Search Time (s)", f"{avg_metrics_results.get('avg_search_time', 0.0):.2f}s")
            perf_col2.metric("Avg Rerank Time (s)", f"{avg_metrics_results.get('avg_rerank_time', 0.0):.2f}s")
            
            perf_col3.metric("Avg Variations Gen.", f"{avg_metrics_results.get('avg_num_variations_generated', 0.0):.1f}")
            perf_col3.metric("Avg Docs Found (Unique)", f"{avg_metrics_results.get('avg_num_unique_docs_found', 0.0):.1f}")
            perf_col3.metric("Avg Docs to Rerank", f"{avg_metrics_results.get('avg_num_docs_reranked', 0.0):.1f}")
            perf_col3.metric("Avg Docs After Rerank/Limit", f"{avg_metrics_results.get('avg_num_retrieved_after_rerank', 0.0):.1f}")

        with st.expander("Xem K·∫øt qu·∫£ Chi ti·∫øt cho t·ª´ng Query", expanded=False):
            cols_to_display_ordered = [
                'query_id', 'query', 'status', 'error_message',
                'embedding_model_name', 'additional_embedding_models_used', # Th√™m c·ªôt model ph·ª• ƒë√£ d√πng
                'retrieval_query_mode','retrieval_method', 'selected_reranker_model',
                'precision@3', 'recall@3', 'f1@3', 'mrr@3', 'ndcg@3',
                'precision@5', 'recall@5', 'f1@5', 'mrr@5', 'ndcg@5',
                'precision@10', 'recall@10', 'f1@10', 'mrr@10', 'ndcg@10',
                'processing_time', 'variation_time', 'search_time', 'rerank_time',
                'num_variations_generated','num_unique_docs_found', 
                'num_retrieved_before_rerank','num_docs_reranked', 'num_retrieved_after_rerank',
                'retrieved_ids', 'relevant_ids', 'summarizing_query'
            ]
            # L·ªçc ra c√°c c·ªôt th·ª±c s·ª± c√≥ trong DataFrame ƒë·ªÉ tr√°nh l·ªói
            existing_cols_for_display = [col_disp for col_disp in cols_to_display_ordered if col_disp in detailed_results_df_display.columns]
            st.dataframe(detailed_results_df_display[existing_cols_for_display])

        st.subheader("4. L∆∞u K·∫øt qu·∫£ Chi ti·∫øt")
        try:
            results_json_output = detailed_results_df_display.to_json(orient='records', indent=2, force_ascii=False)
            results_csv_output = detailed_results_df_display.to_csv(index=False).encode('utf-8')
            current_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

            emb_main_suffix = last_run_config_display.get('embedding_model_name', 'na').split('/')[-1].replace('-', '').replace('_', '')[:10]
            add_emb_suffix = "none"
            if last_run_config_display.get('additional_embedding_model_names_eval'):
                add_emb_suffix = "_".join([name.split('/')[-1].replace('-', '').replace('_', '')[:5] for name in last_run_config_display.get('additional_embedding_model_names_eval')])
            
            qmode_file_suffix = last_run_config_display.get('retrieval_query_mode', 'na').lower()[:3]
            method_file_suffix = last_run_config_display.get('retrieval_method', 'na').lower()
            
            reranker_file_suffix_used = "NoRerank"
            selected_reranker_for_filename_actual = last_run_config_display.get('reranker_model_name_actually_used', 'Kh√¥ng s·ª≠ d·ª•ng')
            if selected_reranker_for_filename_actual != 'Kh√¥ng s·ª≠ d·ª•ng':
                  reranker_file_suffix_used = selected_reranker_for_filename_actual.split('/')[-1].replace('-', '').replace('_', '')[:10]
            
            llm_file_suffix = last_run_config_display.get('gemini_model_name', 'gemini').split('/')[-1].replace('.','-')[:15]

            base_output_filename = f"evalRes_{emb_main_suffix}_add_{add_emb_suffix}_{qmode_file_suffix}_{method_file_suffix}_{reranker_file_suffix_used}_{llm_file_suffix}_{current_timestamp}"
            final_fname_json = f"{base_output_filename}.json"
            final_fname_csv = f"{base_output_filename}.csv"

            dl_col1, dl_col2 = st.columns(2)
            with dl_col1:
                st.download_button("üíæ T·∫£i v·ªÅ JSON", results_json_output, final_fname_json, "application/json", key="download_json_button")
            with dl_col2:
                st.download_button("üíæ T·∫£i v·ªÅ CSV", results_csv_output, final_fname_csv, "text/csv", key="download_csv_button")
        except Exception as e_savefile:
            st.error(f"L·ªói khi chu·∫©n b·ªã file k·∫øt qu·∫£ ƒë·ªÉ t·∫£i v·ªÅ: {str(e_savefile)}")
    
    st.markdown("---")
    st.subheader("Qu·∫£n l√Ω Tr·∫°ng th√°i ƒê√°nh gi√° Hi·ªán t·∫°i")
    if st.button("X√≥a File ƒê√£ T·∫£i v√† K·∫øt Qu·∫£ ƒê√°nh gi√° Hi·ªán t·∫°i", key="clear_current_eval_state_button"):
        st.session_state.eval_data = None
        st.session_state.upload_counter_eval += 1 # Thay ƒë·ªïi key uploader ƒë·ªÉ reset
        st.session_state.eval_run_completed = False
        st.session_state.eval_results_df = None
        st.session_state.last_eval_config_run = {}
        st.session_state.eval_uploaded_filename = None
        st.success("ƒê√£ x√≥a tr·∫°ng th√°i c·ªßa l·∫ßn ƒë√°nh gi√° hi·ªán t·∫°i (file t·∫£i l√™n, k·∫øt qu·∫£).")
        time.sleep(1); st.rerun()
else:
    st.warning("‚ö†Ô∏è H·ªá th·ªëng c∆° b·∫£n cho trang ƒë√°nh gi√° ch∆∞a s·∫µn s√†ng. Vui l√≤ng ki·ªÉm tra l·ªói v√† th·ª≠ l√†m m·ªõi trang.")