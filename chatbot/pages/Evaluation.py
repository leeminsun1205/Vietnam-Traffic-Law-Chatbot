# pages/2_Evaluation.py
import time
import streamlit as st
import pandas as pd
import json
import os
from datetime import datetime
import sys
import numpy as np # Import numpy for isinstance checks
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
import config
import utils
import data_loader
from retriever import HybridRetriever
from utils import precision_at_k, recall_at_k, f1_at_k, mrr_at_k, ndcg_at_k, calculate_average_metrics

def run_retrieval_evaluation(
    eval_data: list,
    hybrid_retriever: HybridRetriever,
    embedding_model,
    reranking_model,
    gemini_model,
    eval_config: dict,
    progress_bar_placeholder, # Truy·ªÅn placeholder v√†o h√†m
    status_text_placeholder # Truy·ªÅn placeholder v√†o h√†m
    ):

    results_list = []
    k_values = [3, 5, 10]

    # --- L·∫•y c·∫•u h√¨nh t·ª´ eval_config ---
    retrieval_query_mode = eval_config.get('retrieval_query_mode', 'T·ªïng qu√°t')
    retrieval_method = eval_config.get('retrieval_method', 'hybrid')
    use_reranker = eval_config.get('use_reranker', True)

    # T·∫°o thanh ti·∫øn tr√¨nh v√† text status b√™n trong placeholder ƒë∆∞·ª£c truy·ªÅn v√†o
    progress_bar = progress_bar_placeholder.progress(0)
    status_text = status_text_placeholder.empty()


    total_items = len(eval_data)
    queries_per_batch = 15 # Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng query tr∆∞·ªõc khi t·∫°m d·ª´ng
    wait_time_seconds = 60 # Th·ªùi gian t·∫°m d·ª´ng


    # ƒê·∫∑t c·ªù h·ªßy b·ªè v·ªÅ False khi b·∫Øt ƒë·∫ßu ch·∫°y (ƒë·∫£m b·∫£o reset sau khi rerun)
    st.session_state.cancel_eval_requested = False


    for i, item in enumerate(eval_data):
        # --- KI·ªÇM TRA Y√äU C·∫¶U H·ª¶Y B·ªé ---
        if st.session_state.cancel_eval_requested:
            status_text.warning(f"ƒê√£ h·ªßy b·ªè qu√° tr√¨nh ƒë√°nh gi√° t·∫°i query {i}/{total_items}.")
            break # Tho√°t kh·ªèi v√≤ng l·∫∑p ch√≠nh

        # T·∫°m d·ª´ng sau m·ªói batch
        if i > 0 and i % queries_per_batch == 0:
            pause_msg = f"ƒê√£ x·ª≠ l√Ω {i}/{total_items} queries. T·∫°m d·ª´ng {wait_time_seconds} gi√¢y..."
            status_text.text(pause_msg)
            time.sleep(wait_time_seconds)
            # Ki·ªÉm tra l·∫°i y√™u c·∫ßu h·ªßy b·ªè sau khi t·∫°m d·ª´ng
            if st.session_state.cancel_eval_requested:
                status_text.warning(f"ƒê√£ h·ªßy b·ªè qu√° tr√¨nh ƒë√°nh gi√° t·∫°i query {i}/{total_items}.")
                break # Tho√°t kh·ªèi v√≤ng l·∫∑p ch√≠nh

            status_text.text(f"Ti·∫øp t·ª•c x·ª≠ l√Ω query {i+1}/{total_items}...")


        query_id = item.get("query_id"); original_query = item.get("query")
        relevant_chunk_ids = set(item.get("relevant_chunk_ids", []))

        status_text.text(f"ƒêang x·ª≠ l√Ω query {i+1}/{total_items}: {query_id} (QueryMode: {retrieval_query_mode}, Method: {retrieval_method}, Rerank: {'B·∫≠t' if use_reranker else 'T·∫Øt'})")


        start_time = time.time()
        # --- Kh·ªüi t·∫°o query_metrics v·ªõi c√°c tr∆∞·ªùng c·∫•u h√¨nh ---
        query_metrics = {
            "query_id": query_id, "query": original_query,
            "retrieval_query_mode": retrieval_query_mode,
            "retrieval_method": retrieval_method,
            "use_reranker": use_reranker,
            "status": "error", "retrieved_ids": [], "relevant_ids": list(relevant_chunk_ids),
            "processing_time": 0.0, 'summarizing_query': '',
            'variation_time': 0.0, 'search_time': 0.0, 'rerank_time': 0.0,
            'num_variations_generated': 0, 'num_unique_docs_found': 0, 'num_docs_reranked': 0,
            'num_retrieved_before_rerank': 0, 'num_retrieved_after_rerank': 0
        }
        # V√≤ng l·∫∑p kh·ªüi t·∫°o metrics, t·ª± ƒë·ªông d√πng k_values m·ªõi
        for k in k_values:
            query_metrics[f'precision@{k}'] = 0.0; query_metrics[f'recall@{k}'] = 0.0
            query_metrics[f'f1@{k}'] = 0.0; query_metrics[f'mrr@{k}'] = 0.0; query_metrics[f'ndcg@{k}'] = 0.0

        try:
            # B∆∞·ªõc 1: T·∫°o variations/summarizing query (lu√¥n ch·∫°y)
            variation_start = time.time()
            relevance_status, _, all_queries, summarizing_query = utils.generate_query_variations(
                original_query=original_query, gemini_model=gemini_model,
                chat_history=None, # Kh√¥ng d√πng l·ªãch s·ª≠ chat cho ƒë√°nh gi√° retrieval
                num_variations=config.NUM_QUERY_VARIATIONS
            )
            query_metrics["variation_time"] = time.time() - variation_start
            query_metrics["summarizing_query"] = summarizing_query
            query_metrics["num_variations_generated"] = len(all_queries) - 1 # Tr·ª´ query g·ªëc

            if relevance_status == 'invalid':
                query_metrics["status"] = "skipped_irrelevant"
                query_metrics["processing_time"] = time.time() - start_time
                results_list.append(query_metrics)
                progress_bar.progress((i + 1) / total_items)
                continue

            # --- B∆∞·ªõc 2: X√°c ƒë·ªãnh query(s) ƒë·ªÉ t√¨m ki·∫øm ---
            queries_to_search = []
            if retrieval_query_mode == 'ƒê∆°n gi·∫£n': queries_to_search = [original_query]
            elif retrieval_query_mode == 'T·ªïng qu√°t': queries_to_search = [summarizing_query]
            elif retrieval_query_mode == 'S√¢u': queries_to_search = all_queries

            # --- B∆∞·ªõc 3: Th·ª±c hi·ªán Retrieval ---
            collected_docs_data = {}
            search_start = time.time()
            if hybrid_retriever: # Ch·ªâ search n·∫øu retriever kh·∫£ d·ª•ng
                 for q_variant in queries_to_search:
                    if not q_variant: continue
                    search_results = hybrid_retriever.search(
                        q_variant, embedding_model,
                        method=retrieval_method,
                        k=config.VECTOR_K_PER_QUERY
                    )
                    for item in search_results:
                        doc_index = item.get('index')
                        # ƒê·∫£m b·∫£o doc_index l√† s·ªë nguy√™n h·ª£p l·ªá tr∆∞·ªõc khi th√™m v√†o dict
                        if isinstance(doc_index, int) and doc_index >= 0 and doc_index not in collected_docs_data:
                            collected_docs_data[doc_index] = item
            query_metrics["search_time"] = time.time() - search_start
            query_metrics["num_unique_docs_found"] = len(collected_docs_data)

            # --- Chu·∫©n b·ªã danh s√°ch k·∫øt qu·∫£ retrieval ---
            retrieved_docs_list = list(collected_docs_data.values())
            sort_reverse = (retrieval_method != 'dense') # Dense sort theo distance (nh·ªè t·ªët h∆°n), Sparse/Hybrid sort theo score (l·ªõn t·ªët h∆°n)
            retrieved_docs_list.sort(key=lambda x: x.get('score', 0 if sort_reverse else float('inf')), reverse=sort_reverse)
            query_metrics["num_retrieved_before_rerank"] = len(retrieved_docs_list)


            # --- B∆∞·ªõc 4: Re-ranking (N·∫øu b·∫≠t v√† model kh·∫£ d·ª•ng) ---
            final_docs_for_metrics = []
            rerank_time = 0.0 # Kh·ªüi t·∫°o rerank_time
            rerank_start = time.time()

            # Ch·ªâ th·ª±c hi·ªán reranking n·∫øu use_reranker B·∫¨T V√Ä reranking_model T·ªíN T·∫†I V√Ä c√≥ k·∫øt qu·∫£ retrieval
            if use_reranker and reranking_model and retrieved_docs_list:
                query_for_reranking = summarizing_query if summarizing_query else original_query # S·ª≠ d·ª•ng c√¢u h·ªèi t√≥m t·∫Øt ho·∫∑c g·ªëc cho rerank
                docs_to_rerank = retrieved_docs_list[:config.MAX_DOCS_FOR_RERANK] # Ch·ªâ rerank top N

                query_metrics["num_docs_reranked"] = len(docs_to_rerank)

                # Chuy·ªÉn ƒë·ªïi ƒë·ªãnh d·∫°ng ƒë·∫ßu v√†o cho rerank_documents
                rerank_input = [{'doc': item.get('doc', {}), 'index': item.get('index')} for item in docs_to_rerank if 'doc' in item]

                if rerank_input: # Ch·ªâ g·ªçi rerank n·∫øu c√≥ input
                    reranked_results = utils.rerank_documents(
                        query_for_reranking, rerank_input, reranking_model
                    )
                    # L·∫•y top K k·∫øt qu·∫£ cu·ªëi c√πng sau rerank
                    final_docs_for_metrics = reranked_results[:config.FINAL_NUM_RESULTS_AFTER_RERANK]
                    rerank_time = time.time() - rerank_start
                else:
                     # Kh√¥ng c√≥ docs ƒë·ªÉ rerank
                     rerank_time = 0.0
                     query_metrics["num_docs_reranked"] = 0

            elif retrieved_docs_list: # Kh√¥ng d√πng reranker HO·∫∂C reranker model kh√¥ng t·∫£i ƒë∆∞·ª£c, nh∆∞ng c√≥ k·∫øt qu·∫£ retrieval
                final_docs_for_metrics = retrieved_docs_list[:config.FINAL_NUM_RESULTS_AFTER_RERANK] # L·∫•y top K tr·ª±c ti·∫øp t·ª´ retrieval
                rerank_time = 0.0
                query_metrics["num_docs_reranked"] = 0
            else: # Kh√¥ng c√≥ k·∫øt qu·∫£ retrieval n√†o
                 rerank_time = 0.0
                 query_metrics["num_docs_reranked"] = 0

            query_metrics["rerank_time"] = rerank_time # L∆∞u th·ªùi gian rerank ƒë√£ t√≠nh
            query_metrics["num_retrieved_after_rerank"] = len(final_docs_for_metrics)


            # --- B∆∞·ªõc 5: L·∫•y IDs v√† T√≠nh Metrics ---
            retrieved_ids = []
            for res in final_docs_for_metrics:
                doc = res.get('doc', {}); original_index = res.get('original_index', res.get('index')) # L·∫•y original_index t·ª´ k·∫øt qu·∫£ rerank n·∫øu c√≥, fallback v·ªÅ index ban ƒë·∫ßu
                chunk_id = None

                # C·ªë g·∫Øng l·∫•y chunk_id t·ª´ doc data
                if isinstance(doc, dict):
                     # ∆Øu ti√™n l·∫•y t·ª´ metadata tr∆∞·ªõc
                    metadata = doc.get('metadata', {})
                    if isinstance(metadata, dict):
                        chunk_id = metadata.get('chunk_id') or metadata.get('id')
                     # N·∫øu kh√¥ng c√≥ trong metadata, th·ª≠ l·∫•y tr·ª±c ti·∫øp t·ª´ doc
                    if not chunk_id:
                        chunk_id = doc.get('id')

                # Fallback l·∫•y t·ª´ original_index n·∫øu chunk_id kh√¥ng t√¨m th·∫•y
                # ƒêi·ªÅu n√†y y√™u c·∫ßu truy c·∫≠p l·∫°i d·ªØ li·ªáu g·ªëc t·ª´ retriever instance
                if not chunk_id and isinstance(original_index, (int, np.integer)):
                    if hybrid_retriever and hasattr(hybrid_retriever, 'documents') and isinstance(hybrid_retriever.documents, list) and 0 <= original_index < len(hybrid_retriever.documents):
                        doc_from_retriever = hybrid_retriever.documents[original_index]
                        if isinstance(doc_from_retriever, dict):
                            metadata_from_retriever = doc_from_retriever.get('metadata', {})
                            if isinstance(metadata_from_retriever, dict):
                                chunk_id = metadata_from_retriever.get('chunk_id') or metadata_from_retriever.get('id')
                            if not chunk_id:
                                chunk_id = doc_from_retriever.get('id')


                if chunk_id is not None: # Ki·ªÉm tra None thay v√¨ ch·ªâ True/False
                    retrieved_ids.append(str(chunk_id)) # ƒê·∫£m b·∫£o l√† string


            query_metrics["retrieved_ids"] = retrieved_ids

            query_metrics["status"] = "evaluated"
            # V√≤ng l·∫∑p t√≠nh metrics, t·ª± ƒë·ªông d√πng k_values m·ªõi
            for k in k_values:
                query_metrics[f'precision@{k}'] = precision_at_k(retrieved_ids, relevant_chunk_ids, k)
                query_metrics[f'recall@{k}'] = recall_at_k(retrieved_ids, relevant_chunk_ids, k)
                query_metrics[f'f1@{k}'] = f1_at_k(retrieved_ids, relevant_chunk_ids, k)
                query_metrics[f'mrr@{k}'] = mrr_at_k(retrieved_ids, relevant_chunk_ids, k)
                query_metrics[f'ndcg@{k}'] = ndcg_at_k(retrieved_ids, relevant_chunk_ids, k)


        except Exception as e:
            query_metrics["status"] = "error_runtime"
            query_metrics["error_message"] = str(e)
        finally:
            query_metrics["processing_time"] = time.time() - start_time
            results_list.append(query_metrics)
            progress_bar.progress((i + 1) / total_items)

    # C·∫≠p nh·∫≠t thanh ti·∫øn tr√¨nh v√† tr·∫°ng th√°i sau khi ho√†n th√†nh ho·∫∑c h·ªßy b·ªè
    if st.session_state.cancel_eval_requested:
         progress_bar.progress((i + 1) / total_items) # Hi·ªÉn th·ªã ti·∫øn ƒë·ªô t·∫°i th·ªùi ƒëi·ªÉm h·ªßy
         # Tr·∫°ng th√°i h·ªßy b·ªè ƒë√£ ƒë∆∞·ª£c hi·ªÉn th·ªã b√™n trong v√≤ng l·∫∑p
    else:
        status_text.text(f"Ho√†n th√†nh ƒë√°nh gi√° {total_items} queries!")


    return pd.DataFrame(results_list)

# --- Giao di·ªán Streamlit ---
st.set_page_config(page_title="ƒê√°nh gi√° Retrieval", layout="wide")
st.title("üìä ƒê√°nh gi√° H·ªá th·ªëng Retrieval")

st.markdown("""
Trang n√†y cho ph√©p b·∫°n ch·∫°y ƒë√°nh gi√° hi·ªáu su·∫•t c·ªßa h·ªá th·ªëng retrieval v√† reranking
d·ª±a tr√™n m·ªôt t·∫≠p d·ªØ li·ªáu c√¢u h·ªèi v√† c√°c chunk t√†i li·ªáu li√™n quan (ground truth).
S·ª≠ d·ª•ng c·∫•u h√¨nh **hi·ªán t·∫°i ƒë∆∞·ª£c ch·ªçn tr√™n sidebar c·ªßa trang n√†y**.
""")

# --- sidebar ---
with st.sidebar:
    st.title("T√πy ch·ªçn ƒê√°nh gi√°")

    # --- Kh·ªüi t·∫°o ho·∫∑c ki·ªÉm tra t·∫•t c·∫£ c√°c bi·∫øn Session State c·∫ßn thi·∫øt ---
    # ƒê·∫£m b·∫£o t·∫•t c·∫£ c√°c key ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÅu c√≥ gi√° tr·ªã m·∫∑c ƒë·ªãnh n·∫øu ch∆∞a t·ªìn t·∫°i
    if "selected_gemini_model" not in st.session_state:
        st.session_state.selected_gemini_model = config.DEFAULT_GEMINI_MODEL
    if "retrieval_query_mode" not in st.session_state:
        st.session_state.retrieval_query_mode = 'T·ªïng qu√°t'
    if "retrieval_method" not in st.session_state:
        st.session_state.retrieval_method = 'hybrid'
    if "use_reranker" not in st.session_state:
        st.session_state.use_reranker = True

    # State cho d·ªØ li·ªáu v√† k·∫øt qu·∫£ ƒë√°nh gi√°
    if 'eval_data' not in st.session_state:
        st.session_state.eval_data = None
    if 'eval_results_df' not in st.session_state:
        st.session_state.eval_results_df = None
    if 'eval_run_completed' not in st.session_state:
        st.session_state.eval_run_completed = False
    if 'eval_uploaded_filename' not in st.session_state:
        st.session_state.eval_uploaded_filename = "" # S·ª≠ d·ª•ng chu·ªói r·ªóng cho tr·∫°ng th√°i ban ƒë·∫ßu
    if 'last_eval_config' not in st.session_state:
        st.session_state.last_eval_config = {}

    # State cho ti·∫øn tr√¨nh v√† h·ªßy b·ªè
    if 'cancel_eval_requested' not in st.session_state:
        st.session_state.cancel_eval_requested = False
    if 'status_message' not in st.session_state:
         st.session_state.status_message = "Ch∆∞a s·∫µn s√†ng." # Tr·∫°ng th√°i hi·ªÉn th·ªã ch√≠nh

    # State cho c√°c instance h·ªá th·ªëng (models, retriever)
    if 'g_embedding_model' not in st.session_state:
        st.session_state.g_embedding_model = None
    if 'g_reranking_model_loaded' not in st.session_state:
        st.session_state.g_reranking_model_loaded = None
    if 'retriever_instance' not in st.session_state:
        st.session_state.retriever_instance = None
    if 'vector_db_instance' not in st.session_state: # C≈©ng l∆∞u vector_db n·∫øu c·∫ßn
         st.session_state.vector_db_instance = None


    st.header("M√¥ h√¨nh")
    st.selectbox(
        "Ch·ªçn m√¥ h√¨nh Gemini (ƒë·ªÉ t·∫°o query variations):",
        options=config.AVAILABLE_GEMINI_MODELS,
        index=config.AVAILABLE_GEMINI_MODELS.index(st.session_state.selected_gemini_model), # ƒê·ªçc t·ª´ state
        key="selected_gemini_model", # Ghi v√†o state khi thay ƒë·ªïi
        help="Ch·ªçn m√¥ h√¨nh ng√¥n ng·ªØ l·ªõn ƒë·ªÉ ph√¢n t√≠ch v√† t·∫°o bi·∫øn th·ªÉ c√¢u h·ªèi cho Retrieval."
    )

    st.header("C·∫•u h√¨nh Retrieval")

    st.radio(
        "Ngu·ªìn c√¢u h·ªèi cho Retrieval:",
        options=['ƒê∆°n gi·∫£n', 'T·ªïng qu√°t', 'S√¢u'],
        index=['ƒê∆°n gi·∫£n', 'T·ªïng qu√°t', 'S√¢u'].index(st.session_state.retrieval_query_mode), # ƒê·ªçc t·ª´ state
        key="retrieval_query_mode", # Ghi v√†o state khi thay ƒë·ªïi
        horizontal=True,
        help=(
            "**ƒê∆°n gi·∫£n:** Ch·ªâ d√πng c√¢u h·ªèi g·ªëc.\n"
            "**T·ªïng qu√°t:** Ch·ªâ d√πng c√¢u h·ªèi t√≥m t·∫Øt (do AI t·∫°o).\n"
            "**S√¢u:** D√πng c·∫£ c√¢u h·ªèi g·ªëc v√† c√°c bi·∫øn th·ªÉ (do AI t·∫°o)."
        )
    )

    st.radio(
        "Ph∆∞∆°ng th·ª©c Retrieval:",
        options=['dense', 'sparse', 'hybrid'],
        index=['dense', 'sparse', 'hybrid'].index(st.session_state.retrieval_method), # ƒê·ªçc t·ª´ state
        key="retrieval_method", # Ghi v√†o state khi thay ƒë·ªïi
        horizontal=True,
        help=(
            "**dense:** T√¨m ki·∫øm d·ª±a tr√™n vector ng·ªØ nghƒ©a.\n"
            "**sparse:** T√¨m ki·∫øm d·ª±a tr√™n t·ª´ kh√≥a (BM25).\n"
            "**hybrid:** K·∫øt h·ª£p c·∫£ dense v√† sparse."
        )
    )

    # Widget ƒë·ªçc v√† ghi v√†o st.session_state['use_reranker']
    st.toggle(
        "S·ª≠ d·ª•ng Reranker",
        value=st.session_state.use_reranker, # ƒê·ªçc t·ª´ state
        key="use_reranker", # Ghi v√†o state khi thay ƒë·ªïi
        help="B·∫≠t ƒë·ªÉ s·ª≠ d·ª•ng m√¥ h√¨nh CrossEncoder x·∫øp h·∫°ng l·∫°i k·∫øt qu·∫£ t√¨m ki·∫øm."
    )


st.subheader("Tr·∫°ng th√°i H·ªá th·ªëng C∆° b·∫£n")

# S·ª≠ d·ª•ng st.status ƒë·ªÉ hi·ªÉn th·ªã tr·∫°ng th√°i kh·ªüi t·∫°o, ch·ªâ ch·∫°y logic kh·ªüi t·∫°o n·∫øu ch∆∞a th√†nh c√¥ng
with st.status(st.session_state.status_message, expanded=True) as status:
    # Ch·ªâ ch·∫°y logic t·∫£i model v√† retriever n·∫øu ch∆∞a ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng
    if st.session_state.g_embedding_model is None or st.session_state.retriever_instance is None:
         try:
            status.update(label="ƒêang t·∫£i Embedding Model...", state="running", expanded=True)
            st.session_state.g_embedding_model = utils.load_embedding_model(config.embedding_model_name)

            # Ch·ªâ t·∫£i reranker model n·∫øu c·∫•u h√¨nh sidebar b·∫≠t V√Ä embedding model ƒë√£ t·∫£i th√†nh c√¥ng
            use_reranker_current = st.session_state.get('use_reranker', True)
            if use_reranker_current and st.session_state.g_embedding_model:
                 status.update(label="ƒêang t·∫£i Reranker Model...", state="running", expanded=True)
                 st.session_state.g_reranking_model_loaded = utils.load_reranker_model(config.reranking_model_name)
            else:
                 st.session_state.g_reranking_model_loaded = None # ƒê·∫£m b·∫£o None n·∫øu t·∫Øt ho·∫∑c embedding l·ªói


            # T·∫£i ho·∫∑c t·∫°o RAG components
            if st.session_state.g_embedding_model: # Ch·ªâ t·∫°o/t·∫£i retriever n·∫øu embedding model ƒë√£ t·∫£i
                status.update(label="ƒêang t·∫£i ho·∫∑c t·∫°o Vector Database v√† Retriever...", state="running", expanded=True)
                st.session_state.vector_db_instance, st.session_state.retriever_instance = data_loader.load_or_create_rag_components(st.session_state.g_embedding_model)
            else:
                 st.session_state.vector_db_instance = None
                 st.session_state.retriever_instance = None


            if st.session_state.retriever_instance and st.session_state.g_embedding_model:
                st.session_state.status_message = "‚úÖ H·ªá th·ªëng ƒë√£ s·∫µn s√†ng!"
                status.update(label=st.session_state.status_message, state="complete", expanded=False)

                # Th√¥ng b√°o v·ªÅ reranker model n·∫øu kh√¥ng t·∫£i ƒë∆∞·ª£c ho·∫∑c b·ªã t·∫Øt
                if use_reranker_current and not st.session_state.g_reranking_model_loaded: # Ki·ªÉm tra l·∫°i tr·∫°ng th√°i t·∫£i v√† c·∫•u h√¨nh
                     st.warning("‚ö†Ô∏è Kh√¥ng t·∫£i ƒë∆∞·ª£c Reranker Model. Ch·ª©c nƒÉng rerank s·∫Ω kh√¥ng ho·∫°t ƒë·ªông.")
                elif not use_reranker_current: # D√πng bi·∫øn m·ªõi ƒë·ªçc t·ª´ state
                     st.info("Ch·ª©c nƒÉng Rerank ƒëang **T·∫Øt** trong c·∫•u h√¨nh sidebar.")


            else: # L·ªói kh·ªüi t·∫°o Retriever ho·∫∑c Embedding Model
                missing = [comp for comp, loaded in [("Retriever/VectorDB", st.session_state.retriever_instance), ("Embedding Model", st.session_state.g_embedding_model)] if not loaded]
                st.session_state.status_message = f"‚ö†Ô∏è L·ªói kh·ªüi t·∫°o: {', '.join(missing)}."
                status.update(label=st.session_state.status_message, state="error", expanded=True)


         except Exception as e:
            st.session_state.status_message = f"‚ö†Ô∏è L·ªói nghi√™m tr·ªçng khi kh·ªüi t·∫°o h·ªá th·ªëng: {e}"
            status.update(label=st.session_state.status_message, state="error", expanded=True)
    else:
        # N·∫øu ƒë√£ t·∫£i th√†nh c√¥ng trong l·∫ßn rerun tr∆∞·ªõc
        status.update(label=st.session_state.status_message, state="complete", expanded=False)
        # Th√¥ng b√°o v·ªÅ reranker model n·∫øu kh√¥ng t·∫£i ƒë∆∞·ª£c ho·∫∑c b·ªã t·∫Øt (hi·ªÉn th·ªã l·∫°i sau rerun n·∫øu c·∫ßn)
        use_reranker_current = st.session_state.get('use_reranker', True)
        if use_reranker_current and not st.session_state.g_reranking_model_loaded:
             st.warning("‚ö†Ô∏è Kh√¥ng t·∫£i ƒë∆∞·ª£c Reranker Model. Ch·ª©c nƒÉng rerank s·∫Ω kh√¥ng ho·∫°t ƒë·ªông.")
        elif not use_reranker_current:
             st.info("Ch·ª©c nƒÉng Rerank ƒëang **T·∫Øt** trong c·∫•u h√¨nh sidebar.")


# Ch·ªâ cho ph√©p c√°c h√†nh ƒë·ªông ti·∫øp theo n·∫øu h·ªá th·ªëng c∆° b·∫£n ƒë√£ s·∫µn s√†ng (embedding v√† retriever)
system_ready = st.session_state.g_embedding_model is not None and st.session_state.retriever_instance is not None

if system_ready:
    # --- Hi·ªÉn th·ªã C·∫•u h√¨nh ƒê√°nh gi√° s·∫Ω s·ª≠ d·ª•ng (ƒë·ªçc t·ª´ session state, gi·ªù do sidebar qu·∫£n l√Ω) ---
    st.caption(f"M√¥ h√¨nh: `{st.session_state.selected_gemini_model}` | Ngu·ªìn Query: `{st.session_state.retrieval_query_mode}` | Retrieval: `{st.session_state.retrieval_method}` | Reranker: `{'B·∫≠t' if st.session_state.use_reranker else 'T·∫Øt'}`")

    # T·∫°o dict c·∫•u h√¨nh cho h√†m ƒë√°nh gi√° - ƒê·ªçc tr·ª±c ti·∫øp t·ª´ st.session_state
    # C√°c gi√° tr·ªã n√†y gi·ªù ƒë∆∞·ª£c ƒë·∫£m b·∫£o t·ªìn t·∫°i do sidebar ho·∫∑c kh·ªüi t·∫°o s·ªõm
    eval_config_dict = {
        'retrieval_query_mode': st.session_state.retrieval_query_mode,
        'retrieval_method': st.session_state.retrieval_method,
        'use_reranker': st.session_state.use_reranker,
        'gemini_model_name': st.session_state.selected_gemini_model,
        'embedding_model_name': config.embedding_model_name, # L·∫•y t·ª´ config file
        # C·∫≠p nh·∫≠t t√™n reranker model d·ª±a tr√™n tr·∫°ng th√°i t·∫£i v√† c·∫•u h√¨nh
        'reranker_model_name': config.reranking_model_name if st.session_state.use_reranker and st.session_state.g_reranking_model_loaded else ("DISABLED_BY_CONFIG" if st.session_state.use_reranker else "DISABLED_BY_CONFIG"),
    }
    # Ki·ªÉm tra cu·ªëi c√πng cho reranker model ƒë·ªÉ truy·ªÅn v√†o h√†m run_retrieval_evaluation
    reranker_model_for_run = st.session_state.g_reranking_model_loaded if st.session_state.use_reranker and st.session_state.g_reranking_model_loaded else None


    st.subheader("T·∫£i L√™n File ƒê√°nh gi√°")
    uploaded_file = st.file_uploader(
        "Ch·ªçn file JSON d·ªØ li·ªáu ƒë√°nh gi√°...", type=["json"], key="eval_file_uploader" # Th√™m key ƒë·ªÉ d·ªÖ reset
    )

    # Logic x·ª≠ l√Ω file t·∫£i l√™n
    # Ki·ªÉm tra n·∫øu file m·ªõi ƒë∆∞·ª£c t·∫£i l√™n HO·∫∂C n·∫øu tr·∫°ng th√°i d·ªØ li·ªáu kh√¥ng kh·ªõp v·ªõi t√™n file (do x√≥a tr·∫°ng th√°i)
    # uploaded_file_name ki·ªÉm tra None ƒë·ªÉ reset khi clear state
    if uploaded_file is not None:
        if st.session_state.eval_uploaded_filename is None or uploaded_file.name != st.session_state.eval_uploaded_filename:
             try:
                # Reset tr·∫°ng th√°i li√™n quan ƒë·∫øn k·∫øt qu·∫£ c≈©
                st.session_state.eval_data = None # Clear data first
                st.session_state.eval_uploaded_filename = uploaded_file.name # C·∫≠p nh·∫≠t t√™n file ngay
                st.session_state.eval_run_completed = False
                st.session_state.eval_results_df = None
                st.session_state.last_eval_config = {}
                st.session_state.cancel_eval_requested = False # Reset c·ªù h·ªßy
                st.session_state.status_message = f"S·∫µn s√†ng ƒë√°nh gi√° v·ªõi d·ªØ li·ªáu t·ª´: {uploaded_file.name}" # C·∫≠p nh·∫≠t status

                eval_data_list = json.loads(uploaded_file.getvalue().decode('utf-8'))
                st.session_state.eval_data = eval_data_list

                st.success(st.session_state.status_message)
                # st.rerun() # Rerun sau khi t·∫£i file th√†nh c√¥ng ƒë·ªÉ c·∫≠p nh·∫≠t giao di·ªán
             except Exception as e:
                st.error(f"L·ªói x·ª≠ l√Ω file JSON: {e}")
                # Reset tr·∫°ng th√°i n·∫øu l·ªói
                st.session_state.eval_data = None
                st.session_state.eval_uploaded_filename = None # ƒê·∫∑t l·∫°i None ƒë·ªÉ c√≥ th·ªÉ t·∫£i l·∫°i file c√πng t√™n
                st.session_state.eval_run_completed = False
                st.session_state.eval_results_df = None
                st.session_state.last_eval_config = {}
                st.session_state.cancel_eval_requested = False # Reset c·ªù h·ªßy
                st.session_state.status_message = "L·ªói t·∫£i file ƒë√°nh gi√°."


    if st.session_state.eval_data is not None:
        st.info(f"S·∫µn s√†ng ƒë√°nh gi√° v·ªõi d·ªØ li·ªáu t·ª´: **{st.session_state.eval_uploaded_filename}**.")

        if st.checkbox("Hi·ªÉn th·ªã d·ªØ li·ªáu m·∫´u (5 d√≤ng)", key="show_eval_data_preview"):
            st.dataframe(pd.DataFrame(st.session_state.eval_data).head())

        # Placeholders cho thanh ti·∫øn tr√¨nh v√† text status trong qu√° tr√¨nh ch·∫°y
        progress_bar_placeholder = st.empty()
        status_text_placeholder = st.empty()


        # X√°c ƒë·ªãnh tr·∫°ng th√°i ƒëang ch·∫°y ƒë·ªÉ disable n√∫t
        is_running = st.session_state.eval_data is not None and not st.session_state.eval_run_completed and not st.session_state.cancel_eval_requested

        # N√∫t b·∫Øt ƒë·∫ßu v√† h·ªßy ƒë√°nh gi√°
        col_eval_btn, col_cancel_btn = st.columns(2)

        with col_eval_btn:
            # Disable n√∫t B·∫Øt ƒë·∫ßu n·∫øu ƒëang ch·∫°y ho·∫∑c ch∆∞a c√≥ d·ªØ li·ªáu
            if st.button("üöÄ B·∫Øt ƒë·∫ßu ƒê√°nh gi√°", key="start_eval_button", disabled=is_running or st.session_state.eval_data is None):
                 # L∆∞u c·∫•u h√¨nh hi·ªán t·∫°i t·ª´ st.session_state v√†o last_eval_config tr∆∞·ªõc khi ch·∫°y
                 current_config_for_save = {
                    'retrieval_query_mode': st.session_state.retrieval_query_mode,
                    'retrieval_method': st.session_state.retrieval_method,
                    'use_reranker': st.session_state.use_reranker,
                    'gemini_model_name': st.session_state.selected_gemini_model,
                    'embedding_model_name': config.embedding_model_name,
                    'reranker_model_name': config.reranking_model_name if st.session_state.use_reranker and st.session_state.g_reranking_model_loaded else ("DISABLED_BY_CONFIG" if st.session_state.use_reranker else "DISABLED_BY_CONFIG"),
                 }
                 st.session_state.last_eval_config = current_config_for_save.copy() # L∆∞u b·∫£n sao
                 st.session_state.eval_run_completed = False # ƒê·∫∑t l·∫°i c·ªù ho√†n th√†nh
                 st.session_state.eval_results_df = None # X√≥a k·∫øt qu·∫£ c≈© khi ch·∫°y m·ªõi

                 # Reset c·ªù h·ªßy khi b·∫Øt ƒë·∫ßu ch·∫°y m·ªõi
                 st.session_state.cancel_eval_requested = False
                 st.session_state.status_message = "ƒêang ch·∫°y ƒë√°nh gi√°..." # C·∫≠p nh·∫≠t status


                 with st.spinner(f"ƒêang t·∫£i model Gemini: {st.session_state.selected_gemini_model}..."):
                     # T·∫£i Gemini model d·ª±a tr√™n l·ª±a ch·ªçn m·ªõi nh·∫•t t·ª´ sidebar (ƒë√£ c√≥ trong session state)
                     # N√™n t·∫£i l·∫°i m·ªói l·∫ßn ch·∫°y m·ªõi ƒë·ªÉ ƒë·∫£m b·∫£o ƒë√∫ng model ƒë∆∞·ª£c ch·ªçn
                     g_gemini_model_eval = utils.load_gemini_model(st.session_state.selected_gemini_model)


                 if g_gemini_model_eval:
                    st.info(f"Model Gemini '{st.session_state.selected_gemini_model}' ƒë√£ s·∫µn s√†ng.")
                    # S·ª≠ d·ª•ng st.spinner ƒë·ªÉ hi·ªÉn th·ªã tr·∫°ng th√°i ch·∫°y
                    # (Spinner n√†y bao quanh h√†m run_retrieval_evaluation)
                    with st.spinner(""): # Spinner r·ªóng, text status ƒë∆∞·ª£c qu·∫£n l√Ω b·ªüi placeholder b√™n d∆∞·ªõi
                        start_eval_time = time.time()
                        results_df = run_retrieval_evaluation(
                            eval_data=st.session_state.eval_data,
                            hybrid_retriever=st.session_state.retriever_instance, # L·∫•y instance t·ª´ state
                            embedding_model=st.session_state.g_embedding_model, # L·∫•y model t·ª´ state
                            reranking_model=reranker_model_for_run, # Truy·ªÅn model (ho·∫∑c None)
                            gemini_model=g_gemini_model_eval, # Truy·ªÅn Gemini model ƒë√£ t·∫£i
                            eval_config=st.session_state.last_eval_config, # Truy·ªÅn dict config ƒë√£ l∆∞u (ƒë·∫£m b·∫£o nh·∫•t)
                            progress_bar_placeholder=progress_bar_placeholder, # Truy·ªÅn placeholder
                            status_text_placeholder=status_text_placeholder # Truy·ªÅn placeholder
                        )
                        total_eval_time = time.time() - start_eval_time

                        # C·∫≠p nh·∫≠t status sau khi h√†m ch·∫°y xong
                        if st.session_state.cancel_eval_requested:
                             st.session_state.status_message = f"ƒê√°nh gi√° b·ªã h·ªßy b·ªè sau {total_eval_time:.2f} gi√¢y."
                             st.warning(st.session_state.status_message)
                        else:
                             st.session_state.status_message = f"Ho√†n th√†nh ƒë√°nh gi√° sau {total_eval_time:.2f} gi√¢y."
                             st.success(st.session_state.status_message)


                        st.session_state.eval_results_df = results_df
                        # Ch·ªâ set complete n·∫øu kh√¥ng b·ªã h·ªßy b·ªè
                        if not st.session_state.cancel_eval_requested:
                            st.session_state.eval_run_completed = True

                        st.session_state.cancel_eval_requested = False # Reset c·ªù h·ªßy sau khi k·∫øt th√∫c ch·∫°y
                        # st.rerun() # Streamlit s·∫Ω t·ª± ƒë·ªông rerun sau callback c·ªßa n√∫t

                 else: # N·∫øu kh√¥ng t·∫£i ƒë∆∞·ª£c Gemini model
                      st.session_state.status_message = f"‚ö†Ô∏è L·ªói t·∫£i m√¥ h√¨nh Gemini: {st.session_state.selected_gemini_model}"
                      st.error(st.session_state.status_message)
                      st.session_state.cancel_eval_requested = False # ƒê·∫£m b·∫£o c·ªù h·ªßy ƒë∆∞·ª£c reset
                      st.session_state.eval_run_completed = False # ƒê·∫£m b·∫£o tr·∫°ng th√°i kh√¥ng ph·∫£i completed


        with col_cancel_btn:
            # Ch·ªâ hi·ªÉn th·ªã n√∫t H·ªßy n·∫øu qu√° tr√¨nh ƒë√°nh gi√° ƒëang ch·∫°y (is_running l√† True)
            if is_running:
                 if st.button("‚ùå H·ªßy ƒê√°nh gi√°", key="cancel_eval_button"):
                    st.session_state.cancel_eval_requested = True # ƒê·∫∑t c·ªù y√™u c·∫ßu h·ªßy
                    st.info("ƒêang y√™u c·∫ßu h·ªßy b·ªè qu√° tr√¨nh ƒë√°nh gi√°...")
                    st.session_state.status_message = "ƒêang y√™u c·∫ßu h·ªßy b·ªè..." # C·∫≠p nh·∫≠t status hi·ªÉn th·ªã
                    # st.rerun() # Streamlit s·∫Ω t·ª± ƒë·ªông rerun sau callback c·ªßa n√∫t


    # --- Hi·ªÉn th·ªã K·∫øt qu·∫£ ---
    # Ch·ªâ hi·ªÉn th·ªã k·∫øt qu·∫£ n·∫øu ƒë√£ ho√†n th√†nh V√Ä kh√¥ng c√≥ y√™u c·∫ßu h·ªßy b·ªè ƒëang ch·ªù x·ª≠ l√Ω
    if st.session_state.eval_run_completed and st.session_state.eval_results_df is not None and not st.session_state.cancel_eval_requested:
        st.subheader("K·∫øt qu·∫£ ƒê√°nh gi√°")
        detailed_results_df = st.session_state.eval_results_df
        last_config = st.session_state.last_eval_config # ƒê·ªçc config ƒë√£ ch·∫°y

        # --- Hi·ªÉn th·ªã l·∫°i c·∫•u h√¨nh ƒë√£ ch·∫°y ---
        st.markdown("**C·∫•u h√¨nh ƒë√£ s·ª≠ d·ª•ng cho l·∫ßn ch·∫°y cu·ªëi:**")
        cfg_col1, cfg_col2, cfg_col3, cfg_col4 = st.columns(4)
        cfg_col1.metric("Ngu·ªìn Query", last_config.get('retrieval_query_mode', 'N/A'))
        cfg_col2.metric("Ret. Method", last_config.get('retrieval_method', 'N/A'))
        cfg_col3.metric("Reranker", "B·∫≠t" if last_config.get('use_reranker', False) else "T·∫Øt")
        st.caption(f"Gemini: `{last_config.get('gemini_model_name', 'N/A')}`, Embedding: `{last_config.get('embedding_model_name', 'N/A')}`, Reranker: `{last_config.get('reranker_model_name', 'N/A')}`")


        avg_metrics, num_eval, num_skipped_error = calculate_average_metrics(detailed_results_df)

        st.metric("T·ªïng s·ªë Queries", len(detailed_results_df))
        col_res1, col_res2 = st.columns(2)
        col_res1.metric("Queries ƒê√°nh gi√° H·ª£p l·ªá", num_eval)
        col_res2.metric("Queries B·ªè qua / L·ªói", num_skipped_error)

        if avg_metrics:
            st.markdown("#### Metrics Trung b√¨nh @K (tr√™n c√°c queries h·ª£p l·ªá)")
            # ƒê√£ b·ªè K=1
            k_values_display = [3, 5, 10]
            cols_k = st.columns(len(k_values_display))
            for idx, k in enumerate(k_values_display):
                with cols_k[idx]:
                    st.markdown(f"**K = {k}**")
                    st.text(f"Precision: {avg_metrics.get(f'avg_precision@{k}', 0.0):.4f}")
                    st.text(f"Recall:    {avg_metrics.get(f'avg_recall@{k}', 0.0):.4f}")
                    st.text(f"F1:        {avg_metrics.get(f'avg_f1@{k}', 0.0):.4f}")
                    st.text(f"MRR:       {avg_metrics.get(f'avg_mrr@{k}', 0.0):.4f}")
                    st.text(f"NDCG:      {avg_metrics.get(f'avg_ndcg@{k}', 0.0):.4f}")

            st.markdown("#### Th√¥ng tin Hi·ªáu nƒÉng & S·ªë l∆∞·ª£ng Trung b√¨nh")
            col_perf1, col_perf2, col_perf3, col_perf4 = st.columns(4)
            col_perf1.metric("Avg Total Time (s)", f"{avg_metrics.get('avg_processing_time', 0.0):.3f}")
            col_perf2.metric("Avg Variation Time (s)", f"{avg_metrics.get('avg_variation_time', 0.0):.3f}")
            col_perf3.metric("Avg Search Time (s)", f"{avg_metrics.get('avg_search_time', 0.0):.3f}")
            col_perf4.metric("Avg Rerank Time (s)", f"{avg_metrics.get('avg_rerank_time', 0.0):.3f}")

            col_count1, col_count2, col_count3, col_count4 = st.columns(4)
            col_count1.metric("Avg Variations Gen", f"{avg_metrics.get('avg_num_variations_generated', 0.0):.1f}")
            col_count2.metric("Avg Docs Found", f"{avg_metrics.get('avg_num_unique_docs_found', 0.0):.1f}")
            col_count3.metric("Avg Docs Reranked", f"{avg_metrics.get('avg_num_docs_reranked', 0.0):.1f}")
            col_count4.metric("Avg Final Docs", f"{avg_metrics.get('avg_num_retrieved_after_rerank', 0.0):.1f}")


        else:
            st.warning("Kh√¥ng th·ªÉ t√≠nh metrics trung b√¨nh (kh√¥ng c√≥ query h·ª£p l·ªá).")


        with st.expander("Xem K·∫øt qu·∫£ Chi ti·∫øt cho t·ª´ng Query"):
            display_columns = [
                'query_id', 'query', 'status',
                'retrieval_query_mode','retrieval_method', 'use_reranker',
                'precision@3', 'recall@3', 'f1@3', 'mrr@3', 'ndcg@3', # Ch·ªâ gi·ªØ K=3, 5, 10
                'precision@5', 'recall@5', 'f1@5', 'mrr@5', 'ndcg@5',
                'precision@10', 'recall@10', 'f1@10', 'mrr@10', 'ndcg@10',
                'processing_time', 'variation_time', 'search_time', 'rerank_time',
                'num_variations_generated','num_unique_docs_found', 'num_retrieved_before_rerank','num_docs_reranked', 'num_retrieved_after_rerank',
                'retrieved_ids', 'relevant_ids', 'summarizing_query', 'error_message'
            ]
            # L·ªçc l·∫°i c√°c c·ªôt hi·ªÉn th·ªã ƒë·ªÉ ch·ªâ gi·ªØ l·∫°i c√°c c·ªôt th·ª±c s·ª± c√≥ trong DataFrame
            # ƒêi·ªÅu n√†y quan tr·ªçng v√¨ c√°c metrics @1 kh√¥ng c√≤n ƒë∆∞·ª£c t√≠nh
            existing_display_columns = [col for col in display_columns if col in detailed_results_df.columns]
            st.dataframe(detailed_results_df[existing_display_columns])


        st.subheader("L∆∞u K·∫øt qu·∫£ Chi ti·∫øt")
        try:
            results_json = detailed_results_df.to_json(orient='records', indent=2, force_ascii=False)
            results_csv = detailed_results_df.to_csv(index=False).encode('utf-8')

            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            # S·ª≠ d·ª•ng config ƒë√£ ch·∫°y ƒë·ªÉ t·∫°o t√™n file
            last_config = st.session_state.get('last_eval_config', {}) # ƒê·∫£m b·∫£o l·∫•y t·ª´ state
            qmode_suffix = last_config.get('retrieval_query_mode', 'na').lower()[:3]
            method_suffix = last_config.get('retrieval_method', 'na').lower()
            rerank_suffix = "rr" if last_config.get('use_reranker', False) else "norr"
            model_suffix = last_config.get('gemini_model_name', 'gemini').split('/')[-1].replace('.','-')[:15]

            base_filename = f"eval_{qmode_suffix}_{method_suffix}_{rerank_suffix}_{model_suffix}_{timestamp}"
            fname_json = f"{base_filename}.json"
            fname_csv = f"{base_filename}.csv"

            col_dl1, col_dl2 = st.columns(2)
            with col_dl1:
                st.download_button("üíæ T·∫£i v·ªÅ JSON", results_json, fname_json, "application/json", key="dl_json")
            with col_dl2:
                st.download_button("üíæ T·∫£i v·ªÅ CSV", results_csv, fname_csv, "text/csv", key="dl_csv")
        except Exception as e:
            st.error(f"L·ªói khi chu·∫©n b·ªã file k·∫øt qu·∫£: {e}")

    # --- Qu·∫£n l√Ω Tr·∫°ng th√°i ƒê√°nh gi√° ---
    st.markdown("---")
    st.subheader("Qu·∫£n l√Ω Tr·∫°ng th√°i ƒê√°nh gi√°")
    # N√∫t x√≥a: reset to√†n b·ªô tr·∫°ng th√°i li√™n quan ƒë·∫øn ƒë√°nh gi√° v√† uploader
    if st.button("X√≥a File ƒê√£ T·∫£i v√† K·∫øt Qu·∫£", key="clear_eval_state"):
        st.session_state.eval_data = None
        st.session_state.eval_uploaded_filename = None # ƒê·∫∑t l·∫°i None ƒë·ªÉ c√≥ th·ªÉ t·∫£i l·∫°i file c√πng t√™n
        st.session_state.eval_run_completed = False
        st.session_state.eval_results_df = None
        st.session_state.last_eval_config = {}
        st.session_state.cancel_eval_requested = False # Reset c·ªù h·ªßy
        st.session_state.status_message = "ƒê√£ x√≥a d·ªØ li·ªáu ƒë√°nh gi√°. S·∫µn s√†ng t·∫£i file m·ªõi." # C·∫≠p nh·∫≠t tr·∫°ng th√°i hi·ªÉn th·ªã

        # KH√îNG C·∫ßn g√°n None v√†o st.session_state["eval_file_uploader"]
        # Ch·ªâ c·∫ßn x√≥a c√°c bi·∫øn tr·∫°ng th√°i d·ªØ li·ªáu v√† rerun
        st.success(st.session_state.status_message)
        st.rerun() # K√≠ch ho·∫°t rerun ƒë·ªÉ giao di·ªán c·∫≠p nh·∫≠t

else:
    # N·∫øu h·ªá th·ªëng ch∆∞a s·∫µn s√†ng (embedding ho·∫∑c retriever l·ªói/ch∆∞a t·∫£i xong)
    st.warning("‚ö†Ô∏è H·ªá th·ªëng c∆° b·∫£n ch∆∞a s·∫µn s√†ng. Vui l√≤ng ki·ªÉm tra l·ªói ·ªü m·ª•c 'Tr·∫°ng th√°i H·ªá th·ªëng C∆° b·∫£n'.")
    # Tr·∫°ng th√°i chi ti·∫øt ƒë√£ ƒë∆∞·ª£c hi·ªÉn th·ªã b·ªüi st.status block