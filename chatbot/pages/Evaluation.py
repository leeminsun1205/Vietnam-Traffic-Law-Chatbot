# pages/Evaluation.py
import time
import streamlit as st
import pandas as pd
import json
import os
from datetime import datetime
import sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))) # Th√™m th∆∞ m·ª•c g·ªëc v√†o sys.path
import config #
from model_loader import ( #
    load_all_embedding_models,
    load_all_reranker_models,
    load_gemini_model
)
from data_loader import load_or_create_rag_components #
from reranker import rerank_documents #
from utils import ( #
    generate_query_variations,
    precision_at_k, recall_at_k, f1_at_k, mrr_at_k, ndcg_at_k,
    calculate_average_metrics
)

# --- H√†m ch·ªâ ƒë·ªÉ sinh v√† thu th·∫≠p bi·∫øn th·ªÉ ---
def generate_and_collect_variations_only(eval_data: list, gemini_model_object, num_variations: int) -> dict:
    """
    Sinh bi·∫øn th·ªÉ cho t·∫•t c·∫£ c√°c query trong eval_data v√† tr·∫£ v·ªÅ m·ªôt dict
    v·ªõi query_id l√†m key.
    """
    collected_variations_output = {}
    progress_bar_var_only = st.progress(0)
    status_text_var_only = st.empty()
    total_items_var_only = len(eval_data)
    queries_per_batch_var_only = 15
    wait_time_seconds_var_only = 60 # Gi·ªØ th·ªùi gian ch·ªù ƒë·ªÉ tr√°nh rate limit

    if not gemini_model_object:
        st.error("L·ªói: Gemini model kh√¥ng ƒë∆∞·ª£c cung c·∫•p cho vi·ªác sinh bi·∫øn th·ªÉ.")
        return {}

    for i, item_data_var in enumerate(eval_data):
        if i > 0 and i % queries_per_batch_var_only == 0:
            pause_msg_var = f"ƒêang sinh bi·∫øn th·ªÉ {i}/{total_items_var_only}. T·∫°m d·ª´ng {wait_time_seconds_var_only} gi√¢y..."
            status_text_var_only.text(pause_msg_var)
            time.sleep(wait_time_seconds_var_only)
            status_text_var_only.text(f"Ti·∫øp t·ª•c sinh bi·∫øn th·ªÉ cho query {i+1}/{total_items_var_only}...")

        query_id_item_var = item_data_var.get("query_id", f"item_{i+1}") # Fallback query_id
        original_query_item_var = item_data_var.get("query")
        status_text_var_only.text(f"ƒêang sinh bi·∫øn th·ªÉ cho query {i+1}/{total_items_var_only}: {query_id_item_var}...")

        try:
            relevance_status_gen, direct_ans_gen, all_q_list_gen, summarizing_q_str_gen = generate_query_variations(
                original_query=original_query_item_var,
                gemini_model=gemini_model_object,
                chat_history=None,
                num_variations=num_variations
            )
            collected_variations_output[query_id_item_var] = {
                "original_query": original_query_item_var,
                "relevance_status": relevance_status_gen,
                "direct_answer_if_invalid": direct_ans_gen,
                "all_queries": all_q_list_gen,
                "summarizing_query": summarizing_q_str_gen,
                "llm_model_used_for_generation": gemini_model_object.model_name # L∆∞u t√™n model ƒë√£ d√πng
            }
        except Exception as e_gen_var_item:
            st.warning(f"L·ªói khi sinh bi·∫øn th·ªÉ cho query_id '{query_id_item_var}': {e_gen_var_item}. M·ª•c n√†y s·∫Ω c√≥ th√¥ng tin l·ªói.")
            collected_variations_output[query_id_item_var] = {
                "original_query": original_query_item_var,
                "relevance_status": "error_generating_variations",
                "direct_answer_if_invalid": "",
                "all_queries": [original_query_item_var], # Fallback
                "summarizing_query": original_query_item_var, # Fallback
                "error_message": str(e_gen_var_item),
                "llm_model_used_for_generation": gemini_model_object.model_name
            }
        finally:
            progress_bar_var_only.progress((i + 1) / total_items_var_only)

    status_text_var_only.success(f"Ho√†n th√†nh sinh bi·∫øn th·ªÉ cho {total_items_var_only} c√¢u h·ªèi!")
    return collected_variations_output

# --- H√†m ch·∫°y ƒë√°nh gi√° ch√≠nh, ƒë∆∞·ª£c s·ª≠a ƒë·ªïi ---
def run_retrieval_evaluation(
    eval_data: list,
    retriever_instance_for_eval,
    embedding_model_object_for_eval,
    reranking_model_object_for_eval,
    gemini_model_object_for_eval,
    eval_config_params: dict,
    preloaded_query_variations: dict = None # M·ªõi: dict {query_id: variation_data}
    ):
    results_list = []
    k_values_metrics = [3, 5, 10]

    retrieval_query_mode_eval = eval_config_params.get('retrieval_query_mode', 'T·ªïng qu√°t')
    retrieval_method_eval = eval_config_params.get('retrieval_method', 'hybrid')
    selected_reranker_name_eval_run = eval_config_params.get('selected_reranker_model_name', 'Kh√¥ng s·ª≠ d·ª•ng')
    use_reranker_eval_run = reranking_model_object_for_eval is not None and selected_reranker_name_eval_run != 'Kh√¥ng s·ª≠ d·ª•ng'
    variation_mode_run = eval_config_params.get('variation_mode_used', "Lu√¥n sinh m·ªõi (qua LLM)")

    progress_bar_eval = st.progress(0)
    status_text_area_eval = st.empty()
    total_items_eval = len(eval_data)
    queries_per_batch_eval = 15
    wait_time_seconds_eval = 60

    for i, item_eval in enumerate(eval_data):
        if i > 0 and i % queries_per_batch_eval == 0:
            pause_msg_eval = f"ƒê√£ x·ª≠ l√Ω {i}/{total_items_eval} queries. T·∫°m d·ª´ng {wait_time_seconds_eval} gi√¢y..."
            status_text_area_eval.text(pause_msg_eval)
            time.sleep(wait_time_seconds_eval)

        query_id_eval = item_eval.get("query_id", f"item_{i+1}") # Fallback query_id
        original_query_eval = item_eval.get("query")
        relevant_chunk_ids_eval = set(str(cid) for cid in item_eval.get("relevant_chunk_ids", []))

        emb_name_disp_eval = eval_config_params.get('embedding_model_name', 'N/A').split('/')[-1]
        rer_name_disp_eval = selected_reranker_name_eval_run.split('/')[-1] if selected_reranker_name_eval_run != 'Kh√¥ng s·ª≠ d·ª•ng' else "T·∫Øt"
        var_mode_disp = variation_mode_run.split('(')[0].strip() if '(' in variation_mode_run else variation_mode_run

        status_text_area_eval.text(
            f"ƒêang x·ª≠ l√Ω query {i+1}/{total_items_eval}: {query_id_eval}\n"
            f"(Emb: {emb_name_disp_eval}, QueryMode: {retrieval_query_mode_eval}, "
            f"Method: {retrieval_method_eval}, Reranker: {rer_name_disp_eval}, VarMode: {var_mode_disp})"
        )

        start_time_eval_q = time.time()
        query_metrics_dict = {
            "query_id": query_id_eval, "query": original_query_eval,
            "embedding_model_name": eval_config_params.get('embedding_model_name', 'N/A'),
            "retrieval_query_mode": retrieval_query_mode_eval,
            "retrieval_method": retrieval_method_eval,
            "selected_reranker_model": selected_reranker_name_eval_run,
            "variation_mode_run": variation_mode_run,
            "variation_source": "N/A", # S·∫Ω ƒë∆∞·ª£c c·∫≠p nh·∫≠t
            "llm_model_for_variation": "N/A", # S·∫Ω ƒë∆∞·ª£c c·∫≠p nh·∫≠t
            "status": "error_default", "retrieved_ids": [], "relevant_ids": list(relevant_chunk_ids_eval),
            "processing_time": 0.0, 'summarizing_query': '',
            'variation_time': 0.0, 'search_time': 0.0, 'rerank_time': 0.0,
            'num_variations_generated': 0, 'num_unique_docs_found': 0, 'num_docs_reranked': 0,
            'num_retrieved_before_rerank': 0, 'num_retrieved_after_rerank': 0, 'error_message': ''
        }
        for k_val_m in k_values_metrics:
            query_metrics_dict[f'precision@{k_val_m}'] = 0.0; query_metrics_dict[f'recall@{k_val_m}'] = 0.0
            query_metrics_dict[f'f1@{k_val_m}'] = 0.0; query_metrics_dict[f'mrr@{k_val_m}'] = 0.0; query_metrics_dict[f'ndcg@{k_val_m}'] = 0.0

        try:
            var_start_processing_time = time.time()
            relevance_status_q_eval = "valid"
            all_queries_q_eval = [original_query_eval]
            summarizing_q_q_eval = original_query_eval
            # direct_ans_if_inv_q_eval = "" # Kh√¥ng d√πng tr·ª±c ti·∫øp trong ƒë√°nh gi√° retrieval

            if preloaded_query_variations and query_id_eval in preloaded_query_variations:
                query_metrics_dict["variation_source"] = "File"
                var_data = preloaded_query_variations[query_id_eval]
                relevance_status_q_eval = var_data.get("relevance_status", "valid")
                all_queries_q_eval = var_data.get("all_queries", [original_query_eval])
                summarizing_q_q_eval = var_data.get("summarizing_query", original_query_eval)
                query_metrics_dict["llm_model_for_variation"] = var_data.get("llm_model_used_for_generation", "From File")
                if relevance_status_q_eval == "error_generating_variations":
                    st.sidebar.warning(f"Query ID {query_id_eval}: L·ªói khi t·∫°o bi·∫øn th·ªÉ t·ª´ file tr∆∞·ªõc ƒë√≥. S·ª≠ d·ª•ng fallback.")
            elif gemini_model_object_for_eval: # Sinh m·ªõi n·∫øu kh√¥ng c√≥ preloaded ho·∫∑c query_id kh√¥ng kh·ªõp
                query_metrics_dict["variation_source"] = "LLM"
                query_metrics_dict["llm_model_for_variation"] = gemini_model_object_for_eval.model_name
                relevance_status_q_eval, _, all_queries_q_eval, summarizing_q_q_eval = generate_query_variations(
                    original_query=original_query_eval,
                    gemini_model=gemini_model_object_for_eval,
                    chat_history=None,
                    num_variations=config.NUM_QUERY_VARIATIONS
                )
            else: # Kh√¥ng c√≥ preloaded v√† kh√¥ng c√≥ model ƒë·ªÉ sinh m·ªõi
                query_metrics_dict["variation_source"] = "Fallback Original"
                query_metrics_dict["llm_model_for_variation"] = "N/A"
                # C√°c gi√° tr·ªã m·∫∑c ƒë·ªãnh ƒë√£ ƒë∆∞·ª£c ƒë·∫∑t ·ªü tr√™n

            query_metrics_dict["variation_time"] = time.time() - var_start_processing_time
            query_metrics_dict["summarizing_query"] = summarizing_q_q_eval
            query_metrics_dict["num_variations_generated"] = len(all_queries_q_eval) - 1 if isinstance(all_queries_q_eval, list) and len(all_queries_q_eval) > 0 else 0

            if relevance_status_q_eval == 'invalid' or relevance_status_q_eval == 'error_generating_variations':
                query_metrics_dict["status"] = "skipped_irrelevant" if relevance_status_q_eval == 'invalid' else "skipped_variation_error"
            else:
                queries_to_search_eval_run = []
                if retrieval_query_mode_eval == 'ƒê∆°n gi·∫£n': queries_to_search_eval_run = [original_query_eval]
                elif retrieval_query_mode_eval == 'T·ªïng qu√°t': queries_to_search_eval_run = [summarizing_q_q_eval] if summarizing_q_q_eval else [original_query_eval]
                elif retrieval_query_mode_eval == 'S√¢u': queries_to_search_eval_run = all_queries_q_eval if all_queries_q_eval else [original_query_eval]

                collected_docs_data_eval_run = {}
                search_start_eval_q_run = time.time()
                for q_var_eval_run in queries_to_search_eval_run:
                    if not q_var_eval_run: continue
                    search_results_eval_run = retriever_instance_for_eval.search(
                        q_var_eval_run,
                        embedding_model_object_for_eval,
                        method=retrieval_method_eval,
                        k=config.VECTOR_K_PER_QUERY
                    )
                    for res_item_eval_run in search_results_eval_run:
                        doc_idx_eval_run = res_item_eval_run.get('index')
                        if isinstance(doc_idx_eval_run, int) and doc_idx_eval_run >= 0 and doc_idx_eval_run not in collected_docs_data_eval_run:
                            collected_docs_data_eval_run[doc_idx_eval_run] = res_item_eval_run
                query_metrics_dict["search_time"] = time.time() - search_start_eval_q_run
                query_metrics_dict["num_unique_docs_found"] = len(collected_docs_data_eval_run)

                retrieved_docs_list_eval_run = list(collected_docs_data_eval_run.values())
                sort_reverse_eval_run = (retrieval_method_eval != 'dense')
                retrieved_docs_list_eval_run.sort(key=lambda x: x.get('score', 0 if sort_reverse_eval_run else float('inf')), reverse=sort_reverse_eval_run)
                query_metrics_dict["num_retrieved_before_rerank"] = len(retrieved_docs_list_eval_run)

                final_docs_for_metrics_eval_run = []
                rerank_start_eval_q_time_run = time.time()

                if use_reranker_eval_run and retrieved_docs_list_eval_run:
                    query_for_reranking_eval_run = summarizing_q_q_eval if summarizing_q_q_eval else original_query_eval
                    docs_to_rerank_input_eval_run = retrieved_docs_list_eval_run[:config.MAX_DOCS_FOR_RERANK]
                    query_metrics_dict["num_docs_reranked"] = len(docs_to_rerank_input_eval_run)
                    rerank_input_fmt_eval_run = [{'doc': item_d_run['doc'], 'index': item_d_run['index']} for item_d_run in docs_to_rerank_input_eval_run]

                    reranked_results_eval_run = rerank_documents(
                        query_for_reranking_eval_run,
                        rerank_input_fmt_eval_run,
                        reranking_model_object_for_eval
                    )
                    final_docs_for_metrics_eval_run = reranked_results_eval_run[:config.FINAL_NUM_RESULTS_AFTER_RERANK]
                    query_metrics_dict["rerank_time"] = time.time() - rerank_start_eval_q_time_run
                elif retrieved_docs_list_eval_run:
                    temp_final_docs_eval_run = retrieved_docs_list_eval_run[:config.FINAL_NUM_RESULTS_AFTER_RERANK]
                    final_docs_for_metrics_eval_run = [
                        {'doc': item_run['doc'], 'score': item_run.get('score'), 'original_index': item_run['index']}
                        for item_run in temp_final_docs_eval_run
                    ]
                    query_metrics_dict["rerank_time"] = 0.0
                    query_metrics_dict["num_docs_reranked"] = 0
                else: # Kh√¥ng c√≥ k·∫øt qu·∫£ retrieval
                    query_metrics_dict["rerank_time"] = 0.0
                    query_metrics_dict["num_docs_reranked"] = 0

                query_metrics_dict["num_retrieved_after_rerank"] = len(final_docs_for_metrics_eval_run)
                retrieved_ids_eval_q_run = []
                for res_final_eval_run in final_docs_for_metrics_eval_run:
                    doc_data_eval_run = res_final_eval_run.get('doc', {})
                    chunk_id_eval_run = None
                    if isinstance(doc_data_eval_run, dict):
                        chunk_id_eval_run = doc_data_eval_run.get('id') or \
                                        doc_data_eval_run.get('chunk_id') or \
                                        doc_data_eval_run.get('metadata', {}).get('id') or \
                                        doc_data_eval_run.get('metadata', {}).get('chunk_id')
                    if chunk_id_eval_run is not None:
                        retrieved_ids_eval_q_run.append(str(chunk_id_eval_run))

                query_metrics_dict["retrieved_ids"] = retrieved_ids_eval_q_run
                query_metrics_dict["status"] = "evaluated"
                for k_val_m_calc_run in k_values_metrics:
                    query_metrics_dict[f'precision@{k_val_m_calc_run}'] = precision_at_k(retrieved_ids_eval_q_run, relevant_chunk_ids_eval, k_val_m_calc_run)
                    query_metrics_dict[f'recall@{k_val_m_calc_run}'] = recall_at_k(retrieved_ids_eval_q_run, relevant_chunk_ids_eval, k_val_m_calc_run)
                    query_metrics_dict[f'f1@{k_val_m_calc_run}'] = f1_at_k(retrieved_ids_eval_q_run, relevant_chunk_ids_eval, k_val_m_calc_run)
                    query_metrics_dict[f'mrr@{k_val_m_calc_run}'] = mrr_at_k(retrieved_ids_eval_q_run, relevant_chunk_ids_eval, k_val_m_calc_run)
                    query_metrics_dict[f'ndcg@{k_val_m_calc_run}'] = ndcg_at_k(retrieved_ids_eval_q_run, relevant_chunk_ids_eval, k_val_m_calc_run)

        except Exception as e_eval_q_run:
            query_metrics_dict["status"] = "error_runtime"
            query_metrics_dict["error_message"] = f"{type(e_eval_q_run).__name__}: {str(e_eval_q_run)}"
            st.sidebar.error(f"L·ªói khi x·ª≠ l√Ω query {query_id_eval}: {e_eval_q_run}")
            import traceback
            st.sidebar.expander(f"Traceback l·ªói query {query_id_eval}").code(traceback.format_exc())
        finally:
            query_metrics_dict["processing_time"] = time.time() - start_time_eval_q
            results_list.append(query_metrics_dict)
            progress_bar_eval.progress((i + 1) / total_items_eval)

    status_text_area_eval.text(f"Ho√†n th√†nh ƒë√°nh gi√° {total_items_eval} queries!")
    return pd.DataFrame(results_list)


# --- (Ph·∫ßn c√≤n l·∫°i c·ªßa trang Streamlit cho ƒê√°nh gi√°) ---
# ... (initialize_evaluation_page_resources, st.sidebar, st.caption, ...)

# --- Kh·ªüi t·∫°o t√†i nguy√™n cho trang ƒê√°nh gi√° ---
eval_page_status_placeholder = st.empty()
if "eval_page_resources_initialized" not in st.session_state:
    st.session_state.eval_page_resources_initialized = False

if not st.session_state.eval_page_resources_initialized:
    with st.spinner("ƒêang kh·ªüi t·∫°o t√†i nguy√™n cho trang ƒê√°nh gi√°..."):
        eval_resources_ready = initialize_evaluation_page_resources() # H√†m n√†y ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a ·ªü ph·∫£n h·ªìi tr∆∞·ªõc
        st.session_state.eval_page_resources_initialized = eval_resources_ready

if st.session_state.eval_page_resources_initialized:
    eval_page_status_placeholder.success("‚úÖ T√†i nguy√™n trang ƒê√°nh gi√° ƒë√£ s·∫µn s√†ng!")

    # L·∫•y c√°c model objects ƒë√£ ƒë∆∞·ª£c t·∫£i tr∆∞·ªõc
    eval_pg_active_emb_name = st.session_state.eval_pg_selected_embedding_model_name
    eval_pg_active_rer_name = st.session_state.eval_pg_selected_reranker_model_name
    eval_pg_active_gem_name = st.session_state.eval_pg_selected_gemini_model_name

    eval_pg_active_emb_obj = st.session_state.eval_pg_loaded_embedding_models.get(eval_pg_active_emb_name)
    eval_pg_active_rag_comps = st.session_state.eval_pg_rag_components_per_embedding_model.get(eval_pg_active_emb_name)
    eval_pg_active_retriever = eval_pg_active_rag_comps[1] if eval_pg_active_rag_comps else None
    eval_pg_active_rer_obj = st.session_state.eval_pg_loaded_reranker_models.get(eval_pg_active_rer_name)
    eval_pg_active_gem_obj = load_gemini_model(eval_pg_active_gem_name)

    can_run_evaluation_flow = True
    # Ki·ªÉm tra c√°c model c·∫ßn thi·∫øt cho c√°c ch·∫ø ƒë·ªô kh√°c nhau
    if st.session_state.eval_pg_variation_mode == "S·ª≠ d·ª•ng file bi·∫øn th·ªÉ ƒë√£ t·∫£i l√™n":
        if not st.session_state.get("eval_pg_variations_data_from_file"):
            # S·∫Ω c√≥ th√¥ng b√°o l·ªói c·ª• th·ªÉ h∆°n khi nh·∫•n n√∫t "B·∫Øt ƒë·∫ßu"
            pass # Kh√¥ng d·ª´ng ngay ·ªü ƒë√¢y, ƒë·ªÉ ng∆∞·ªùi d√πng c√≥ c∆° h·ªôi t·∫£i file
    elif st.session_state.eval_pg_variation_mode == "T·∫°o m·ªõi t·ª´ LLM":
        if not eval_pg_active_gem_obj:
            st.error(f"L·ªói: Gemini model '{eval_pg_active_gem_name}' ch∆∞a t·∫£i ƒë∆∞·ª£c. C·∫ßn thi·∫øt ƒë·ªÉ t·∫°o bi·∫øn th·ªÉ m·ªõi.")
            can_run_evaluation_flow = False
    # Ki·ªÉm tra chung cho retriever v√† embedding n·∫øu kh√¥ng ph·∫£i ch·ªâ sinh bi·∫øn th·ªÉ
    if st.session_state.eval_pg_variation_mode != "Ch·ªâ sinh v√† l∆∞u bi·∫øn th·ªÉ (kh√¥ng ch·∫°y ƒë√°nh gi√°)":
        if not eval_pg_active_emb_obj:
            st.error(f"L·ªói: Embedding model '{eval_pg_active_emb_name.split('/')[-1]}' (ƒê√°nh gi√°) ch∆∞a t·∫£i.")
            can_run_evaluation_flow = False
        if not eval_pg_active_retriever:
            st.error(f"L·ªói: Retriever cho '{eval_pg_active_emb_name.split('/')[-1]}' (ƒê√°nh gi√°) ch∆∞a s·∫µn s√†ng.")
            can_run_evaluation_flow = False

    if can_run_evaluation_flow:
        st.caption(
            f"ƒê√°nh gi√° v·ªõi: Embedding: `{eval_pg_active_emb_name.split('/')[-1]}` | "
            f"Gemini: `{eval_pg_active_gem_name}` | "
            f"Query Mode: `{st.session_state.eval_pg_retrieval_query_mode}` | "
            f"Retrieval: `{st.session_state.eval_pg_retrieval_method}` | "
            f"Reranker: `{eval_pg_active_rer_name.split('/')[-1] if eval_pg_active_rer_name != 'Kh√¥ng s·ª≠ d·ª•ng' else 'T·∫Øt'}` | "
            f"Ch·∫ø ƒë·ªô Bi·∫øn th·ªÉ: `{st.session_state.eval_pg_variation_mode.split('(')[0].strip()}`"
        )

        # --- UI cho c√°c l·ª±a ch·ªçn ch·∫ø ƒë·ªô bi·∫øn th·ªÉ ---
        st.subheader("C·∫•u h√¨nh Bi·∫øn th·ªÉ C√¢u h·ªèi (Query Variations)")
        variation_mode_options_list = [
            "T·∫°o m·ªõi t·ª´ LLM",
            "Ch·ªâ sinh v√† l∆∞u bi·∫øn th·ªÉ (kh√¥ng ch·∫°y ƒë√°nh gi√°)", # ƒê·ªïi t√™n cho n√∫t ri√™ng
            "S·ª≠ d·ª•ng file bi·∫øn th·ªÉ ƒë√£ t·∫£i l√™n"
        ]
        # L·∫•y gi√° tr·ªã hi·ªán t·∫°i t·ª´ session_state ƒë·ªÉ gi·ªØ l·ª±a ch·ªçn khi rerun
        current_variation_mode_index = variation_mode_options_list.index(st.session_state.eval_pg_variation_mode) \
            if st.session_state.eval_pg_variation_mode in variation_mode_options_list else 0

        st.session_state.eval_pg_variation_mode = st.radio(
            "Ch·∫ø ƒë·ªô x·ª≠ l√Ω bi·∫øn th·ªÉ c√¢u h·ªèi:",
            options=variation_mode_options_list,
            key="eval_pg_variation_mode_radio_selector",
            index=current_variation_mode_index,
            horizontal=False,
            help=(
                "- **T·∫°o m·ªõi t·ª´ LLM:** M·ªói l·∫ßn ch·∫°y s·∫Ω g·ªçi LLM ƒë·ªÉ t·∫°o bi·∫øn th·ªÉ.\n"
                "- **Ch·ªâ sinh v√† l∆∞u bi·∫øn th·ªÉ:** Ch·∫°y LLM ƒë·ªÉ t·∫°o bi·∫øn th·ªÉ t·ª´ file ƒë√°nh gi√° g·ªëc, sau ƒë√≥ cho ph√©p t·∫£i xu·ªëng file JSON. Kh√¥ng ch·∫°y c√°c b∆∞·ªõc retrieval hay t√≠nh metrics.\n"
                "- **S·ª≠ d·ª•ng file bi·∫øn th·ªÉ ƒë√£ t·∫£i l√™n:** T·∫£i l√™n file JSON bi·∫øn th·ªÉ ƒë√£ l∆∞u. H·ªá th·ªëng s·∫Ω d√πng c√°c bi·∫øn th·ªÉ t·ª´ file n√†y thay v√¨ g·ªçi LLM."
            )
        )
        # Checkbox v√† File Uploader t√πy theo ch·∫ø ƒë·ªô
        if st.session_state.eval_pg_variation_mode == "T·∫°o m·ªõi t·ª´ LLM":
            st.checkbox(
                "L∆∞u c√°c bi·∫øn th·ªÉ c√¢u h·ªèi ƒë∆∞·ª£c t·∫°o ra file JSON?",
                key="eval_pg_save_newly_generated_variations_cb", # Key m·ªõi
                help="N·∫øu ch·ªçn, sau khi ch·∫°y ƒë√°nh gi√°, b·∫°n c√≥ th·ªÉ t·∫£i v·ªÅ file ch·ª©a c√°c bi·∫øn th·ªÉ v·ª´a ƒë∆∞·ª£c t·∫°o."
            )
        elif st.session_state.eval_pg_variation_mode == "S·ª≠ d·ª•ng file bi·∫øn th·ªÉ ƒë√£ t·∫£i l√™n":
            eval_pg_uploaded_variations_file_widget = st.file_uploader(
                "T·∫£i l√™n file JSON ch·ª©a bi·∫øn th·ªÉ c√¢u h·ªèi ƒë√£ l∆∞u:",
                type=["json"],
                key="eval_pg_var_file_uploader_widget",
                accept_multiple_files=False
            )
            if eval_pg_uploaded_variations_file_widget is not None:
                # Ch·ªâ x·ª≠ l√Ω n·∫øu file m·ªõi ƒë∆∞·ª£c t·∫£i l√™n ho·∫∑c ch∆∞a c√≥ file n√†o trong state
                if st.session_state.get("eval_pg_uploaded_variations_file_obj_name") != eval_pg_uploaded_variations_file_widget.name:
                    try:
                        variations_data_from_uploaded_file = json.loads(eval_pg_uploaded_variations_file_widget.getvalue().decode('utf-8'))
                        if not isinstance(variations_data_from_uploaded_file, dict) or \
                           not all(isinstance(item_v, dict) and "all_queries" in item_v for item_v in variations_data_from_uploaded_file.values()):
                            st.error("File bi·∫øn th·ªÉ kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng. C·∫ßn m·ªôt JSON object v·ªõi query_id l√†m key, v√† m·ªói value ch·ª©a 'all_queries'.")
                            st.session_state.eval_pg_variations_data_from_file = None
                        else:
                            st.session_state.eval_pg_variations_data_from_file = variations_data_from_uploaded_file
                            st.session_state.eval_pg_uploaded_variations_file_obj_name = eval_pg_uploaded_variations_file_widget.name # L∆∞u t√™n file ƒë·ªÉ tr√°nh x·ª≠ l√Ω l·∫°i
                            st.success(f"ƒê√£ t·∫£i v√† x·ª≠ l√Ω file bi·∫øn th·ªÉ: {eval_pg_uploaded_variations_file_widget.name} ({len(variations_data_from_uploaded_file)} query_ids).")
                    except Exception as e_var_json_upload:
                        st.error(f"L·ªói x·ª≠ l√Ω file JSON bi·∫øn th·ªÉ: {e_var_json_upload}")
                        st.session_state.eval_pg_variations_data_from_file = None
            elif st.session_state.get("eval_pg_variations_data_from_file"): # N·∫øu ƒë√£ c√≥ d·ªØ li·ªáu t·ª´ tr∆∞·ªõc
                 st.info(f"ƒêang s·ª≠ d·ª•ng file bi·∫øn th·ªÉ ƒë√£ t·∫£i: {st.session_state.get('eval_pg_uploaded_variations_file_obj_name')}")


        # --- T·∫£i File ƒê√°nh gi√° G·ªëc ---
        uploader_key_eval_pg_main = f"eval_pg_main_file_uploader_{st.session_state.eval_pg_upload_counter}"
        st.subheader("T·∫£i L√™n File ƒê√°nh gi√° G·ªëc (.json)")
        uploaded_file_eval_pg_main = st.file_uploader(
            "Ch·ªçn file JSON ch·ª©a d·ªØ li·ªáu ƒë√°nh gi√° g·ªëc (queries, relevant_ids)...",
            type=["json"],
            key=uploader_key_eval_pg_main
        )
        if uploaded_file_eval_pg_main is not None:
            if uploaded_file_eval_pg_main.name != st.session_state.eval_pg_uploaded_filename:
                try:
                    eval_data_list_pg_main = json.loads(uploaded_file_eval_pg_main.getvalue().decode('utf-8'))
                    # S∆° b·ªô ki·ªÉm tra c·∫•u tr√∫c file eval_data
                    if not isinstance(eval_data_list_pg_main, list) or \
                       (len(eval_data_list_pg_main) > 0 and not all(isinstance(item_e, dict) and "query" in item_e and "query_id" in item_e for item_e in eval_data_list_pg_main)):
                        st.error("File ƒë√°nh gi√° g·ªëc kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng. C·∫ßn m·ªôt danh s√°ch c√°c object, m·ªói object ph·∫£i c√≥ 'query' v√† 'query_id'.")
                        st.session_state.eval_pg_data = None
                    else:
                        st.session_state.eval_pg_data = eval_data_list_pg_main
                        st.session_state.eval_pg_uploaded_filename = uploaded_file_eval_pg_main.name
                        st.session_state.eval_pg_run_completed = False
                        st.session_state.eval_pg_results_df = None
                        st.session_state.eval_pg_last_config_run = {}
                        st.session_state.eval_pg_generated_variations_for_saving = None # Reset khi t·∫£i file m·ªõi
                        st.success(f"ƒê√£ t·∫£i file ƒë√°nh gi√° g·ªëc '{uploaded_file_eval_pg_main.name}' ({len(eval_data_list_pg_main)} c√¢u h·ªèi).")
                except Exception as e_json_main:
                    st.error(f"L·ªói x·ª≠ l√Ω file JSON ƒë√°nh gi√° g·ªëc: {e_json_main}")
                    st.session_state.eval_pg_data = None; st.session_state.eval_pg_uploaded_filename = None

        if st.session_state.eval_pg_data is not None:
            st.info(f"S·∫µn s√†ng x·ª≠ l√Ω v·ªõi d·ªØ li·ªáu t·ª´: **{st.session_state.eval_pg_uploaded_filename}** ({len(st.session_state.eval_pg_data)} c√¢u h·ªèi).")
            if st.checkbox("Hi·ªÉn th·ªã d·ªØ li·ªáu m·∫´u (5 d√≤ng ƒë·∫ßu)", key="eval_pg_show_preview_main"):
                st.dataframe(pd.DataFrame(st.session_state.eval_pg_data).head())

            # --- N√∫t th·ª±c thi ch√≠nh ---
            # N√∫t "Ch·ªâ sinh v√† l∆∞u bi·∫øn th·ªÉ"
            if st.session_state.eval_pg_variation_mode == "Ch·ªâ sinh v√† l∆∞u bi·∫øn th·ªÉ (kh√¥ng ch·∫°y ƒë√°nh gi√°)":
                if st.button("üìù B·∫Øt ƒë·∫ßu: Ch·ªâ Sinh v√† L∆∞u Bi·∫øn th·ªÉ C√¢u h·ªèi", key="eval_pg_generate_variations_only_btn"):
                    if not eval_pg_active_gem_obj:
                        st.error("L·ªói: C·∫ßn c√≥ Gemini model ƒë·ªÉ th·ª±c hi·ªán thao t√°c n√†y.")
                    else:
                        with st.spinner("‚è≥ ƒêang sinh bi·∫øn th·ªÉ cho t·∫•t c·∫£ c√°c c√¢u h·ªèi..."):
                            generated_data = generate_and_collect_variations_only(
                                eval_data=st.session_state.eval_pg_data,
                                gemini_model_object=eval_pg_active_gem_obj,
                                num_variations=config.NUM_QUERY_VARIATIONS
                            )
                            if generated_data:
                                st.session_state.eval_pg_generated_variations_for_saving = generated_data
                                # N√∫t download s·∫Ω xu·∫•t hi·ªán ·ªü d∆∞·ªõi
                            else:
                                st.error("Kh√¥ng th·ªÉ sinh bi·∫øn th·ªÉ. Vui l√≤ng ki·ªÉm tra log.")
            else: # C√°c ch·∫ø ƒë·ªô c√≤n l·∫°i ("T·∫°o m·ªõi t·ª´ LLM" ho·∫∑c "S·ª≠ d·ª•ng file...") s·∫Ω ch·∫°y ƒë√°nh gi√° retrieval
                run_eval_button_text = "üöÄ B·∫Øt ƒë·∫ßu ƒê√°nh gi√° Retrieval & Metrics"
                if st.session_state.eval_pg_variation_mode == "S·ª≠ d·ª•ng file bi·∫øn th·ªÉ ƒë√£ t·∫£i l√™n":
                    if not st.session_state.get("eval_pg_variations_data_from_file"):
                        run_eval_button_text = "‚ö†Ô∏è Vui l√≤ng t·∫£i file bi·∫øn th·ªÉ tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu"


                if st.button(run_eval_button_text, key="eval_pg_start_full_eval_button",
                             disabled=(st.session_state.eval_pg_variation_mode == "S·ª≠ d·ª•ng file bi·∫øn th·ªÉ ƒë√£ t·∫£i l√™n" and \
                                       not st.session_state.get("eval_pg_variations_data_from_file"))):

                    # Ki·ªÉm tra ƒëi·ªÅu ki·ªán ti√™n quy·∫øt
                    proceed_run = True
                    variations_to_pass_to_run = None
                    if st.session_state.eval_pg_variation_mode == "S·ª≠ d·ª•ng file bi·∫øn th·ªÉ ƒë√£ t·∫£i l√™n":
                        if not st.session_state.get("eval_pg_variations_data_from_file"):
                            st.error("B·∫°n ƒë√£ ch·ªçn 'S·ª≠ d·ª•ng file bi·∫øn th·ªÉ ƒë√£ t·∫£i l√™n' nh∆∞ng ch∆∞a t·∫£i file ho·∫∑c file kh√¥ng h·ª£p l·ªá.")
                            proceed_run = False
                        else:
                            variations_to_pass_to_run = st.session_state.eval_pg_variations_data_from_file
                    elif st.session_state.eval_pg_variation_mode == "T·∫°o m·ªõi t·ª´ LLM":
                        if not eval_pg_active_gem_obj:
                            st.error("B·∫°n ƒë√£ ch·ªçn 'T·∫°o m·ªõi t·ª´ LLM' nh∆∞ng Gemini model ch∆∞a s·∫µn s√†ng.")
                            proceed_run = False
                    # Ki·ªÉm tra c√°c model kh√°c n·∫øu kh√¥ng ph·∫£i ch·ªâ sinh bi·∫øn th·ªÉ (ƒë√£ l√†m ·ªü tr√™n, can_run_evaluation_flow)

                    if proceed_run and can_run_evaluation_flow: # can_run_evaluation_flow ki·ªÉm tra retriever, emb
                        eval_config_for_this_run_pg_main = {
                            'embedding_model_name': eval_pg_active_emb_name,
                            'retrieval_query_mode': st.session_state.eval_pg_retrieval_query_mode,
                            'retrieval_method': st.session_state.eval_pg_retrieval_method,
                            'selected_reranker_model_name': eval_pg_active_rer_name,
                            'gemini_model_name': eval_pg_active_gem_name,
                            'variation_mode_used': st.session_state.eval_pg_variation_mode,
                        }
                        st.session_state.eval_pg_last_config_run = eval_config_for_this_run_pg_main.copy()

                        with st.spinner("‚è≥ ƒêang ch·∫°y ƒë√°nh gi√° Retrieval & Metrics..."):
                            start_eval_time_pg_main = time.time()
                            save_new_vars_flag = (st.session_state.eval_pg_variation_mode == "T·∫°o m·ªõi t·ª´ LLM" and \
                                                  st.session_state.get("eval_pg_save_newly_generated_variations_cb", False))

                            results_df_output_pg_main = run_retrieval_evaluation(
                                eval_data=st.session_state.eval_pg_data,
                                retriever_instance_for_eval=eval_pg_active_retriever,
                                embedding_model_object_for_eval=eval_pg_active_emb_obj,
                                reranking_model_object_for_eval=eval_pg_active_rer_obj,
                                gemini_model_object_for_eval=eval_pg_active_gem_obj,
                                eval_config_params=st.session_state.eval_pg_last_config_run,
                                preloaded_query_variations=variations_to_pass_to_run
                                # C·ªù save_generated_variations_flag kh√¥ng c·∫ßn truy·ªÅn n·ªØa
                                # v√¨ run_retrieval_evaluation s·∫Ω kh√¥ng ch·ªãu tr√°ch nhi·ªám l∆∞u,
                                # n√≥ ch·ªâ sinh n·∫øu c·∫ßn. Vi·ªác l∆∞u s·∫Ω do logic b√™n ngo√†i sau khi
                                # run_retrieval_evaluation tr·∫£ v·ªÅ c√°c bi·∫øn th·ªÉ ƒë√£ sinh (n·∫øu c√≥).
                                # Tuy nhi√™n, ƒë·ªÉ ƒë∆°n gi·∫£n, ta c√≥ th·ªÉ gi·ªØ l·∫°i vi·ªác `run_retrieval_evaluation`
                                # ghi v√†o session_state n·∫øu `save_new_vars_flag` l√† True v√† n√≥ th·ª±c s·ª± sinh m·ªõi.
                                # Nh∆∞ng t·ªët h∆°n l√† `run_retrieval_evaluation` tr·∫£ v·ªÅ c√°c bi·∫øn th·ªÉ ƒë√£ sinh (n·∫øu c√≥).
                                # Hi·ªán t·∫°i, `run_retrieval_evaluation` kh√¥ng tr·∫£ v·ªÅ c√°c bi·∫øn th·ªÉ.
                                # N√≥ s·∫Ω s·ª≠ d·ª•ng preloaded ho·∫∑c t·ª± sinh. N·∫øu mu·ªën l∆∞u c√°c bi·∫øn th·ªÉ sinh m·ªõi khi ch·∫°y full eval,
                                # c·∫ßn s·ª≠a `run_retrieval_evaluation` ƒë·ªÉ tr·∫£ v·ªÅ ch√∫ng, ho·∫∑c n√≥ t·ª± ghi v√†o st.session_state.
                                # C√°ch ƒë∆°n gi·∫£n l√† sau khi ch·∫°y full eval, n·∫øu ch·∫ø ƒë·ªô l√† "T·∫°o m·ªõi" v√† "L∆∞u", th√¨
                                # ta c√≥ th·ªÉ g·ªçi l·∫°i h√†m generate_and_collect_variations_only ƒë·ªÉ ƒë·∫£m b·∫£o c√≥ file l∆∞u.
                                # Ho·∫∑c, `run_retrieval_evaluation` s·∫Ω c·∫ßn m·ªôt c∆° ch·∫ø ƒë·ªÉ tr·∫£ v·ªÅ c√°c bi·∫øn th·ªÉ ƒë√≥.
                            )
                            total_eval_time_pg_main = time.time() - start_eval_time_pg_main
                            st.success(f"Ho√†n th√†nh ƒë√°nh gi√° Retrieval & Metrics sau {total_eval_time_pg_main:.2f} gi√¢y.")
                            st.session_state.eval_pg_results_df = results_df_output_pg_main
                            st.session_state.eval_pg_run_completed = True

                            # N·∫øu ng∆∞·ªùi d√πng mu·ªën l∆∞u c√°c bi·∫øn th·ªÉ ƒë∆∞·ª£c t·∫°o m·ªõi trong l·∫ßn ch·∫°y ƒë√°nh gi√° n√†y
                            if st.session_state.eval_pg_variation_mode == "T·∫°o m·ªõi t·ª´ LLM" and \
                               st.session_state.get("eval_pg_save_newly_generated_variations_cb", False) and \
                               results_df_output_pg_main is not None and not results_df_output_pg_main.empty:
                                # C·∫ßn thu th·∫≠p l·∫°i c√°c bi·∫øn th·ªÉ ƒë√£ ƒë∆∞·ª£c sinh (n·∫øu run_retrieval_evaluation kh√¥ng tr·∫£ v·ªÅ)
                                # C√°ch an to√†n nh·∫•t l√† g·ªçi l·∫°i generate_and_collect_variations_only
                                # Ho·∫∑c s·ª≠a run_retrieval_evaluation ƒë·ªÉ n√≥ tr·∫£ v·ªÅ dict c√°c bi·∫øn th·ªÉ n·∫øu ƒë∆∞·ª£c sinh m·ªõi.
                                # Hi·ªán t·∫°i, ta gi·∫£ ƒë·ªãnh ng∆∞·ªùi d√πng s·∫Ω d√πng n√∫t "Ch·ªâ Sinh v√† L∆∞u" n·∫øu mu·ªën file ch√≠nh x√°c.
                                # Ho·∫∑c, ta c√≥ th·ªÉ th√™m m·ªôt c·ªôt "generated_variations_details" v√†o results_df r·ªìi tr√≠ch xu·∫•t.
                                # ƒê·ªÉ ƒë∆°n gi·∫£n cho l·∫ßn n√†y, n·∫øu mu·ªën l∆∞u, ng∆∞·ªùi d√πng n√™n d√πng n√∫t "Ch·ªâ Sinh v√† L∆∞u".
                                st.info("ƒê·ªÉ l∆∞u c√°c bi·∫øn th·ªÉ c√¢u h·ªèi v·ª´a ƒë∆∞·ª£c t·∫°o trong qu√° tr√¨nh ƒë√°nh gi√°, vui l√≤ng s·ª≠ d·ª•ng n√∫t 'üìù B·∫Øt ƒë·∫ßu: Ch·ªâ Sinh v√† L∆∞u Bi·∫øn th·ªÉ C√¢u h·ªèi' sau khi qu√° tr√¨nh n√†y ho√†n t·∫•t (n·∫øu b·∫°n mu·ªën m·ªôt file ri√™ng).")


                            st.rerun() # Rerun ƒë·ªÉ hi·ªÉn th·ªã k·∫øt qu·∫£

        # --- N√∫t t·∫£i xu·ªëng file bi·∫øn th·ªÉ (n·∫øu c√≥ v√† ƒë∆∞·ª£c t·∫°o t·ª´ n√∫t "Ch·ªâ sinh v√† l∆∞u") ---
        if st.session_state.get("eval_pg_generated_variations_for_saving"):
            try:
                variations_json_to_save = json.dumps(st.session_state.eval_pg_generated_variations_for_saving, indent=2, ensure_ascii=False)
                ts_var_save = datetime.now().strftime("%Y%m%d_%H%M%S")
                gem_name_var_save = st.session_state.eval_pg_selected_gemini_model_name.split('/')[-1].replace('.','-')[:15]
                var_fname_save = f"generated_query_variations_{gem_name_var_save}_{ts_var_save}.json"
                st.download_button(
                    label="üì• T·∫£i v·ªÅ File Bi·∫øn th·ªÉ C√¢u h·ªèi ƒë√£ t·∫°o (.json)",
                    data=variations_json_to_save,
                    file_name=var_fname_save,
                    mime="application/json",
                    key="download_generated_variations_btn"
                )
            except Exception as e_dl_gen_var:
                st.error(f"L·ªói khi chu·∫©n b·ªã file bi·∫øn th·ªÉ ƒë√£ t·∫°o ƒë·ªÉ t·∫£i xu·ªëng: {e_dl_gen_var}")


        # --- Hi·ªÉn th·ªã k·∫øt qu·∫£ ƒë√°nh gi√° (n·∫øu c√≥) ---
        if st.session_state.eval_pg_run_completed and st.session_state.eval_pg_results_df is not None:
            st.subheader("K·∫øt qu·∫£ ƒê√°nh gi√° Chi ti·∫øt")
            detailed_results_df_display_pg = st.session_state.eval_pg_results_df
            last_config_run_display_pg = st.session_state.eval_pg_last_config_run

            st.markdown("**C·∫•u h√¨nh ƒë√£ s·ª≠ d·ª•ng cho l·∫ßn ch·∫°y cu·ªëi:**")
            cfg_cols_pg = st.columns(6) # Th√™m c·ªôt cho Variation Mode
            emb_n_disp_pg = last_config_run_display_pg.get('embedding_model_name', 'N/A').split('/')[-1]
            cfg_cols_pg[0].metric("Embedding", emb_n_disp_pg)
            cfg_cols_pg[1].metric("Query Mode", last_config_run_display_pg.get('retrieval_query_mode', 'N/A'))
            cfg_cols_pg[2].metric("Ret. Method", last_config_run_display_pg.get('retrieval_method', 'N/A'))
            rer_n_disp_pg = last_config_run_display_pg.get('selected_reranker_model_name', 'N/A').split('/')[-1]
            if rer_n_disp_pg == "Kh√¥ng s·ª≠ d·ª•ng".split('/')[-1]: rer_n_disp_pg = "T·∫Øt"
            cfg_cols_pg[3].metric("Reranker", rer_n_disp_pg)
            gem_n_disp_pg = last_config_run_display_pg.get('gemini_model_name', 'N/A').split('/')[-1]
            cfg_cols_pg[4].metric("Gemini (Var)", gem_n_disp_pg)
            var_mode_cfg_disp = last_config_run_display_pg.get('variation_mode_used', 'N/A').split('(')[0].strip()
            cfg_cols_pg[5].metric("Variation Mode", var_mode_cfg_disp)


            avg_metrics_res_pg, num_eval_pg, num_skip_err_pg = calculate_average_metrics(detailed_results_df_display_pg)

            st.metric("T·ªïng s·ªë Queries trong File", len(detailed_results_df_display_pg))
            col_rc1_pg, col_rc2_pg = st.columns(2)
            col_rc1_pg.metric("Queries ƒê√°nh gi√° H·ª£p l·ªá", num_eval_pg)
            col_rc2_pg.metric("Queries B·ªè qua / L·ªói Runtime", num_skip_err_pg)

            if avg_metrics_res_pg:
                st.markdown("#### Metrics Trung b√¨nh @K (tr√™n c√°c queries h·ª£p l·ªá)")
                # ... (gi·ªØ nguy√™n ph·∫ßn hi·ªÉn th·ªã metrics P, R, F1, MRR, NDCG) ...
                k_vals_disp_pg = [3, 5, 10]
                cols_k_pg = st.columns(len(k_vals_disp_pg))
                for idx_k_pg, k_v_pg in enumerate(k_vals_disp_pg):
                    with cols_k_pg[idx_k_pg]:
                        st.markdown(f"**K = {k_v_pg}**")
                        st.text(f"Precision: {avg_metrics_res_pg.get(f'avg_precision@{k_v_pg}', 0.0):.4f}")
                        st.text(f"Recall:    {avg_metrics_res_pg.get(f'avg_recall@{k_v_pg}', 0.0):.4f}")
                        st.text(f"F1:        {avg_metrics_res_pg.get(f'avg_f1@{k_v_pg}', 0.0):.4f}")
                        st.text(f"MRR:       {avg_metrics_res_pg.get(f'avg_mrr@{k_v_pg}', 0.0):.4f}")
                        st.text(f"NDCG:      {avg_metrics_res_pg.get(f'avg_ndcg@{k_v_pg}', 0.0):.4f}")

                st.markdown("#### Th√¥ng tin Hi·ªáu nƒÉng & S·ªë l∆∞·ª£ng Trung b√¨nh (tr√™n c√°c queries h·ª£p l·ªá)")
                # ... (gi·ªØ nguy√™n ph·∫ßn hi·ªÉn th·ªã hi·ªáu nƒÉng) ...
                perf_col1_pg, perf_col2_pg, perf_col3_pg, perf_col4_pg = st.columns(4) # Th√™m c·ªôt
                perf_col1_pg.metric("Avg. Query Time (s)", f"{avg_metrics_res_pg.get('avg_processing_time', 0.0):.2f}s")
                perf_col1_pg.metric("Avg. Variation Time (s)", f"{avg_metrics_res_pg.get('avg_variation_time', 0.0):.3f}s") # Ch√≠nh x√°c h∆°n
                perf_col2_pg.metric("Avg. Search Time (s)", f"{avg_metrics_res_pg.get('avg_search_time', 0.0):.2f}s")
                perf_col2_pg.metric("Avg. Rerank Time (s)", f"{avg_metrics_res_pg.get('avg_rerank_time', 0.0):.3f}s") # Ch√≠nh x√°c h∆°n
                perf_col3_pg.metric("Avg. #Variations Gen", f"{avg_metrics_res_pg.get('avg_num_variations_generated', 0.0):.1f}")
                perf_col3_pg.metric("Avg. #Docs Reranked", f"{avg_metrics_res_pg.get('avg_num_docs_reranked', 0.0):.1f}")
                perf_col4_pg.metric("Avg. #Docs After Rerank", f"{avg_metrics_res_pg.get('avg_num_retrieved_after_rerank',0.0):.1f}")
                perf_col4_pg.metric("Avg. #Unique Docs Found", f"{avg_metrics_res_pg.get('avg_num_unique_docs_found',0.0):.1f}")


            with st.expander("Xem K·∫øt qu·∫£ Chi ti·∫øt t·ª´ng Query (Raw Data)"):
                display_cols_eval_pg_results = [
                    'query_id', 'query', 'status', 'error_message',
                    'embedding_model_name', 'retrieval_query_mode','retrieval_method', 'selected_reranker_model',
                    'variation_mode_run', 'variation_source', 'llm_model_for_variation', # Th√™m c√°c c·ªôt m·ªõi
                    'precision@3', 'recall@3', 'f1@3', 'mrr@3', 'ndcg@3',
                    'precision@5', 'recall@5', 'f1@5', 'mrr@5', 'ndcg@5',
                    'precision@10', 'recall@10', 'f1@10', 'mrr@10', 'ndcg@10',
                    'processing_time', 'variation_time', 'search_time', 'rerank_time',
                    'num_variations_generated','num_unique_docs_found', 'num_retrieved_before_rerank',
                    'num_docs_reranked', 'num_retrieved_after_rerank',
                    'summarizing_query', 'retrieved_ids', 'relevant_ids'
                ]
                existing_display_cols_eval_pg_results = [col for col in display_cols_eval_pg_results if col in detailed_results_df_display_pg.columns]
                st.dataframe(detailed_results_df_display_pg[existing_display_cols_eval_pg_results])

            st.subheader("L∆∞u K·∫øt qu·∫£ ƒê√°nh gi√° Retrieval")
            # ... (gi·ªØ nguy√™n logic t·∫£i file k·∫øt qu·∫£ ƒë√°nh gi√°) ...
            try:
                results_json_pg_main = detailed_results_df_display_pg.to_json(orient='records', indent=2, force_ascii=False)
                results_csv_pg_main = detailed_results_df_display_pg.to_csv(index=False).encode('utf-8')
                timestamp_pg_main = datetime.now().strftime("%Y%m%d_%H%M%S")

                emb_sfx_pg_main = last_config_run_display_pg.get('embedding_model_name', 'na').split('/')[-1].replace('-', '').replace('_', '')[:10]
                qmode_sfx_pg_main = last_config_run_display_pg.get('retrieval_query_mode', 'na').lower()[:3]
                method_sfx_pg_main = last_config_run_display_pg.get('retrieval_method', 'na').lower()
                rer_sfx_pg_main = "norr"
                sel_rer_fname_pg_main = last_config_run_display_pg.get('selected_reranker_model_name', 'Kh√¥ng s·ª≠ d·ª•ng')
                if sel_rer_fname_pg_main != 'Kh√¥ng s·ª≠ d·ª•ng':
                    rer_sfx_pg_main = sel_rer_fname_pg_main.split('/')[-1].replace('-', '').replace('_', '')[:10]
                mod_sfx_pg_main = last_config_run_display_pg.get('gemini_model_name', 'gemini').split('/')[-1].replace('.','-')[:15]
                var_mode_sfx_pg_main = last_config_run_display_pg.get('variation_mode_used', 'na').lower().replace(" ","")[:10]


                base_fname_pg_main = f"eval_results_{emb_sfx_pg_main}_{qmode_sfx_pg_main}_{method_sfx_pg_main}_{rer_sfx_pg_main}_{mod_sfx_pg_main}_{var_mode_sfx_pg_main}_{timestamp_pg_main}"
                fname_json_pg_main = f"{base_fname_pg_main}.json"
                fname_csv_pg_main = f"{base_fname_pg_main}.csv"

                dl_col1_pg_main, dl_col2_pg_main = st.columns(2)
                with dl_col1_pg_main:
                    st.download_button("üíæ T·∫£i v·ªÅ K·∫øt qu·∫£ ƒê√°nh gi√° (JSON)", results_json_pg_main, fname_json_pg_main, "application/json", key="dl_json_eval_pg_main")
                with dl_col2_pg_main:
                    st.download_button("üíæ T·∫£i v·ªÅ K·∫øt qu·∫£ ƒê√°nh gi√° (CSV)", results_csv_pg_main, fname_csv_pg_main, "text/csv", key="dl_csv_eval_pg_main")
            except Exception as e_file_dl_main:
                st.error(f"L·ªói khi chu·∫©n b·ªã file k·∫øt qu·∫£ ƒë√°nh gi√°: {e_file_dl_main}")


        st.markdown("---")
        st.subheader("Qu·∫£n l√Ω Tr·∫°ng th√°i ƒê√°nh gi√°")
        if st.button("X√≥a File ƒê√£ T·∫£i v√† K·∫øt Qu·∫£ Hi·ªán T·∫°i", key="eval_pg_clear_state_button_main"):
            st.session_state.eval_pg_data = None
            st.session_state.eval_pg_upload_counter += 1
            st.session_state.eval_pg_run_completed = False
            st.session_state.eval_pg_results_df = None
            st.session_state.eval_pg_last_config_run = {}
            st.session_state.eval_pg_uploaded_filename = None
            st.session_state.eval_pg_variations_data_from_file = None # X√≥a c·∫£ d·ªØ li·ªáu bi·∫øn th·ªÉ ƒë√£ t·∫£i
            st.session_state.eval_pg_uploaded_variations_file_obj_name = None
            st.session_state.eval_pg_generated_variations_for_saving = None # X√≥a c·∫£ bi·∫øn th·ªÉ v·ª´a t·∫°o
            st.success("ƒê√£ x√≥a tr·∫°ng th√°i ƒë√°nh gi√° hi·ªán t·∫°i.")
            time.sleep(1)
            st.rerun()
    else: # can_run_evaluation_flow is False
        st.warning("‚ö†Ô∏è Kh√¥ng th·ªÉ ti·∫øn h√†nh do thi·∫øu c√°c th√†nh ph·∫ßn model c·∫ßn thi·∫øt. Vui l√≤ng ki·ªÉm tra th√¥ng b√°o l·ªói ·ªü tr√™n v√† c·∫•u h√¨nh trong sidebar.")

elif not st.session_state.eval_page_resources_initialized:
    eval_page_status_placeholder.error("‚ö†Ô∏è T√†i nguy√™n trang ƒê√°nh gi√° CH∆ØA S·∫¥N S√ÄNG. L·ªói trong qu√° tr√¨nh t·∫£i model ho·∫∑c t·∫°o RAG. Vui l√≤ng ki·ªÉm tra log chi ti·∫øt ho·∫∑c l√†m m·ªõi trang.")