# pages/2_Evaluation.py
import time
import streamlit as st
import pandas as pd
import json
import os
from datetime import datetime
import sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
import config
import utils
import data_loader
from retriever import HybridRetriever
from utils import precision_at_k, recall_at_k, f1_at_k, mrr_at_k, ndcg_at_k, calculate_average_metrics

def run_retrieval_evaluation(
    eval_data: list,
    hybrid_retriever: HybridRetriever,
    embedding_model,
    reranking_model, 
    gemini_model,
    eval_config: dict 
    ):

    results_list = []
    k_values = [3, 5, 10] 

    # --- Láº¥y cáº¥u hÃ¬nh tá»« eval_config ---
    retrieval_query_mode = eval_config.get('retrieval_query_mode', 'Tá»•ng quÃ¡t')
    retrieval_method = eval_config.get('retrieval_method', 'hybrid')
    use_reranker = eval_config.get('use_reranker', True)
    dummy_history = None 

    progress_bar = st.progress(0)
    status_text = st.empty()

    total_items = len(eval_data)
    queries_per_batch = 15 # Giá»›i háº¡n sá»‘ lÆ°á»£ng query trÆ°á»›c khi táº¡m dá»«ng
    wait_time_seconds = 60 # Thá»i gian táº¡m dá»«ng

    for i, item in enumerate(eval_data):
        # Táº¡m dá»«ng sau má»—i batch
        if i > 0 and i % queries_per_batch == 0:
            pause_msg = f"ÄÃ£ xá»­ lÃ½ {i}/{total_items} queries. Táº¡m dá»«ng {wait_time_seconds} giÃ¢y..."
            status_text.text(pause_msg)
            time.sleep(wait_time_seconds)
            status_text.text(f"Tiáº¿p tá»¥c xá»­ lÃ½ query {i+1}/{total_items}...")

        query_id = item.get("query_id"); original_query = item.get("query")
        relevant_chunk_ids = set(item.get("relevant_chunk_ids", []))

        status_text.text(f"Äang xá»­ lÃ½ query {i+1}/{total_items}: {query_id} (QueryMode: {retrieval_query_mode}, Method: {retrieval_method}, Rerank: {use_reranker})")

        start_time = time.time()
        # --- Khá»Ÿi táº¡o query_metrics vá»›i cÃ¡c trÆ°á»ng cáº¥u hÃ¬nh ---
        query_metrics = {
            "query_id": query_id, "query": original_query,
            "retrieval_query_mode": retrieval_query_mode,
            "retrieval_method": retrieval_method,
            "use_reranker": use_reranker,
            "status": "error", "retrieved_ids": [], "relevant_ids": list(relevant_chunk_ids),
            "processing_time": 0.0, 'summarizing_query': '',
            'variation_time': 0.0, 'search_time': 0.0, 'rerank_time': 0.0,
            'num_variations_generated': 0, 'num_unique_docs_found': 0, 'num_docs_reranked': 0,
            'num_retrieved_before_rerank': 0, 'num_retrieved_after_rerank': 0
        }
        # VÃ²ng láº·p khá»Ÿi táº¡o metrics, tá»± Ä‘á»™ng dÃ¹ng k_values má»›i
        for k in k_values:
            query_metrics[f'precision@{k}'] = 0.0; query_metrics[f'recall@{k}'] = 0.0
            query_metrics[f'f1@{k}'] = 0.0; query_metrics[f'mrr@{k}'] = 0.0; query_metrics[f'ndcg@{k}'] = 0.0

        try:
            # BÆ°á»›c 1: Táº¡o variations/summarizing query (luÃ´n cháº¡y)
            variation_start = time.time()
            relevance_status, _, all_queries, summarizing_query = utils.generate_query_variations(
                original_query=original_query, gemini_model=gemini_model,
                chat_history=dummy_history, 
                num_variations=config.NUM_QUERY_VARIATIONS
            )
            query_metrics["variation_time"] = time.time() - variation_start
            query_metrics["summarizing_query"] = summarizing_query
            query_metrics["num_variations_generated"] = len(all_queries) - 1

            if relevance_status == 'invalid':
                query_metrics["status"] = "skipped_irrelevant"
                query_metrics["processing_time"] = time.time() - start_time
                results_list.append(query_metrics)
                progress_bar.progress((i + 1) / total_items)
                continue

            # --- BÆ°á»›c 2: XÃ¡c Ä‘á»‹nh query(s) Ä‘á»ƒ tÃ¬m kiáº¿m ---
            queries_to_search = []
            if retrieval_query_mode == 'ÄÆ¡n giáº£n': queries_to_search = [original_query]
            elif retrieval_query_mode == 'Tá»•ng quÃ¡t': queries_to_search = [summarizing_query]
            elif retrieval_query_mode == 'SÃ¢u': queries_to_search = all_queries

            # --- BÆ°á»›c 3: Thá»±c hiá»‡n Retrieval ---
            collected_docs_data = {}
            search_start = time.time()
            for q_variant in queries_to_search:
                if not q_variant: continue
                search_results = hybrid_retriever.search(
                    q_variant, embedding_model,
                    method=retrieval_method,
                    k=config.VECTOR_K_PER_QUERY
                )
                for item in search_results:
                    doc_index = item.get('index')
                    if isinstance(doc_index, int) and doc_index >= 0 and doc_index not in collected_docs_data:
                        collected_docs_data[doc_index] = item
            query_metrics["search_time"] = time.time() - search_start
            query_metrics["num_unique_docs_found"] = len(collected_docs_data)

            # --- Chuáº©n bá»‹ danh sÃ¡ch káº¿t quáº£ retrieval ---
            retrieved_docs_list = list(collected_docs_data.values())
            sort_reverse = (retrieval_method != 'dense')
            retrieved_docs_list.sort(key=lambda x: x.get('score', 0 if sort_reverse else float('inf')), reverse=sort_reverse)
            query_metrics["num_retrieved_before_rerank"] = len(retrieved_docs_list)


            # --- BÆ°á»›c 4: Re-ranking (Náº¿u báº­t) ---
            final_docs_for_metrics = []
            rerank_start = time.time()

            if use_reranker and retrieved_docs_list:
                query_for_reranking = summarizing_query if summarizing_query else original_query
                docs_to_rerank = retrieved_docs_list[:config.MAX_DOCS_FOR_RERANK]
                query_metrics["num_docs_reranked"] = len(docs_to_rerank)

                rerank_input = [{'doc': item['doc'], 'index': item['index']} for item in docs_to_rerank]

                reranked_results = utils.rerank_documents(
                    query_for_reranking, rerank_input, reranking_model
                )
                final_docs_for_metrics = reranked_results[:config.FINAL_NUM_RESULTS_AFTER_RERANK]
                query_metrics["rerank_time"] = time.time() - rerank_start

            elif retrieved_docs_list:
                final_docs_for_metrics = retrieved_docs_list[:config.FINAL_NUM_RESULTS_AFTER_RERANK]
                query_metrics["rerank_time"] = 0.0
                query_metrics["num_docs_reranked"] = 0
            else:
                 query_metrics["rerank_time"] = 0.0
                 query_metrics["num_docs_reranked"] = 0

            query_metrics["num_retrieved_after_rerank"] = len(final_docs_for_metrics)

            # --- BÆ°á»›c 5: Láº¥y IDs vÃ  TÃ­nh Metrics ---
            retrieved_ids = []
            for res in final_docs_for_metrics:
                doc_data = res.get('doc', {})
                chunk_id = None
                if isinstance(doc_data, dict):
                    chunk_id = doc_data.get('id')
                    if not chunk_id:
                        metadata = doc_data.get('metadata', {})
                        if isinstance(metadata, dict):
                            chunk_id = metadata.get('id') or metadata.get('chunk_id')
                if chunk_id:
                    retrieved_ids.append(str(chunk_id))

            query_metrics["retrieved_ids"] = retrieved_ids

            query_metrics["status"] = "evaluated"
            # VÃ²ng láº·p tÃ­nh metrics, tá»± Ä‘á»™ng dÃ¹ng k_values má»›i
            for k in k_values:
                query_metrics[f'precision@{k}'] = precision_at_k(retrieved_ids, relevant_chunk_ids, k)
                query_metrics[f'recall@{k}'] = recall_at_k(retrieved_ids, relevant_chunk_ids, k)
                query_metrics[f'f1@{k}'] = f1_at_k(retrieved_ids, relevant_chunk_ids, k)
                query_metrics[f'mrr@{k}'] = mrr_at_k(retrieved_ids, relevant_chunk_ids, k)
                query_metrics[f'ndcg@{k}'] = ndcg_at_k(retrieved_ids, relevant_chunk_ids, k)


        except Exception as e:
            query_metrics["status"] = "error_runtime"
            query_metrics["error_message"] = str(e)
        finally:
            query_metrics["processing_time"] = time.time() - start_time
            results_list.append(query_metrics)
            progress_bar.progress((i + 1) / total_items)

    status_text.text(f"HoÃ n thÃ nh Ä‘Ã¡nh giÃ¡ {total_items} queries!")
    return pd.DataFrame(results_list)

# --- Giao diá»‡n Streamlit ---
st.set_page_config(page_title="ÄÃ¡nh giÃ¡ Retrieval", layout="wide")
st.title("ğŸ“Š ÄÃ¡nh giÃ¡ Há»‡ thá»‘ng Retrieval")

st.markdown("""
Trang nÃ y cho phÃ©p báº¡n cháº¡y Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t cá»§a há»‡ thá»‘ng retrieval vÃ  reranking
dá»±a trÃªn má»™t táº­p dá»¯ liá»‡u cÃ¢u há»i vÃ  cÃ¡c chunk tÃ i liá»‡u liÃªn quan (ground truth).
Sá»­ dá»¥ng cáº¥u hÃ¬nh **hiá»‡n táº¡i Ä‘Æ°á»£c chá»n trÃªn sidebar cá»§a trang nÃ y**.
""")
# Debug: Hiá»ƒn thá»‹ tráº¡ng thÃ¡i cáº¥u hÃ¬nh hiá»‡n táº¡i trong session state trÃªn trang Chatbot
st.sidebar.subheader("Debug State (Chatbot)")
st.sidebar.write(f"Gemini Model: {st.session_state.get('selected_gemini_model', 'N/A')}")
st.sidebar.write(f"Answer Mode: {st.session_state.get('answer_mode', 'N/A')}")
st.sidebar.write(f"Query Mode: {st.session_state.get('retrieval_query_mode', 'N/A')}")
st.sidebar.write(f"Retrieval Method: {st.session_state.get('retrieval_method', 'N/A')}")
st.sidebar.write(f"Use Reranker: {st.session_state.get('use_reranker', 'N/A')}")
st.sidebar.write(f"Use History LLM1: {st.session_state.get('use_history_for_llm1', 'N/A')}")
# --- sidebar ---
with st.sidebar:
    st.title("TÃ¹y chá»n ÄÃ¡nh giÃ¡")

    DEFAULT_EVAL_CONFIG_STATE = {
        "selected_gemini_model": st.session_state.get("selected_gemini_model", config.DEFAULT_GEMINI_MODEL),
        "retrieval_query_mode": st.session_state.get("retrieval_query_mode", 'Tá»•ng quÃ¡t'),
        "retrieval_method": st.session_state.get("retrieval_method", 'hybrid'),
        "use_reranker": st.session_state.get("use_reranker", True),
    }

    for key, default_value in DEFAULT_EVAL_CONFIG_STATE.items():
        if key not in st.session_state:
            st.session_state[key] = default_value

    if 'use_history_for_llm1' not in st.session_state:
        st.session_state.use_history_for_llm1 = False


    st.header("MÃ´ hÃ¬nh")
    st.selectbox(
        "Chá»n mÃ´ hÃ¬nh Gemini (Ä‘á»ƒ táº¡o query variations):",
        options=config.AVAILABLE_GEMINI_MODELS,
        index=config.AVAILABLE_GEMINI_MODELS.index(st.session_state.get('selected_gemini_model', config.DEFAULT_GEMINI_MODEL)), # Äá»c tá»« state
        key="selected_gemini_model", # Ghi vÃ o state khi thay Ä‘á»•i
        help="Chá»n mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n Ä‘á»ƒ phÃ¢n tÃ­ch vÃ  táº¡o biáº¿n thá»ƒ cÃ¢u há»i cho Retrieval."
    )

    st.header("Cáº¥u hÃ¬nh Retrieval")

    st.radio(
        "Nguá»“n cÃ¢u há»i cho Retrieval:",
        options=['ÄÆ¡n giáº£n', 'Tá»•ng quÃ¡t', 'SÃ¢u'],
        index=['ÄÆ¡n giáº£n', 'Tá»•ng quÃ¡t', 'SÃ¢u'].index(st.session_state.get('retrieval_query_mode', 'Tá»•ng quÃ¡t')), # Äá»c tá»« state
        key="retrieval_query_mode", # Ghi vÃ o state khi thay Ä‘á»•i
        horizontal=True,
        help=(
            "**ÄÆ¡n giáº£n:** Chá»‰ dÃ¹ng cÃ¢u há»i gá»‘c.\n"
            "**Tá»•ng quÃ¡t:** Chá»‰ dÃ¹ng cÃ¢u há»i tÃ³m táº¯t (do AI táº¡o).\n"
            "**SÃ¢u:** DÃ¹ng cáº£ cÃ¢u há»i gá»‘c vÃ  cÃ¡c biáº¿n thá»ƒ (do AI táº¡o)."
        )
    )

    st.radio(
        "PhÆ°Æ¡ng thá»©c Retrieval:",
        options=['dense', 'sparse', 'hybrid'],
        index=['dense', 'sparse', 'hybrid'].index(st.session_state.get('retrieval_method', 'hybrid')), # Äá»c tá»« state
        key="retrieval_method", # Ghi vÃ o state khi thay Ä‘á»•i
        horizontal=True,
        help=(
            "**dense:** TÃ¬m kiáº¿m dá»±a trÃªn vector ngá»¯ nghÄ©a.\n"
            "**sparse:** TÃ¬m kiáº¿m dá»±a trÃªn tá»« khÃ³a (BM25).\n"
            "**hybrid:** Káº¿t há»£p cáº£ dense vÃ  sparse."
        )
    )

    # Widget Ä‘á»c vÃ  ghi vÃ o st.session_state['use_reranker']
    st.toggle(
        "Sá»­ dá»¥ng Reranker",
        value=st.session_state.get('use_reranker', True), # Äá»c tá»« state
        key="use_reranker", # Ghi vÃ o state khi thay Ä‘á»•i
        help="Báº­t Ä‘á»ƒ sá»­ dá»¥ng mÃ´ hÃ¬nh CrossEncoder xáº¿p háº¡ng láº¡i káº¿t quáº£ tÃ¬m kiáº¿m."
    )

    # ÄÃ£ bá» cÃ i Ä‘áº·t cho History LLM1 á»Ÿ sidebar

# --- Khá»Ÿi táº¡o hoáº·c kiá»ƒm tra Session State (Tiáº¿p tá»¥c) ---
# Pháº§n khá»Ÿi táº¡o state riÃªng cá»§a Evaluation (giá»¯ nguyÃªn)
if 'eval_data' not in st.session_state: st.session_state.eval_data = None
if 'eval_results_df' not in st.session_state: st.session_state.eval_results_df = None
if 'eval_run_completed' not in st.session_state: st.session_state.eval_run_completed = False
if 'eval_uploaded_filename' not in st.session_state: st.session_state.eval_uploaded_filename = ""
# last_eval_config khÃ´ng cáº§n khá»Ÿi táº¡o á»Ÿ Ä‘Ã¢y vÃ¬ nÃ³ chá»‰ Ä‘Æ°á»£c set khi báº¯t Ä‘áº§u Ä‘Ã¡nh giÃ¡


st.subheader("Tráº¡ng thÃ¡i Há»‡ thá»‘ng CÆ¡ báº£n")
init_ok = False
retriever_instance = None
g_embedding_model = None
g_reranking_model_loaded = None # Äá»•i tÃªn biáº¿n Ä‘á»ƒ trÃ¡nh nháº§m láº«n

with st.spinner("Kiá»ƒm tra vÃ  khá»Ÿi táº¡o tÃ i nguyÃªn cá»‘t lÃµi..."):
    try:
        g_embedding_model = utils.load_embedding_model(config.embedding_model_name)
        # Táº£i reranker model nhÆ°ng chá»‰ dÃ¹ng náº¿u use_reranker_eval lÃ  True (Ä‘á»c tá»« state)
        g_reranking_model_loaded = utils.load_reranker_model(config.reranking_model_name)

        _, retriever_instance = data_loader.load_or_create_rag_components(g_embedding_model)

        # Äá»c giÃ¡ trá»‹ use_reranker tá»« session state (Ä‘Æ°á»£c quáº£n lÃ½ bá»Ÿi sidebar)
        use_reranker_current = st.session_state.get('use_reranker', True)

        if retriever_instance and g_embedding_model:
            init_ok = True
            # ThÃ´ng bÃ¡o vá» reranker model náº¿u khÃ´ng táº£i Ä‘Æ°á»£c hoáº·c bá»‹ táº¯t
            if not g_reranking_model_loaded:
                 st.warning("âš ï¸ KhÃ´ng táº£i Ä‘Æ°á»£c Reranker Model. Chá»©c nÄƒng rerank sáº½ khÃ´ng hoáº¡t Ä‘á»™ng.")
            elif not use_reranker_current: # DÃ¹ng biáº¿n má»›i Ä‘á»c tá»« state
                 st.info("Reranker Model Ä‘Ã£ táº£i, nhÆ°ng chá»©c nÄƒng Rerank Ä‘ang **Táº¯t** trong cáº¥u hÃ¬nh sidebar.")

        else:
            missing = [comp for comp, loaded in [("Retriever/VectorDB", retriever_instance), ("Embedding Model", g_embedding_model)] if not loaded]
            st.error(f"âš ï¸ Lá»—i khá»Ÿi táº¡o: {', '.join(missing)}.")

    except Exception as e:
        st.error(f"âš ï¸ Lá»—i nghiÃªm trá»ng khi khá»Ÿi táº¡o há»‡ thá»‘ng: {e}")

if init_ok:
    # --- Hiá»ƒn thá»‹ Cáº¥u hÃ¬nh ÄÃ¡nh giÃ¡ sáº½ sá»­ dá»¥ng (Ä‘á»c tá»« session state, giá» do sidebar quáº£n lÃ½) ---
    st.caption(f"MÃ´ hÃ¬nh: `{st.session_state.get('selected_gemini_model', 'N/A')}` | Nguá»“n Query: `{st.session_state.get('retrieval_query_mode', 'N/A')}` | Retrieval: `{st.session_state.get('retrieval_method', 'N/A')}` | Reranker: `{'Báº­t' if st.session_state.get('use_reranker', False) else 'Táº¯t'}`")

    # Táº¡o dict cáº¥u hÃ¬nh cho hÃ m Ä‘Ã¡nh giÃ¡ - Äá»c trá»±c tiáº¿p tá»« st.session_state
    # CÃ¡c giÃ¡ trá»‹ nÃ y giá» Ä‘Æ°á»£c Ä‘áº£m báº£o tá»“n táº¡i do sidebar hoáº·c khá»Ÿi táº¡o sá»›m
    eval_config_dict = {
        'retrieval_query_mode': st.session_state.get('retrieval_query_mode', 'Tá»•ng quÃ¡t'),
        'retrieval_method': st.session_state.get('retrieval_method', 'hybrid'),
        'use_reranker': st.session_state.get('use_reranker', True),
        'use_history_llm1': False, # GiÃ¡ trá»‹ nÃ y luÃ´n lÃ  False cho evaluation
        'gemini_model_name': st.session_state.get('selected_gemini_model', config.DEFAULT_GEMINI_MODEL),
        'embedding_model_name': config.embedding_model_name,
        # Cáº­p nháº­t tÃªn reranker model dá»±a trÃªn tráº¡ng thÃ¡i táº£i vÃ  cáº¥u hÃ¬nh
        'reranker_model_name': config.reranking_model_name if st.session_state.get('use_reranker', True) and g_reranking_model_loaded else ("DISABLED_BY_CONFIG" if st.session_state.get('use_reranker', True) else "DISABLED_BY_CONFIG"),
    }
    # Kiá»ƒm tra cuá»‘i cÃ¹ng cho reranker model Ä‘á»ƒ truyá»n vÃ o hÃ m run_retrieval_evaluation
    reranker_model_for_run = g_reranking_model_loaded if st.session_state.get('use_reranker', True) and g_reranking_model_loaded else None


    st.subheader("Táº£i LÃªn File ÄÃ¡nh giÃ¡")
    uploaded_file = st.file_uploader(
        "Chá»n file JSON dá»¯ liá»‡u Ä‘Ã¡nh giÃ¡...", type=["json"], key="eval_file_uploader"
    )

    if uploaded_file is not None:
        if uploaded_file.name != st.session_state.eval_uploaded_filename:
            try:
                eval_data_list = json.loads(uploaded_file.getvalue().decode('utf-8'))
                st.session_state.eval_data = eval_data_list
                st.session_state.eval_uploaded_filename = uploaded_file.name
                st.session_state.eval_run_completed = False
                # Reset last_eval_config khi táº£i file má»›i Ä‘á»ƒ trÃ¡nh hiá»ƒn thá»‹ káº¿t quáº£ cÅ© vá»›i cáº¥u hÃ¬nh sai
                st.session_state.last_eval_config = {}
                st.success(f"ÄÃ£ táº£i file '{uploaded_file.name}' ({len(eval_data_list)} cÃ¢u há»i).")
            except Exception as e:
                st.error(f"Lá»—i xá»­ lÃ½ file JSON: {e}")
                st.session_state.eval_data = None; st.session_state.eval_uploaded_filename = ""
                st.session_state.eval_run_completed = False

    if st.session_state.eval_data is not None:
        st.info(f"Sáºµn sÃ ng Ä‘Ã¡nh giÃ¡ vá»›i dá»¯ liá»‡u tá»«: **{st.session_state.eval_uploaded_filename}**.")

        if st.checkbox("Hiá»ƒn thá»‹ dá»¯ liá»‡u máº«u (5 dÃ²ng)", key="show_eval_data_preview"):
            st.dataframe(pd.DataFrame(st.session_state.eval_data).head())

        # NÃºt báº¯t Ä‘áº§u Ä‘Ã¡nh giÃ¡
        if st.button("ğŸš€ Báº¯t Ä‘áº§u ÄÃ¡nh giÃ¡", key="start_eval_button"):
             # LÆ°u cáº¥u hÃ¬nh hiá»‡n táº¡i tá»« st.session_state vÃ o last_eval_config trÆ°á»›c khi cháº¡y
             # ÄÃ¢y lÃ  cáº¥u hÃ¬nh mÃ  ngÆ°á»i dÃ¹ng Ä‘Ã£ chá»n trÃªn sidebar cá»§a trang Evaluation
             current_config_for_save = {
                'retrieval_query_mode': st.session_state.get('retrieval_query_mode', 'Tá»•ng quÃ¡t'),
                'retrieval_method': st.session_state.get('retrieval_method', 'hybrid'),
                'use_reranker': st.session_state.get('use_reranker', True),
                'use_history_llm1': False, # GiÃ¡ trá»‹ nÃ y luÃ´n lÃ  False cho evaluation
                'gemini_model_name': st.session_state.get('selected_gemini_model', config.DEFAULT_GEMINI_MODEL),
                'embedding_model_name': config.embedding_model_name,
                'reranker_model_name': config.reranking_model_name if st.session_state.get('use_reranker', True) and g_reranking_model_loaded else ("DISABLED_BY_CONFIG" if st.session_state.get('use_reranker', True) else "DISABLED_BY_CONFIG"),
             }
             st.session_state.last_eval_config = current_config_for_save.copy() # LÆ°u báº£n sao

             with st.spinner(f"Äang táº£i model Gemini: {st.session_state.get('selected_gemini_model', config.DEFAULT_GEMINI_MODEL)}..."):
                 # Táº£i Gemini model dá»±a trÃªn lá»±a chá»n má»›i nháº¥t tá»« sidebar (Ä‘Ã£ cÃ³ trong session state)
                 g_gemini_model_eval = utils.load_gemini_model(st.session_state.get('selected_gemini_model', config.DEFAULT_GEMINI_MODEL))


             if g_gemini_model_eval:
                st.info(f"Model Gemini '{st.session_state.get('selected_gemini_model', config.DEFAULT_GEMINI_MODEL)}' Ä‘Ã£ sáºµn sÃ ng.")
                with st.spinner("â³ Äang cháº¡y Ä‘Ã¡nh giÃ¡..."):
                    start_eval_time = time.time()
                    results_df = run_retrieval_evaluation(
                        eval_data=st.session_state.eval_data,
                        hybrid_retriever=retriever_instance,
                        embedding_model=g_embedding_model,
                        reranking_model=reranker_model_for_run, # Truyá»n model (hoáº·c None)
                        gemini_model=g_gemini_model_eval, # Truyá»n Gemini model Ä‘Ã£ táº£i
                        eval_config=st.session_state.last_eval_config # Truyá»n dict config Ä‘Ã£ lÆ°u (Ä‘áº£m báº£o nháº¥t)
                    )
                    total_eval_time = time.time() - start_eval_time
                    st.success(f"HoÃ n thÃ nh Ä‘Ã¡nh giÃ¡ sau {total_eval_time:.2f} giÃ¢y.")

                    st.session_state.eval_results_df = results_df
                    st.session_state.eval_run_completed = True
                    st.rerun() # Rerun Ä‘á»ƒ hiá»ƒn thá»‹ káº¿t quáº£


    # --- Hiá»ƒn thá»‹ Káº¿t quáº£ ---
    if st.session_state.eval_run_completed and st.session_state.eval_results_df is not None:
        st.subheader("Káº¿t quáº£ ÄÃ¡nh giÃ¡")
        detailed_results_df = st.session_state.eval_results_df
        last_config = st.session_state.last_eval_config # Äá»c config Ä‘Ã£ cháº¡y

        # --- Hiá»ƒn thá»‹ láº¡i cáº¥u hÃ¬nh Ä‘Ã£ cháº¡y ---
        st.markdown("**Cáº¥u hÃ¬nh Ä‘Ã£ sá»­ dá»¥ng cho láº§n cháº¡y cuá»‘i:**")
        cfg_col1, cfg_col2, cfg_col3, cfg_col4 = st.columns(4)
        cfg_col1.metric("Nguá»“n Query", last_config.get('retrieval_query_mode', 'N/A'))
        cfg_col2.metric("Ret. Method", last_config.get('retrieval_method', 'N/A'))
        cfg_col3.metric("Reranker", "Báº­t" if last_config.get('use_reranker', False) else "Táº¯t")
        cfg_col4.metric("History LLM1", "Táº¯t") # LuÃ´n hiá»ƒn thá»‹ Táº¯t vÃ¬ khÃ´ng dÃ¹ng history
        st.caption(f"Gemini: `{last_config.get('gemini_model_name', 'N/A')}`, Embedding: `{last_config.get('embedding_model_name', 'N/A')}`, Reranker: `{last_config.get('reranker_model_name', 'N/A')}`")


        avg_metrics, num_eval, num_skipped_error = calculate_average_metrics(detailed_results_df)

        st.metric("Tá»•ng sá»‘ Queries", len(detailed_results_df))
        col_res1, col_res2 = st.columns(2)
        col_res1.metric("Queries ÄÃ¡nh giÃ¡ Há»£p lá»‡", num_eval)
        col_res2.metric("Queries Bá» qua / Lá»—i", num_skipped_error)

        if avg_metrics:
            st.markdown("#### Metrics Trung bÃ¬nh @K (trÃªn cÃ¡c queries há»£p lá»‡)")
            # ÄÃ£ bá» K=1
            k_values_display = [3, 5, 10]
            cols_k = st.columns(len(k_values_display))
            for idx, k in enumerate(k_values_display):
                with cols_k[idx]:
                    st.markdown(f"**K = {k}**")
                    st.text(f"Precision: {avg_metrics.get(f'avg_precision@{k}', 0.0):.4f}")
                    st.text(f"Recall:    {avg_metrics.get(f'avg_recall@{k}', 0.0):.4f}")
                    st.text(f"F1:        {avg_metrics.get(f'avg_f1@{k}', 0.0):.4f}")
                    st.text(f"MRR:       {avg_metrics.get(f'avg_mrr@{k}', 0.0):.4f}")
                    st.text(f"NDCG:      {avg_metrics.get(f'avg_ndcg@{k}', 0.0):.4f}")

            st.markdown("#### ThÃ´ng tin Hiá»‡u nÄƒng & Sá»‘ lÆ°á»£ng Trung bÃ¬nh")
            col_perf1, col_perf2, col_perf3, col_perf4 = st.columns(4)
            col_perf1.metric("Avg Total Time (s)", f"{avg_metrics.get('avg_processing_time', 0.0):.3f}")
            col_perf2.metric("Avg Variation Time (s)", f"{avg_metrics.get('avg_variation_time', 0.0):.3f}")
            col_perf3.metric("Avg Search Time (s)", f"{avg_metrics.get('avg_search_time', 0.0):.3f}")
            col_perf4.metric("Avg Rerank Time (s)", f"{avg_metrics.get('avg_rerank_time', 0.0):.3f}")

            col_count1, col_count2, col_count3, col_count4 = st.columns(4)
            col_count1.metric("Avg Variations Gen", f"{avg_metrics.get('avg_num_variations_generated', 0.0):.1f}")
            col_count2.metric("Avg Docs Found", f"{avg_metrics.get('avg_num_unique_docs_found', 0.0):.1f}")
            col_count3.metric("Avg Docs Reranked", f"{avg_metrics.get('avg_num_docs_reranked', 0.0):.1f}")
            col_count4.metric("Avg Final Docs", f"{avg_metrics.get('avg_num_retrieved_after_rerank', 0.0):.1f}")


        else:
            st.warning("KhÃ´ng thá»ƒ tÃ­nh metrics trung bÃ¬nh (khÃ´ng cÃ³ query há»£p lá»‡).")


        with st.expander("Xem Káº¿t quáº£ Chi tiáº¿t cho tá»«ng Query"):
            display_columns = [
                'query_id', 'query', 'status',
                'retrieval_query_mode','retrieval_method', 'use_reranker', # ÄÃ£ bá» use_history_llm1 khá»i cá»™t hiá»ƒn thá»‹
                'precision@3', 'recall@3', 'f1@3', 'mrr@3', 'ndcg@3', # Chá»‰ giá»¯ K=3, 5, 10
                'precision@5', 'recall@5', 'f1@5', 'mrr@5', 'ndcg@5',
                'precision@10', 'recall@10', 'f1@10', 'mrr@10', 'ndcg@10',
                'processing_time', 'variation_time', 'search_time', 'rerank_time',
                'num_variations_generated','num_unique_docs_found', 'num_retrieved_before_rerank','num_docs_reranked', 'num_retrieved_after_rerank',
                'retrieved_ids', 'relevant_ids', 'summarizing_query', 'error_message'
            ]
            # Lá»c láº¡i cÃ¡c cá»™t hiá»ƒn thá»‹ Ä‘á»ƒ chá»‰ giá»¯ láº¡i cÃ¡c cá»™t thá»±c sá»± cÃ³ trong DataFrame
            # Äiá»u nÃ y quan trá»ng vÃ¬ cÃ¡c metrics @1 khÃ´ng cÃ²n Ä‘Æ°á»£c tÃ­nh
            existing_display_columns = [col for col in display_columns if col in detailed_results_df.columns]
            st.dataframe(detailed_results_df[existing_display_columns])


        st.subheader("LÆ°u Káº¿t quáº£ Chi tiáº¿t")
        try:
            results_json = detailed_results_df.to_json(orient='records', indent=2, force_ascii=False)
            results_csv = detailed_results_df.to_csv(index=False).encode('utf-8')

            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            # Sá»­ dá»¥ng config Ä‘Ã£ cháº¡y Ä‘á»ƒ táº¡o tÃªn file
            qmode_suffix = last_config.get('retrieval_query_mode', 'na').lower()[:3]
            method_suffix = last_config.get('retrieval_method', 'na').lower()
            rerank_suffix = "rr" if last_config.get('use_reranker', False) else "norr"
            # ÄÃ£ bá» hist_suffix khá»i tÃªn file
            model_suffix = last_config.get('gemini_model_name', 'gemini').split('/')[-1].replace('.','-')[:15]

            # TÃªn file khÃ´ng cÃ²n chá»©a thÃ´ng tin history
            base_filename = f"eval_{qmode_suffix}_{method_suffix}_{rerank_suffix}_{model_suffix}_{timestamp}"
            fname_json = f"{base_filename}.json"
            fname_csv = f"{base_filename}.csv"

            col_dl1, col_dl2 = st.columns(2)
            with col_dl1:
                st.download_button("ğŸ’¾ Táº£i vá» JSON", results_json, fname_json, "application/json", key="dl_json")
            with col_dl2:
                st.download_button("ğŸ’¾ Táº£i vá» CSV", results_csv, fname_csv, "text/csv", key="dl_csv")
        except Exception as e:
            st.error(f"Lá»—i khi chuáº©n bá»‹ file káº¿t quáº£: {e}")

    # --- Quáº£n lÃ½ Tráº¡ng thÃ¡i ÄÃ¡nh giÃ¡ ---
    st.markdown("---")
    st.subheader("Quáº£n lÃ½ Tráº¡ng thÃ¡i ÄÃ¡nh giÃ¡")
    if st.button("XÃ³a File ÄÃ£ Táº£i vÃ  Káº¿t Quáº£", key="clear_eval_state"):
        st.session_state.eval_data = None
        st.session_state.eval_uploaded_filename = ""
        st.session_state.eval_run_completed = False
        st.session_state.eval_results_df = None
        st.session_state.last_eval_config = {}
        # Reset cÃ¡c cÃ i Ä‘áº·t sidebar vá» máº·c Ä‘á»‹nh khi xÃ³a tráº¡ng thÃ¡i
        st.session_state.selected_gemini_model = config.DEFAULT_GEMINI_MODEL
        st.session_state.retrieval_query_mode = 'Tá»•ng quÃ¡t'
        st.session_state.retrieval_method = 'hybrid'
        st.session_state.use_reranker = True
        st.session_state.use_history_llm1 = False # LuÃ´n reset use_history_llm1 vá» False cho Evaluation

        st.success("ÄÃ£ xÃ³a tráº¡ng thÃ¡i Ä‘Ã¡nh giÃ¡.")
        time.sleep(1); st.rerun()

else:
    st.warning("âš ï¸ Há»‡ thá»‘ng cÆ¡ báº£n chÆ°a sáºµn sÃ ng. Vui lÃ²ng kiá»ƒm tra lá»—i vÃ  khá»Ÿi Ä‘á»™ng láº¡i.")
